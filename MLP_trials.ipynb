{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mL0ZoKwmSIrL"
      },
      "outputs": [],
      "source": [
        "#Self-hyperparam selection: https://link.springer.com/article/10.1007/s11063-024-11578-0\n",
        "#Self-pruning: https://github.com/skarifahmed/seMLP/blob/main/src/Prune.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PMr_2rxGcZyG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1mHello World !\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from utils import Utils\n",
        "from color import color \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "# libraries\n",
        "import joblib\n",
        "\n",
        "# scale features\n",
        "from sklearn import preprocessing\n",
        "from sklearn import impute\n",
        "# classifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "# scoring metrics\n",
        "from sklearn.metrics import confusion_matrix, matthews_corrcoef\n",
        "\n",
        "# custom scripts\n",
        "import sys\n",
        "sys.path.insert(0, \"%s\" % \"CV/\")\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, GroupShuffleSplit, StratifiedShuffleSplit, cross_validate, StratifiedKFold\n",
        "from sklearn.metrics import roc_curve, auc, recall_score, accuracy_score, precision_score, confusion_matrix, make_scorer, matthews_corrcoef, jaccard_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "site_path = \"/Users/sanjanayasna/csc334/MLP_MAHOMES/data/sites_calculated_features.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1mAll features:\u001b[0m\n",
            "sites: 3981 \tcolumns: 485\n",
            "Set   Catalytic\n",
            "data  False        2636\n",
            "      True          829\n",
            "test  False         345\n",
            "      True          171\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#read in feature set:\n",
        "sites = pd.read_csv(site_path)\n",
        "sites = sites.set_index('SITE_ID',drop=True)\n",
        "\n",
        "# The following labels need to be changed after looking over literature (see Feehan, Franklin, Slusky 2021)\n",
        "change_site_labels = [\"5zb8_0\", \"6aci_0\", \"6oq7_0\", \"6pjv_1\", \"6q55_0\",\n",
        "                      \"6q55_2\", \"6rmg_0\", \"6rtg_0\", \"6rw0_0\", \"6v77_0\"]\n",
        "\n",
        "# The following sites are removed due to unkopwn correct labels (see Feehan, Franklin, Slusky 2021)\n",
        "sites.loc[sites.index.isin(change_site_labels), 'Catalytic']=True\n",
        "remove_sites = [\"6mf0_1\", \"6okh_0\", \"6qwo_0\", \"6r9n_0\"]\n",
        "sites=sites.loc[~sites.index.isin(remove_sites)]\n",
        "\n",
        "#print shape of dataset\n",
        "print(color.BOLD + \"All features:\" + color.END)\n",
        "print(\"sites: %s \\tcolumns: %s\"%(sites.shape[0], sites.shape[1]))\n",
        "sizes = sites.groupby([\"Set\", \"Catalytic\"]).size()\n",
        "print(sizes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "#save_models toggel\n",
        "save_models = False\n",
        "#pkl output path\n",
        "pkl_out = r'/Users/sanjanayasna/csc334/MLP_MAHOMES/pkl'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Catalytic</th>\n",
              "      <th>MetalCodes</th>\n",
              "      <th>MetalAtoms</th>\n",
              "      <th>fa_atr_Sum_3.5</th>\n",
              "      <th>fa_rep_Sum_3.5</th>\n",
              "      <th>fa_sol_Sum_3.5</th>\n",
              "      <th>fa_intra_atr_xover4_Sum_3.5</th>\n",
              "      <th>fa_intra_rep_xover4_Sum_3.5</th>\n",
              "      <th>fa_intra_sol_xover4_Sum_3.5</th>\n",
              "      <th>lk_ball_Sum_3.5</th>\n",
              "      <th>...</th>\n",
              "      <th>geom_cn8</th>\n",
              "      <th>geom_cn9</th>\n",
              "      <th>geom_Filled</th>\n",
              "      <th>geom_PartFilled</th>\n",
              "      <th>geom_AvgN</th>\n",
              "      <th>geom_AvgO</th>\n",
              "      <th>geom_AvgS</th>\n",
              "      <th>geom_AvgOther</th>\n",
              "      <th>SC_vol_perc</th>\n",
              "      <th>Set</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SITE_ID</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6s9z_0</th>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-33.20757</td>\n",
              "      <td>20.22373</td>\n",
              "      <td>26.34441</td>\n",
              "      <td>-1.88617</td>\n",
              "      <td>0.46054</td>\n",
              "      <td>2.14096</td>\n",
              "      <td>14.05052</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.910384</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6g5l_0</th>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-27.04899</td>\n",
              "      <td>39.17134</td>\n",
              "      <td>22.76555</td>\n",
              "      <td>-1.71942</td>\n",
              "      <td>0.45999</td>\n",
              "      <td>2.05517</td>\n",
              "      <td>12.94894</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.862189</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6hwz_0</th>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-27.30433</td>\n",
              "      <td>35.04867</td>\n",
              "      <td>23.45195</td>\n",
              "      <td>-1.62146</td>\n",
              "      <td>0.35902</td>\n",
              "      <td>1.91231</td>\n",
              "      <td>13.06378</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.991431</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6qww_0</th>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-25.36664</td>\n",
              "      <td>12.54178</td>\n",
              "      <td>27.17902</td>\n",
              "      <td>-1.14349</td>\n",
              "      <td>0.22087</td>\n",
              "      <td>1.68091</td>\n",
              "      <td>11.47631</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.864546</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6qww_1</th>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-30.53159</td>\n",
              "      <td>8.99318</td>\n",
              "      <td>27.77842</td>\n",
              "      <td>-1.00782</td>\n",
              "      <td>0.39657</td>\n",
              "      <td>1.04229</td>\n",
              "      <td>13.23736</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.990893</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 485 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         Catalytic  MetalCodes  MetalAtoms  fa_atr_Sum_3.5  fa_rep_Sum_3.5  \\\n",
              "SITE_ID                                                                      \n",
              "6s9z_0        True           1           1       -33.20757        20.22373   \n",
              "6g5l_0        True           1           1       -27.04899        39.17134   \n",
              "6hwz_0        True           1           1       -27.30433        35.04867   \n",
              "6qww_0        True           1           1       -25.36664        12.54178   \n",
              "6qww_1       False           1           1       -30.53159         8.99318   \n",
              "\n",
              "         fa_sol_Sum_3.5  fa_intra_atr_xover4_Sum_3.5  \\\n",
              "SITE_ID                                                \n",
              "6s9z_0         26.34441                     -1.88617   \n",
              "6g5l_0         22.76555                     -1.71942   \n",
              "6hwz_0         23.45195                     -1.62146   \n",
              "6qww_0         27.17902                     -1.14349   \n",
              "6qww_1         27.77842                     -1.00782   \n",
              "\n",
              "         fa_intra_rep_xover4_Sum_3.5  fa_intra_sol_xover4_Sum_3.5  \\\n",
              "SITE_ID                                                             \n",
              "6s9z_0                       0.46054                      2.14096   \n",
              "6g5l_0                       0.45999                      2.05517   \n",
              "6hwz_0                       0.35902                      1.91231   \n",
              "6qww_0                       0.22087                      1.68091   \n",
              "6qww_1                       0.39657                      1.04229   \n",
              "\n",
              "         lk_ball_Sum_3.5  ...  geom_cn8  geom_cn9  geom_Filled  \\\n",
              "SITE_ID                   ...                                    \n",
              "6s9z_0          14.05052  ...       0.0       0.0          0.0   \n",
              "6g5l_0          12.94894  ...       0.0       0.0          0.0   \n",
              "6hwz_0          13.06378  ...       0.0       0.0          0.0   \n",
              "6qww_0          11.47631  ...       0.0       0.0          0.0   \n",
              "6qww_1          13.23736  ...       0.0       0.0          1.0   \n",
              "\n",
              "         geom_PartFilled  geom_AvgN  geom_AvgO  geom_AvgS  geom_AvgOther  \\\n",
              "SITE_ID                                                                    \n",
              "6s9z_0               1.0        3.0        0.0        0.0            0.0   \n",
              "6g5l_0               1.0        3.0        0.0        0.0            0.0   \n",
              "6hwz_0               1.0        3.0        0.0        0.0            0.0   \n",
              "6qww_0               0.0        0.0        3.0        0.0            0.0   \n",
              "6qww_1               0.0        0.0        4.0        0.0            1.0   \n",
              "\n",
              "         SC_vol_perc   Set  \n",
              "SITE_ID                     \n",
              "6s9z_0      0.910384  test  \n",
              "6g5l_0      0.862189  test  \n",
              "6hwz_0      0.991431  test  \n",
              "6qww_0      0.864546  test  \n",
              "6qww_1      0.990893  test  \n",
              "\n",
              "[5 rows x 485 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sites.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1mAll scaled data-set features:\u001b[0m\n",
            "sites: 3465 \tcolumns: 484\n",
            "Catalytic\n",
            "False    2636\n",
            "True      829\n",
            "dtype: int64\n",
            "\u001b[1m\n",
            "All scaled T-metal-site features:\u001b[0m\n",
            "sites: 516 \tcolumns: 484\n",
            "Catalytic\n",
            "False    345\n",
            "True     171\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#Get scaled features\n",
        "data_scaled, Tsites_scaled = Utils.get_scaled_features(sites =sites, pkl_out=pkl_out, save_models=save_models)\n",
        "#Print stats\n",
        "print(color.BOLD + \"All scaled data-set features:\" + color.END)\n",
        "print(\"sites: %s \\tcolumns: %s\"%(data_scaled.shape[0], data_scaled.shape[1]))\n",
        "print(data_scaled.groupby([\"Catalytic\"]).size())\n",
        "\n",
        "print(color.BOLD + \"\\nAll scaled T-metal-site features:\" + color.END)\n",
        "print(\"sites: %s \\tcolumns: %s\"%(Tsites_scaled.shape[0], Tsites_scaled.shape[1]))\n",
        "print(Tsites_scaled.groupby([\"Catalytic\"]).size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "dir = \"/Users/sanjanayasna/csc334/MLP_MAHOMES/data/\"\n",
        "#save the scaled data\n",
        "data_scaled.to_csv(os.path.join(dir, \"data_scaled.csv\"))\n",
        "Tsites_scaled.to_csv(os.path.join(dir, \"Tsites_scaled.csv\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "#set feature set type\n",
        "MAHOMES_feature_set = \"AllMeanSph\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Well sampled training data\n",
        "#X is train\n",
        "#y is target for train\n",
        "X, y = Utils.get_training_data(MAHOMES_feature_set, random_seed = 1, data_scaled= data_scaled)\n",
        " ## prepare test-set\n",
        "testX = Tsites_scaled.copy()\n",
        "testY = testX['Catalytic']; del testX['Catalytic']\n",
        "testX = Utils.feature_subset(testX, MAHOMES_feature_set, noBSA=True)\n",
        "\n",
        "## get multiple predictions for test-set w/ diff random seeds\n",
        "test_site_preds = {'actual': pd.Series(testY, index=testX.index)}\n",
        "\n",
        "#Overview:\n",
        "# X: training data\n",
        "# y: target for training data\n",
        "# testX: test data\n",
        "# testY: target for test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.utils.data.sampler as sampler\n",
        "#Will use subsetRandomSampler (which assumes a shuffle=trfue data loading argument)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "181\n"
          ]
        }
      ],
      "source": [
        "#Train input feed params\n",
        "init_features = len(X.columns)\n",
        "twice = init_features * 2\n",
        "print(init_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import torch\n",
        "def mse_r2_calculator(mlp, test_data, test_targets):\n",
        "    with torch.no_grad():\n",
        "        outputs = mlp(test_data)\n",
        "        predicted_labels = outputs.squeeze().tolist()\n",
        "\n",
        "    predicted_labels = np.array(predicted_labels)\n",
        "    test_targets = np.array(test_targets)\n",
        "\n",
        "    mse = mean_squared_error(test_targets, predicted_labels)\n",
        "    r2 = r2_score(test_targets, predicted_labels)\n",
        "    print(\"Mean Squared Error:\", mse)\n",
        "    print(\"R2 Score:\", r2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Loads to torch tensors\n",
        "class dataLoader:\n",
        "    #Use ONLY train data \n",
        "    def __init__(self, X, y):\n",
        "        #converts x and y to numpy arr so they can be torch tensor\n",
        "        if not torch.is_tensor(X) and not torch.is_tensor(y):\n",
        "            X = X.to_numpy()\n",
        "            y = y.to_numpy()\n",
        "        #x_train\n",
        "        # if not torch.is_tensor(X):\n",
        "        #     self.X = torch.from_numpy(X)\n",
        "        # #y_train\n",
        "        # if not torch.is_tensor(y):\n",
        "        #     self.y = torch.from_numpy(y)\n",
        "            \n",
        "        #To convert boolean to int, do .long()\n",
        "        self.X = torch.from_numpy(X)\n",
        "        self.y = torch.from_numpy(y).long()\n",
        "    def get_trainloader(dataset):\n",
        "        return torch.utils.data.DataLoader(dataset, batch_size=10, shuffle=True, num_workers=1)\n",
        "    def get_testloader(dataset):\n",
        "        return torch.utils.data.DataLoader(dataset, batch_size=10, shuffle=True, num_workers=1)\n",
        "    #to get lenght, for enumerator use\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting Epoch 1\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.007\n",
            "Loss after mini-batch    21: 0.007\n",
            "Loss after mini-batch    31: 0.006\n",
            "Loss after mini-batch    41: 0.006\n",
            "Loss after mini-batch    51: 0.006\n",
            "Loss after mini-batch    61: 0.005\n",
            "Loss after mini-batch    71: 0.006\n",
            "Loss after mini-batch    81: 0.006\n",
            "Loss after mini-batch    91: 0.005\n",
            "Loss after mini-batch   101: 0.005\n",
            "Loss after mini-batch   111: 0.006\n",
            "Loss after mini-batch   121: 0.006\n",
            "Loss after mini-batch   131: 0.006\n",
            "Loss after mini-batch   141: 0.005\n",
            "Loss after mini-batch   151: 0.005\n",
            "Loss after mini-batch   161: 0.006\n",
            "Loss after mini-batch   171: 0.006\n",
            "Loss after mini-batch   181: 0.005\n",
            "Loss after mini-batch   191: 0.005\n",
            "Loss after mini-batch   201: 0.005\n",
            "Loss after mini-batch   211: 0.005\n",
            "Loss after mini-batch   221: 0.005\n",
            "Loss after mini-batch   231: 0.007\n",
            "Loss after mini-batch   241: 0.006\n",
            "Loss after mini-batch   251: 0.006\n",
            "Loss after mini-batch   261: 0.006\n",
            "Loss after mini-batch   271: 0.005\n",
            "Loss after mini-batch   281: 0.005\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.005\n",
            "Loss after mini-batch   311: 0.005\n",
            "Loss after mini-batch   321: 0.005\n",
            "Loss after mini-batch   331: 0.005\n",
            "Epoch 1 done\n",
            "Starting Epoch 2\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.005\n",
            "Loss after mini-batch    21: 0.005\n",
            "Loss after mini-batch    31: 0.005\n",
            "Loss after mini-batch    41: 0.005\n",
            "Loss after mini-batch    51: 0.005\n",
            "Loss after mini-batch    61: 0.005\n",
            "Loss after mini-batch    71: 0.005\n",
            "Loss after mini-batch    81: 0.005\n",
            "Loss after mini-batch    91: 0.005\n",
            "Loss after mini-batch   101: 0.005\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.005\n",
            "Loss after mini-batch   131: 0.005\n",
            "Loss after mini-batch   141: 0.005\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.006\n",
            "Loss after mini-batch   171: 0.005\n",
            "Loss after mini-batch   181: 0.005\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.005\n",
            "Loss after mini-batch   211: 0.005\n",
            "Loss after mini-batch   221: 0.005\n",
            "Loss after mini-batch   231: 0.005\n",
            "Loss after mini-batch   241: 0.005\n",
            "Loss after mini-batch   251: 0.005\n",
            "Loss after mini-batch   261: 0.005\n",
            "Loss after mini-batch   271: 0.005\n",
            "Loss after mini-batch   281: 0.005\n",
            "Loss after mini-batch   291: 0.006\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.006\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Epoch 2 done\n",
            "Starting Epoch 3\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.005\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.005\n",
            "Loss after mini-batch    41: 0.005\n",
            "Loss after mini-batch    51: 0.005\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.005\n",
            "Loss after mini-batch    81: 0.005\n",
            "Loss after mini-batch    91: 0.005\n",
            "Loss after mini-batch   101: 0.005\n",
            "Loss after mini-batch   111: 0.005\n",
            "Loss after mini-batch   121: 0.005\n",
            "Loss after mini-batch   131: 0.005\n",
            "Loss after mini-batch   141: 0.005\n",
            "Loss after mini-batch   151: 0.005\n",
            "Loss after mini-batch   161: 0.005\n",
            "Loss after mini-batch   171: 0.005\n",
            "Loss after mini-batch   181: 0.005\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.005\n",
            "Loss after mini-batch   211: 0.005\n",
            "Loss after mini-batch   221: 0.005\n",
            "Loss after mini-batch   231: 0.005\n",
            "Loss after mini-batch   241: 0.005\n",
            "Loss after mini-batch   251: 0.005\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.005\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.005\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.005\n",
            "Loss after mini-batch   331: 0.004\n",
            "Epoch 3 done\n",
            "Starting Epoch 4\n",
            "Loss after mini-batch     1: 0.000\n",
            "Loss after mini-batch    11: 0.005\n",
            "Loss after mini-batch    21: 0.005\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.005\n",
            "Loss after mini-batch    91: 0.005\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.005\n",
            "Loss after mini-batch   121: 0.005\n",
            "Loss after mini-batch   131: 0.005\n",
            "Loss after mini-batch   141: 0.005\n",
            "Loss after mini-batch   151: 0.005\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.005\n",
            "Loss after mini-batch   181: 0.005\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.005\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.005\n",
            "Loss after mini-batch   241: 0.005\n",
            "Loss after mini-batch   251: 0.005\n",
            "Loss after mini-batch   261: 0.005\n",
            "Loss after mini-batch   271: 0.005\n",
            "Loss after mini-batch   281: 0.005\n",
            "Loss after mini-batch   291: 0.005\n",
            "Loss after mini-batch   301: 0.005\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Epoch 4 done\n",
            "Starting Epoch 5\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.005\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.005\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.005\n",
            "Loss after mini-batch    71: 0.005\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.005\n",
            "Loss after mini-batch   101: 0.005\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.005\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.006\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.005\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.005\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.005\n",
            "Loss after mini-batch   251: 0.005\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.005\n",
            "Loss after mini-batch   281: 0.005\n",
            "Loss after mini-batch   291: 0.005\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.005\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.005\n",
            "Epoch 5 done\n",
            "Starting Epoch 6\n",
            "Loss after mini-batch     1: 0.000\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.005\n",
            "Loss after mini-batch    41: 0.005\n",
            "Loss after mini-batch    51: 0.005\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.005\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.005\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.005\n",
            "Loss after mini-batch   131: 0.005\n",
            "Loss after mini-batch   141: 0.005\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.005\n",
            "Loss after mini-batch   171: 0.005\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.005\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.006\n",
            "Loss after mini-batch   231: 0.005\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.005\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.005\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.006\n",
            "Loss after mini-batch   311: 0.005\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.005\n",
            "Epoch 6 done\n",
            "Starting Epoch 7\n",
            "Loss after mini-batch     1: 0.000\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.005\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.006\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.005\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.005\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.005\n",
            "Loss after mini-batch   131: 0.005\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.005\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.005\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.005\n",
            "Loss after mini-batch   221: 0.005\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.005\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.005\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.005\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.005\n",
            "Loss after mini-batch   321: 0.005\n",
            "Loss after mini-batch   331: 0.004\n",
            "Epoch 7 done\n",
            "Starting Epoch 8\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.005\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.005\n",
            "Loss after mini-batch    81: 0.005\n",
            "Loss after mini-batch    91: 0.005\n",
            "Loss after mini-batch   101: 0.006\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.005\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.005\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.005\n",
            "Loss after mini-batch   201: 0.005\n",
            "Loss after mini-batch   211: 0.005\n",
            "Loss after mini-batch   221: 0.005\n",
            "Loss after mini-batch   231: 0.005\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.005\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.005\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.005\n",
            "Loss after mini-batch   331: 0.004\n",
            "Epoch 8 done\n",
            "Starting Epoch 9\n",
            "Loss after mini-batch     1: 0.000\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.005\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.005\n",
            "Loss after mini-batch    51: 0.005\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.005\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.005\n",
            "Loss after mini-batch   111: 0.005\n",
            "Loss after mini-batch   121: 0.005\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.005\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.005\n",
            "Loss after mini-batch   181: 0.005\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.005\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.005\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.005\n",
            "Loss after mini-batch   311: 0.005\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Epoch 9 done\n",
            "Starting Epoch 10\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.005\n",
            "Loss after mini-batch    41: 0.005\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.005\n",
            "Loss after mini-batch    91: 0.005\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.003\n",
            "Loss after mini-batch   121: 0.005\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.005\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.005\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.005\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.005\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.005\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.005\n",
            "Epoch 10 done\n",
            "Starting Epoch 11\n",
            "Loss after mini-batch     1: 0.000\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.003\n",
            "Loss after mini-batch    41: 0.005\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.005\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.005\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.005\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.005\n",
            "Loss after mini-batch   181: 0.005\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.005\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.005\n",
            "Loss after mini-batch   241: 0.005\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.005\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.005\n",
            "Epoch 11 done\n",
            "Starting Epoch 12\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.005\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.005\n",
            "Loss after mini-batch    61: 0.005\n",
            "Loss after mini-batch    71: 0.005\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.005\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.005\n",
            "Loss after mini-batch   121: 0.005\n",
            "Loss after mini-batch   131: 0.005\n",
            "Loss after mini-batch   141: 0.005\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.005\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.005\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.005\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.003\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.005\n",
            "Loss after mini-batch   321: 0.005\n",
            "Loss after mini-batch   331: 0.004\n",
            "Epoch 12 done\n",
            "Starting Epoch 13\n",
            "Loss after mini-batch     1: 0.000\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.005\n",
            "Loss after mini-batch    61: 0.005\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.005\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.005\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.005\n",
            "Loss after mini-batch   151: 0.005\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.005\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.005\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.005\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.005\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Epoch 13 done\n",
            "Starting Epoch 14\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.005\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.005\n",
            "Loss after mini-batch    51: 0.005\n",
            "Loss after mini-batch    61: 0.005\n",
            "Loss after mini-batch    71: 0.003\n",
            "Loss after mini-batch    81: 0.005\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.005\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.005\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.005\n",
            "Loss after mini-batch   181: 0.005\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.005\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.005\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.005\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.005\n",
            "Loss after mini-batch   331: 0.005\n",
            "Epoch 14 done\n",
            "Starting Epoch 15\n",
            "Loss after mini-batch     1: 0.000\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.005\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.005\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.005\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.005\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.005\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.005\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.005\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.005\n",
            "Loss after mini-batch   201: 0.005\n",
            "Loss after mini-batch   211: 0.005\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.003\n",
            "Loss after mini-batch   251: 0.003\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.005\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.005\n",
            "Loss after mini-batch   301: 0.005\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.005\n",
            "Loss after mini-batch   331: 0.004\n",
            "Epoch 15 done\n",
            "Starting Epoch 16\n",
            "Loss after mini-batch     1: 0.000\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.005\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.005\n",
            "Loss after mini-batch    81: 0.005\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.005\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.005\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.005\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.005\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.005\n",
            "Loss after mini-batch   271: 0.005\n",
            "Loss after mini-batch   281: 0.005\n",
            "Loss after mini-batch   291: 0.005\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Epoch 16 done\n",
            "Starting Epoch 17\n",
            "Loss after mini-batch     1: 0.000\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.005\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.005\n",
            "Loss after mini-batch    71: 0.005\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.005\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.005\n",
            "Loss after mini-batch   151: 0.005\n",
            "Loss after mini-batch   161: 0.005\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.005\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.005\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.005\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Epoch 17 done\n",
            "Starting Epoch 18\n",
            "Loss after mini-batch     1: 0.000\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.005\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.005\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.005\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.005\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.005\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.005\n",
            "Loss after mini-batch   291: 0.005\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.005\n",
            "Loss after mini-batch   331: 0.005\n",
            "Epoch 18 done\n",
            "Starting Epoch 19\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.005\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.005\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.005\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.003\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.005\n",
            "Loss after mini-batch   221: 0.005\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.005\n",
            "Loss after mini-batch   261: 0.005\n",
            "Loss after mini-batch   271: 0.005\n",
            "Loss after mini-batch   281: 0.005\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.005\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.005\n",
            "Loss after mini-batch   331: 0.004\n",
            "Epoch 19 done\n",
            "Starting Epoch 20\n",
            "Loss after mini-batch     1: 0.000\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.005\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.003\n",
            "Loss after mini-batch   171: 0.005\n",
            "Loss after mini-batch   181: 0.005\n",
            "Loss after mini-batch   191: 0.005\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.005\n",
            "Loss after mini-batch   241: 0.005\n",
            "Loss after mini-batch   251: 0.005\n",
            "Loss after mini-batch   261: 0.003\n",
            "Loss after mini-batch   271: 0.005\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.003\n",
            "Loss after mini-batch   321: 0.005\n",
            "Loss after mini-batch   331: 0.004\n",
            "Epoch 20 done\n",
            "Starting Epoch 21\n",
            "Loss after mini-batch     1: 0.000\n",
            "Loss after mini-batch    11: 0.005\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.005\n",
            "Loss after mini-batch    51: 0.005\n",
            "Loss after mini-batch    61: 0.003\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.005\n",
            "Loss after mini-batch    91: 0.005\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.005\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.005\n",
            "Loss after mini-batch   201: 0.003\n",
            "Loss after mini-batch   211: 0.005\n",
            "Loss after mini-batch   221: 0.005\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.005\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.005\n",
            "Epoch 21 done\n",
            "Starting Epoch 22\n",
            "Loss after mini-batch     1: 0.000\n",
            "Loss after mini-batch    11: 0.005\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.005\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.005\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.005\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.005\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.005\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.005\n",
            "Loss after mini-batch   331: 0.004\n",
            "Epoch 22 done\n",
            "Starting Epoch 23\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.005\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.003\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.005\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.005\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.006\n",
            "Loss after mini-batch   191: 0.005\n",
            "Loss after mini-batch   201: 0.005\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.005\n",
            "Loss after mini-batch   241: 0.003\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.005\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.005\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.005\n",
            "Loss after mini-batch   331: 0.004\n",
            "Epoch 23 done\n",
            "Starting Epoch 24\n",
            "Loss after mini-batch     1: 0.000\n",
            "Loss after mini-batch    11: 0.005\n",
            "Loss after mini-batch    21: 0.005\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.005\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.005\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.005\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.005\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.005\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.005\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Epoch 24 done\n",
            "Starting Epoch 25\n",
            "Loss after mini-batch     1: 0.000\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.005\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.005\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.005\n",
            "Loss after mini-batch   171: 0.005\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.005\n",
            "Loss after mini-batch   201: 0.005\n",
            "Loss after mini-batch   211: 0.005\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.005\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Epoch 25 done\n",
            "Starting Epoch 26\n",
            "Loss after mini-batch     1: 0.000\n",
            "Loss after mini-batch    11: 0.005\n",
            "Loss after mini-batch    21: 0.003\n",
            "Loss after mini-batch    31: 0.005\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.005\n",
            "Loss after mini-batch   151: 0.005\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.005\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.005\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.005\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Epoch 26 done\n",
            "Starting Epoch 27\n",
            "Loss after mini-batch     1: 0.000\n",
            "Loss after mini-batch    11: 0.003\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.005\n",
            "Loss after mini-batch   111: 0.005\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.005\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.005\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.005\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.005\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Epoch 27 done\n",
            "Starting Epoch 28\n",
            "Loss after mini-batch     1: 0.000\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.005\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.005\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.005\n",
            "Loss after mini-batch   231: 0.005\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.005\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.005\n",
            "Loss after mini-batch   291: 0.005\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.003\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Epoch 28 done\n",
            "Starting Epoch 29\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.005\n",
            "Loss after mini-batch    71: 0.005\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.005\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.005\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.005\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.003\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.005\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.005\n",
            "Epoch 29 done\n",
            "Starting Epoch 30\n",
            "Loss after mini-batch     1: 0.000\n",
            "Loss after mini-batch    11: 0.005\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.005\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.005\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.003\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.005\n",
            "Loss after mini-batch   191: 0.005\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.005\n",
            "Loss after mini-batch   251: 0.005\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.003\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.005\n",
            "Loss after mini-batch   331: 0.004\n",
            "Epoch 30 done\n",
            "Starting Epoch 31\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.005\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.005\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.005\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.005\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.005\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.003\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.003\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.005\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.005\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Epoch 31 done\n",
            "Starting Epoch 32\n",
            "Loss after mini-batch     1: 0.000\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.005\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.005\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.005\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.005\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.003\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.005\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.005\n",
            "Epoch 32 done\n",
            "Starting Epoch 33\n",
            "Loss after mini-batch     1: 0.000\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.005\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.005\n",
            "Loss after mini-batch   201: 0.005\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.005\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.005\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Epoch 33 done\n",
            "Starting Epoch 34\n",
            "Loss after mini-batch     1: 0.000\n",
            "Loss after mini-batch    11: 0.005\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.003\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.003\n",
            "Loss after mini-batch    81: 0.005\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.005\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.005\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.005\n",
            "Loss after mini-batch   241: 0.005\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Epoch 34 done\n",
            "Starting Epoch 35\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.005\n",
            "Loss after mini-batch   101: 0.003\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.005\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.005\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.005\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.005\n",
            "Epoch 35 done\n",
            "Starting Epoch 36\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.005\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.003\n",
            "Loss after mini-batch    71: 0.005\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.005\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.003\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.003\n",
            "Loss after mini-batch   181: 0.005\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.005\n",
            "Loss after mini-batch   211: 0.005\n",
            "Loss after mini-batch   221: 0.005\n",
            "Loss after mini-batch   231: 0.005\n",
            "Loss after mini-batch   241: 0.005\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Epoch 36 done\n",
            "Starting Epoch 37\n",
            "Loss after mini-batch     1: 0.000\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.005\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.005\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.005\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.005\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.003\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.005\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.005\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.005\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.005\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.005\n",
            "Loss after mini-batch   291: 0.005\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Epoch 37 done\n",
            "Starting Epoch 38\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.005\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.005\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.005\n",
            "Loss after mini-batch   181: 0.003\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.005\n",
            "Loss after mini-batch   251: 0.005\n",
            "Loss after mini-batch   261: 0.005\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.005\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Epoch 38 done\n",
            "Starting Epoch 39\n",
            "Loss after mini-batch     1: 0.000\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.003\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.005\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.005\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.005\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Epoch 39 done\n",
            "Starting Epoch 40\n",
            "Loss after mini-batch     1: 0.000\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.005\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.005\n",
            "Loss after mini-batch    71: 0.003\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.003\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.005\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.005\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.005\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.005\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.005\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Epoch 40 done\n",
            "Starting Epoch 41\n",
            "Loss after mini-batch     1: 0.000\n",
            "Loss after mini-batch    11: 0.003\n",
            "Loss after mini-batch    21: 0.005\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.005\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.005\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.005\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.003\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.005\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.005\n",
            "Loss after mini-batch   271: 0.005\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Epoch 41 done\n",
            "Starting Epoch 42\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.005\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.003\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.005\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.005\n",
            "Loss after mini-batch   161: 0.005\n",
            "Loss after mini-batch   171: 0.005\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.005\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.003\n",
            "Loss after mini-batch   331: 0.004\n",
            "Epoch 42 done\n",
            "Starting Epoch 43\n",
            "Loss after mini-batch     1: 0.000\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.005\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.005\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.005\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.005\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.005\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.005\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.003\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Epoch 43 done\n",
            "Starting Epoch 44\n",
            "Loss after mini-batch     1: 0.000\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.005\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.005\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.005\n",
            "Loss after mini-batch   181: 0.003\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.005\n",
            "Loss after mini-batch   211: 0.003\n",
            "Loss after mini-batch   221: 0.005\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.005\n",
            "Epoch 44 done\n",
            "Starting Epoch 45\n",
            "Loss after mini-batch     1: 0.000\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.005\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.005\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.003\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.003\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.005\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.005\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.003\n",
            "Loss after mini-batch   241: 0.003\n",
            "Loss after mini-batch   251: 0.005\n",
            "Loss after mini-batch   261: 0.005\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.005\n",
            "Loss after mini-batch   301: 0.005\n",
            "Loss after mini-batch   311: 0.003\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.003\n",
            "Epoch 45 done\n",
            "Starting Epoch 46\n",
            "Loss after mini-batch     1: 0.000\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.005\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.005\n",
            "Loss after mini-batch    81: 0.006\n",
            "Loss after mini-batch    91: 0.005\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.005\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.005\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.005\n",
            "Loss after mini-batch   311: 0.005\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.003\n",
            "Epoch 46 done\n",
            "Starting Epoch 47\n",
            "Loss after mini-batch     1: 0.000\n",
            "Loss after mini-batch    11: 0.005\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.003\n",
            "Loss after mini-batch    41: 0.005\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.003\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.005\n",
            "Loss after mini-batch    91: 0.005\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.005\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.005\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.005\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.003\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.003\n",
            "Loss after mini-batch   331: 0.004\n",
            "Epoch 47 done\n",
            "Starting Epoch 48\n",
            "Loss after mini-batch     1: 0.000\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.005\n",
            "Loss after mini-batch    31: 0.003\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.003\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.005\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.005\n",
            "Loss after mini-batch   181: 0.005\n",
            "Loss after mini-batch   191: 0.005\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.005\n",
            "Loss after mini-batch   281: 0.005\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Epoch 48 done\n",
            "Starting Epoch 49\n",
            "Loss after mini-batch     1: 0.000\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.005\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.005\n",
            "Loss after mini-batch    71: 0.005\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.005\n",
            "Loss after mini-batch   101: 0.003\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.005\n",
            "Loss after mini-batch   141: 0.003\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.003\n",
            "Loss after mini-batch   181: 0.003\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.005\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.005\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.005\n",
            "Loss after mini-batch   331: 0.004\n",
            "Epoch 49 done\n",
            "Starting Epoch 50\n",
            "Loss after mini-batch     1: 0.000\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.005\n",
            "Loss after mini-batch    31: 0.005\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.003\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.005\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.003\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.003\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.005\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.005\n",
            "Loss after mini-batch   301: 0.003\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Epoch 50 done\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAByhklEQVR4nO29eZxcdZn2fZ3ae+9O70k6+0ZAkpCQGBBBCTLqg8DoGLcBo8OMSmbUzMwz8voIbjNBRQb1yYgvDoOvOoL6iI4+IxoDiSKRQBaWkH0ha2/prbq6az/vH6d+p05X13LOqVNVp6qu7+fTH0h3dffpWk5d576v+7olWZZlEEIIIYSUCEepD4AQQggh1Q3FCCGEEEJKCsUIIYQQQkoKxQghhBBCSgrFCCGEEEJKCsUIIYQQQkoKxQghhBBCSgrFCCGEEEJKiqvUB6CHeDyOCxcuoKGhAZIklfpwCCGEEKIDWZbh9/sxc+ZMOByZ6x9lIUYuXLiAnp6eUh8GIYQQQkxw9uxZzJ49O+PXy0KMNDQ0AFD+mMbGxhIfDSGEEEL0MDY2hp6eHvV9PBNlIUZEa6axsZFihBBCCCkzclksaGAlhBBCSEmhGCGEEEJISaEYIYQQQkhJoRghhBBCSEmhGCGEEEJISaEYIYQQQkhJoRghhBBCSEmhGCGEEEJISaEYIYQQQkhJoRghhBBCSEmhGCGEEEJISaEYIYQQQkhJoRghpEiEo3E88vuTONLrL/WhEEKIraAYIaRI7Do6gH/+70PY+utDpT4UQgixFRQjhBSJwfEQAGB4IlLiIyGEEHtBMUJIkRgPRgEAwXCsxEdCCCH2gmKEkCLhDyliZDJCMUIIIVooRggpEgGKEUIISQvFCCFFgm0aQghJD8UIIUVinJURQghJC8UIIUVCiJFoXEYkFi/x0RBCiH2gGCGkSAgxArA6QgghWihGCCkSwjMC0DdCCCFaKEYIKRKsjBBCSHooRggpEhQjhBCSHooRQoqALMtTxQjbNIQQomJKjGzbtg3z5s2Dz+fDunXrsGfPnoy3feyxxyBJ0pQPn89n+oAJKUdC0ThicVn9NysjhBCSxLAYeeKJJ7Blyxbcd9992LdvH1asWIGbb74Z/f39Gb+nsbERFy9eVD9ef/31vA6akHLDrzGvAkCQYoQQQlQMi5EHH3wQd911FzZt2oTly5fj4YcfRm1tLR599NGM3yNJErq6utSPzs7OvA6akHJD26IBgMkwc0YIIURgSIyEw2Hs3bsXGzZsSP4AhwMbNmzA7t27M37f+Pg45s6di56eHtx66604ePBg1t8TCoUwNjY25YOQciaQKkZYGSGEEBVDYmRwcBCxWGxaZaOzsxO9vb1pv2fp0qV49NFH8Ytf/AI/+MEPEI/Hcc011+DcuXMZf8/WrVvR1NSkfvT09Bg5TEJsR2qbhmKEEEKSFHyaZv369bjjjjuwcuVKXH/99fjZz36G9vZ2fOc738n4Pffccw9GR0fVj7Nnzxb6MAkpKKltGoaeEUJIEpeRG7e1tcHpdKKvr2/K5/v6+tDV1aXrZ7jdbqxatQrHjx/PeBuv1wuv12vk0AixNWzTEEJIZgxVRjweD1avXo0dO3aon4vH49ixYwfWr1+v62fEYjG88sor6O7uNnakhJQxfooRQgjJiKHKCABs2bIFd955J9asWYO1a9fioYceQiAQwKZNmwAAd9xxB2bNmoWtW7cCAL74xS/ijW98IxYtWoSRkRF87Wtfw+uvv46/+qu/svYvIcTGjKd6RtimIYQQFcNiZOPGjRgYGMC9996L3t5erFy5Ek899ZRqaj1z5gwcjmTBZXh4GHfddRd6e3vR0tKC1atX47nnnsPy5cut+ysIsTmpbRrmjBBCSBJJlmU5981Ky9jYGJqamjA6OorGxsZSHw4hhvn8fx3EY8+dhs/tQDASx60rZ+Ib71tV6sMihJCCovf9m7tpCCkCYrS3vUExZrNNQwghSShGCCkCok3TXq+IkWCUCayEECKgGCGkCIickTYhRlgZIYQQFYoRQoqAGO1V2zQ0sBJCiArFCCFFIEAxQgghGaEYIaQIiJwR0aahgZUQQpJQjBBSBMZTKiPMGSGEkCQUI4QUmHhcRiDMNg0hhGSCYoSQAjMRiUFEC4rR3slIDGWQN0gIIUWBYoSQAiP8Ik6HhOZaNwBAloEQs0YIIQQAxQghBUf4Req9LtS4nern6RshhBAFihFCCoxWjLicDnicysuOvhFCCFGgGCGkwIg2Tb1XWZLtcyfECMd7CSEEAMUIIQVHrYz4FDFS41FaNayMEEKIAsUIIQVGiJE6tTKiiBF6RgghRIFihJACMx6MAAAaEmJEmFgnw5ymIYQQgGKEkIITSHhD6lMqI2zTEEKIAsUIIQXGH5zapqmhGCGEkClQjBBSYMZDSpsm1cAa5DQNIYQAoBghpOAEQoromOYZYWWEEEIAUIwQUnBS2zT0jBBCyFQoRggpMNPbNAw9I4QQLRQjhBQYkTOS2qZhzgghhChQjBBSYIRnRK2MsE1DCCFToBghpMConhFPwjMi4uDZpiGEEAAUI4QUHOEZaWBlhBBC0kIxQkgBicbiCEaU2Pd6ekYIISQtFCOEFBDhFwE0Cazc2ksIIVOgGCGkgPgTLRqPywGPS3m5qTkj9IwQQggAihFCCkpq+iqg9Yxway8hhAAUI4QUFGFerdOKEQ89I4QQooVihJACIsZ669NVRtimIYQQABQjhBSU1MAzgLtpCCEkFYoRQgqIupcmTZuGYoQQQhQoRggpINnaNOFoHLG4XJLjIqQSiPP1UzFQjBBSQNK1aYQYAWhiJcQs3/3DSaz4wm/x6vnRUh8KsQCKEUIKSLo2jdeVfNmxVUOIOXYdHYA/FMWeU0OlPhRiARQjhBSQ8dD0No3DIcHnVl56nKghxByiBToyES7xkRAroBghpICMizaNRowA3E9DSL6MBZWq48hkpMRHQqyAYoSQAjIenN6mAbi5l5B8GZsUlRGKkUqAYoSQAqK2aXxTxYhPTWFlJDwhZvCzMlJRUIwQUkBytWlYGSHEOMFIDKGoIuTpGakMKEYIKSDpdtMAjIQnJB+EeRVgm6ZSoBghpICMJ06aDSltGi7LI8Q8okUDsDJSKVCMEFJAAhnaNNxPQ4h5xjSVkbFglEnGFQDFCCEFIhSNIRxT+tps0xBiHWMpptVRmljLHooRQgrEuObqjQZWQqxD6xkB2KqpBChGCCkQokVT63HC6ZCmfI2eEULMMxacWgnheG/5QzFCSIHwZ5ikATSeEbZpCDFMapuGlZHyh2KEkAKhTtKkESNs0xBinultGlZGyh2KEWIJsiwjGmOaqJZAOH36KoDkojyKEUIMM61NQzFS9lCMEEu48z9ewFu+vpMeCA3i6q3Ok6YyQs8IIaaZ1qahZ6TsoRgheSPLMp47PoizQ5M4MzRR6sOxDZn20gD0jBCSD0LodzR4AdAzUglQjJC8CcfiiCZChzjvnyQQomeEkEIg2jRzZtQCYJumEqAYIXkzEUq+ofKkkEQYWNNN0yTFCH02hBhlbFJ5balihBdBZQ/FCMmbCc3VPSsjSfxZ2jSqZ4RtGkIMI3bTzFYrI2zTlDsUIyRvJkLJMTuKkSSiTZOavgpwNw0h+SB207BNUzlQjJC8mQizMpKO8SxihJ4RQswRi8vqa2tuKysjlQLFCMkbkacBTB+5q2aE4z+tGGGbhhBTaHc+9bQoYoSbe8sfihGSN5OsjKQlkM0zwsoIIaYQkzQ+twNt9R718zz3lDcUIyRvAhQjadHTponGZUSYXEuIbsQ5ptHnhsvpUEfn2aopbyhGSN5oDaw8ISQZz9Km8XmSLz1WRwjRj2h/NiQqjs11bgAc7y13KEZI3tDAmp5sCawepwMOSfl/+kYI0Y9o0zTWKCKkuUZp1YxyoqasoRgheTMR1o72RrPcsnqQZTlrm0aSJPpGCDHBmKZNAwDNtcp/h1mVLWtMiZFt27Zh3rx58Pl8WLduHfbs2aPr+x5//HFIkoTbbrvNzK8lNkVbGRmbjECW6WqfjMQgzP3pxAiQnKihGCFEP9PaNLVKZYRZI+WNYTHyxBNPYMuWLbjvvvuwb98+rFixAjfffDP6+/uzft/p06fxD//wD7juuutMHyyxJ1oxEo7FEWTEuVoVkSSgNiE6UuGyPEKMM71NQ89IJWBYjDz44IO46667sGnTJixfvhwPP/wwamtr8eijj2b8nlgshg9+8IP4whe+gAULFuR1wMR+aNs0AH0jgMa86nFBkqS0t2GbhhDjiL00qW0amufLG0NiJBwOY+/evdiwYUPyBzgc2LBhA3bv3p3x+774xS+io6MDH/3oR80fKbEtgZQre4qR7OZVgRp8RjFCiG7EXhrRpmkSlRG2acqazGfKNAwODiIWi6Gzs3PK5zs7O3H48OG03/Pss8/i3//933HgwAHdvycUCiEUCqn/HhsbM3KYpMhoR3sBihEge8aIINmmYVuLEL2ktmlahGeE552ypqDTNH6/H3/5l3+JRx55BG1tbbq/b+vWrWhqalI/enp6CniUJF8mUiojLJcm2zR1WcQI2zSEGCfZphEGVkWUjPK8U9YYqoy0tbXB6XSir69vyuf7+vrQ1dU17fYnTpzA6dOnccstt6ifi8eVq0CXy4UjR45g4cKF077vnnvuwZYtW9R/j42NUZDYGCFGJAmQZVZGgGRlpCFbm4ZihBDD+EOZRnt53ilnDFVGPB4PVq9ejR07dqifi8fj2LFjB9avXz/t9suWLcMrr7yCAwcOqB/vete78Ja3vAUHDhzIKDC8Xi8aGxunfBD7Igys7fVeABQjgGYvTbbKCJflEWIYtTJSIzwjYrSXlZFyxlBlBAC2bNmCO++8E2vWrMHatWvx0EMPIRAIYNOmTQCAO+64A7NmzcLWrVvh8/lwxRVXTPn+5uZmAJj2eVK+iMpId3MN+v0hbu4F4A/lbtP4WBkhxDCqZ8QnPCPuxOeVzb1OR/rpNWJvDIuRjRs3YmBgAPfeey96e3uxcuVKPPXUU6qp9cyZM3A4GOxaTQgxMrPJh5fOsjICZN9LI2CbhhBjyLKsCT1TRIiYpgGU0MWWOk/a7yX2xrAYAYDNmzdj8+bNab+2c+fOrN/72GOPmfmVxMaINk1Xkw8AxQiQbNNk9YwkluUx9IwQfUyEY4gloo1Fm0Zs7vWHohieCFOMlCksYZC8CEfjiMSUk8PMphoAFCOAvjaNqIwwZ4QQfYgWjcuR3O0EAE21TGEtdyhGSF5or+q7m5XKCE8I+to09IwQYgztXhptsrHIGuHm3vKFYoTkRSDRonE7JbTWcZpGIO6X7G0a7qYhxAjqxl6NTwTg5t5KgGKE5IUwr9Z6XKqRjNM0xgyswSgTWAnRQ+okjYCR8OUPxQjJC2FerfM41b7t6GQEsiyX8rBKjiHPCCsjhOhC26bRwkj48odihOSFqIzUeJzq1UkkJle9D0JP6JnPQ88IIUZQ2zS+9G0aRsKXLxQjJC/UyojXhTqPUw0cqnbfyHiGKzgtzBkhxBhjwanpqwJxIcRI+PKFYoTkRSCUqIy4nZAkST0pVLMYicdlBBIVI12L8timIUQXwjPSMK0ywjZNuUMxQvJiMuVNt1mIkSq+QhGTNIDO3TSsjBCii+TG3qlipIVtmrKHYoTkhXjjrU28sYqRu2q+QhEbe91OCV5X5pcY2zSEGEOdpklp03Bzb/lDMULyIjnaq7yxsk2T9IvUeacGM6WiDT2r9ukjQvSQupdGwM295Q/FCMmLCbUyItZ5M2tkXMckDZBs08gyEGLWCCE5SU7TpK+MiM29pPygGCF5wcrIdPSKEZ+mhUPfCCG5SbZpUgysKZt7SflBMULyYiI01cBKMaIvfRVQto26nUobh74RQnKTKfRMbO4FGAlfrlCMkLwQBlZhxqQY0VRGsmSMCHwc7yVEN5lCzwBu7i13KEZIXiRHexNipJZiRG+bBuBEDSF6CUZiqrcqtU0DaFNYq/fcU85QjJC8CGQwsFbzwiq9bRqAWSOE6EW0aID0r63kfhq2acoRihGSF5MZDKzVbCIbD5uojIQ5TUNINvwifdXrUtdOaFEj4QPVe+4pZyhGSF4EVDFCA6tArYwY8YywMkJIVpJ7aaa3aIBkm4aekfKEYoTkRabKyOhkpGqDvOgZIcR6RLU10/JJ0aZhJHx5QjFC8iKgbu2dKkaicVnNIKk2AkbEiPCMVOl9RYhehGck3SQNwM295Q7FCMkLkTNSk2jT1HqccCX6udXaqvEbaNOwMkKIPjLtpRFwc295QzFCTBOJxRGOKcbLusQVviRJyRG7Kj0piDZNnY7KCD0jhOgjW8YIoN0YzjZNOUIxQkyjbcMIAyuQNJhVqxgRbZoGXW0a5SXI0DNCspMpfVXQUkcDazlDMUJMI95AXQ4JHs2elWrPGjGSwCraNMwZISQ7mfbSCMTm3uEAKyPlCMUIMU0y8Mw55fPVnjUiruDqPPSMEGIVOds03Nxb1lCMENNMpmSMCKo5ayQSi6uR1ZnKyVp8Hu6mIUQPudo0TdzcW9ZQjBDTCG9ErTd9ZaQaxYi4TwB9BlZWRgjRR642jZube8saihFimomUwDNBNYsRcfXmdTngduZ+edEzQog+xiaz54wA3NxbzlCMENNMsE0zDeGj0dOiAZKhZ6yMEJIddTdNltcWN/eWLxQjxDRq+iorIypGNvYCmpwRekYIyUqu3TQAN/eWMxQjxDS5DKzVWCr1Gwg8A7SeEW7tJSQTsbisjsw3ZqmMcHNv+UIxQkzD0d7pGNlLA2h207BNQ0hGRMURABqyeEa4ubd8oRghphF7aaaJkSqOgx/PMX6YSg3bNITkREzS+NyOKQGLqTTXcHNvuUIxQkyjGli9mQ2sslxd4UNG9tIA3E1DiB5GcwSeCVgZKV8oRohpJkSbxp2+TROLywhU2RX/uMk2DcUIIZnJFXgmEJt7hzlNU3ZQjBDTZKqM1LidcDslANXXqlGnaQy2acLROCOsCclArsAzATf3li8UI8Q0ExlGeyVJUpdWVdu8v1oZ0bGXBkiKEYAmVkIykWsvjYBtmvKFYoSYRlRGalLECAA01ShvxtU2729kYy+gJLUK2KohJD2G2zTc3Ft2UIwQ0wg/SLrttNU63mvUM+JwSPC5lZchJ2oISY/uNg0395YtFCPENBOh9DkjQPWmsBpNYAW4n4aQXOjZSwNwc285QzFCTJPJwApUsRgx2KYBuLmXkFzo2UsDKJt7xYUAfSPlBcUIMc1EhgRWgGLESGXEp6awMhKekHTobdMAyVbNMCdqygqKEWKa5NZeihGBGTHCyggh2Um2aXK/rri5tzyhGCGmiMVlhKLKlXxaA2vC1T46GZ32tUpFluXkbhozbRoaWAlJiz+kb7QXSEbCV9skX7lDMUJMIVo0QKbR3uqrjISicURiioPfUGWEy/IIyYpaGanRXxkZYWWkrKAYIaYQLRqnQ5qSlSFoqsIkRNGiAdJXizLB/TSEZEf1jOipjKieEYqRcoJihJhCtCNq3U5IkjTt69VYGRH3SZ3HCYdj+n2SCbZpCMmMLMua0DP9bZpquhCqBChGiCmSY73TWzRAdYoRv8G9NAIaWAnJzEQ4pgaYGWrTVNG5pxKgGCGmmMiSvgpoEliDUchydSQhijZNnQG/CAA1gZWeEUKmI1o0Loc0ZZdTJri5tzyhGCGmEAbWdOZVIClGYnF5ipeikhFtmgajYsTDNg0hmdDupUnXEk6Fm3vLE4oRYopclRGf2wGPU3l6VUurxkz6KsA2DSHZUDf26gg8A9imKVcoRogpsm3sBQBJktBUW12+EXEFZ2SSBqAYISQbRiZpAI72lisUI8QUok1Tl8HACmjHe6vjpGAm8Axgzggh2dC2afQgPCNjwQg395YRFCPEFIFQojLiznyCqLaJmnGznhGO9hKSEbVNo7MyIs47sszNveUExQgxxaSRykiVnBDUNo1BMcI2DSGZGQvqT18FuLm3XKEYIaYIqEvyWBkRmG7TqGKEW3sJSUV4RvQEngm4ubf8oBghpsi2sVdQbWLEbJtG9YywTUPINJIbe42LkWrxq1UCFCPEFMLAmk2MNFapGDEeesY2DSGZUKdpdLZpAG7uLUcoRogpJnS0aZqrVIwY2dgL0DNCSDaM7KURNHG8t+ygGCGmMDTaWy1ixOxuGrZpCMlIcppG/+uqhZt7yw6KEWKK5GgvxYgg6RnRfwUHsDJCSDaSbRoDnhFu7i07KEaIKUQmRjZ/RLUlsCY9I7mXeWkRYiQalxGJcaKGEC1GQ88ARsKXIxQjxBQBHQbWaqqMyLJsejeNz5N8GbI6QshUjIaeAclzDz0j5QPFCDHFpIGckbHJCOIVHss8EY5BTvyJRts0HqcDjsQyUvpGCEkSisYQiirVQiNtmpZEJPwI2zRlgykxsm3bNsybNw8+nw/r1q3Dnj17Mt72Zz/7GdasWYPm5mbU1dVh5cqV+P73v2/6gIk9MFIZicvAeOL2lYoIPHNIysZiI0iSRN8IIWkQLRrA2JQa2zTlh2Ex8sQTT2DLli247777sG/fPqxYsQI333wz+vv7095+xowZ+OxnP4vdu3fj5ZdfxqZNm7Bp0yb85je/yfvgSWmIxWUEE2mh2cSIz+2E16U8xSo9fMivGeuVJMnw94uJGooRQpKIFk2D1wWnQ//ript7yw/DYuTBBx/EXXfdhU2bNmH58uV4+OGHUVtbi0cffTTt7W+44QbcfvvtuOyyy7Bw4UJ88pOfxJVXXolnn30274MnpUH7hpkr4KtafCPjJrIQtHBZHiHTSe6lMfa6aqrh5t5yw5AYCYfD2Lt3LzZs2JD8AQ4HNmzYgN27d+f8flmWsWPHDhw5cgRvfvObM94uFAphbGxsygexDxOJKoAkQa18ZKJaxEjA5CSNgG0aQqbjV/fSGDOFi8oIN/eWD4bEyODgIGKxGDo7O6d8vrOzE729vRm/b3R0FPX19fB4PHjnO9+Jb33rW7jpppsy3n7r1q1oampSP3p6eowcJikwIn21zpO7JVEtYsRvMn1VoAafUYwQomJmLw3Azb3lSFGmaRoaGnDgwAG88MIL+Od//mds2bIFO3fuzHj7e+65B6Ojo+rH2bNni3GYRCd6zKuCahEjyfTVfNs0zBkhRGBmL40gOd7LiZpywNAj3NbWBqfTib6+vimf7+vrQ1dXV8bvczgcWLRoEQBg5cqVOHToELZu3Yobbrgh7e29Xi+8Xq+RQyNFZFLHxl5BtYgRIdDq2aYpO7614xjaGrx4/9o5pT4UkkKyTWNc5LfUuXF+ZJIm1jLBUGXE4/Fg9erV2LFjh/q5eDyOHTt2YP369bp/TjweRygUMvKriY0I6MgYEVTL5l4xgmi6TUMxYhgrrnjPDk3g69uP4r5fHKz4LJxyJNmmMf664ube8sJwm2bLli145JFH8L3vfQ+HDh3Cxz/+cQQCAWzatAkAcMcdd+Cee+5Rb79161Zs374dJ0+exKFDh/D1r38d3//+9/GhD33Iur+CFJVJtmmmkYyCz9MzwmkaXTy5/xxWfnE7fvCn1/P6ORdGJgEA4Vgcwyzn2w4ze2kE3NxbXhg+c27cuBEDAwO499570dvbi5UrV+Kpp55STa1nzpyBw5HUOIFAAJ/4xCdw7tw51NTUYNmyZfjBD36AjRs3WvdXkKIiluTV6njjba6S/TTihCeuxoziY2XEEE8fHgAAvHh6CB9641zTP6d3LKj+/+B4GK31bA+nYzwUxf99+QJuWt6FGXXmnuNmMLOXRtDMSPiywtRl3ObNm7F58+a0X0s1pn75y1/Gl7/8ZTO/htiUCVEZybKxV6CNhK9khgPKVfWMOnMGVrZpjHHwwigA4OJoMMcts9M7qhUjISxFQ14/rxIJR+P46GMv4PlTQzjc68d9t1xetN9tZi+NgJHw5UVV76Z54DdHcOeje3C4lzkmRhCjvbU6zJrVsrBqKHHCazF51ViTWJbH0LPcTISjODUYAAD0jeUpRsamihEyFVmW8dknX8Hzp4YAAK+eHy3q78+nTVPOkfAvnR3BG/9lB/7vyxdLfShFo6rFyO6Tl7Dr6ACO94+X+lDKioAmZyQX1eIZUSsjtSbFiJs5I3o5dNGvLiW8OBqELJs3nmrFzICfYiSVh3edxE/2nlP/fbRvPK/72yj5tGnK+ULoNwd70TsWxHd+f6LUh1I0qlqM9LTUAADODk2W+EjKCxpYpzOcZ2WEnhH9vHYxWckMReN5vdlcHJ3qGSFJnnr1Ir7y1GEAwGffcRkckvI6LqZoy6dN01zGbRpRpXv53Cj686z+lQvVLUZm1AIAzg1PlPhIygsjo72qZyQYqdjRyXhcxnDiDdGsuU9dlMc2TU5euzC1VZCPb6RvlG2adLxybhSfeuIAAODO9XNx15sXYG5rHQClOlIszO6mAYCWMm7TaIXxM0fSL6GtNKpbjLQoYuTsMCsjRjASeiZOIrKcjEyvNPzBqLqMS/SpjUIDq35euzDV42XWNxKPy+jXXOVTjChcHJ3ER7/3AoKROG5Y2o7P/Y/lAIDFHfUAgKN9/qIcRywuqyPzpnJGyni0V/tcfPowxUjFM3uG0qY5N8TKiBHEUjg9Blaf2wmfW3maVepEjTCv1ntd8LryS2ANRRgHn41oLI7Dvcqb4cJ25UrdbGVkMBBCVFOtoxhRXtsffexF9PtDWNJZj2+9fxVcTuX1u6RTmTQ61l8cMSJWLADmEljLeXPvoEYk/+HYIELRyr9IqWoxIioj54YnK7aFUAgmDFRGgMr3jQwFhF/EXFUEAHweVkb0cHIwgFA0jjqPE2vntwIAekfNVTb7RqeKj2o3sMbiMj75+AG8dnEMbfUe/PudV08RAYs7RWWkOG0aMUnjczvgybEdPB1NmqpsOV0IybKstmm8LgcmwjE8f3KoxEdVeKpajHQ3+eB0SAjH4lPKtSQ7as6IDs8IUN6udj3kO0kDsE2jF5Evcll3I2Y1+wBMHc81wsWEiOloUILOLo2Hq/qi5P5fH8LvDvXB43LgO3+5RvXUCURl5GifvygTNepYr8nlkx5XeW7uHQtGEY4pFdJ3vKEbQHW0aqpajLicDnQ3KSe0szSx6mbCwGgvUAWVkTwnaQCNGKGBNSvCL3L5zEZ0NiqvXbNtGuE1uXxmIwAgGpcr9jmaix/tOYNH/nAKAPDAX6zA6rkt026zoL0OTocEfzCKvrHCX7yJvTRmxnoF5bi5V1ToGrwuvP0KZQHtjsN9RR2pLgVVLUYAjYmVvhHdCDFSwzYNgOSJLp/KiI85I7o4mBAjy2c2ortJ8Xz1mhQjoqLSM6NWNUhWo2/kTycv4XM/fxUA8OkNS/CuFTPT3s7rcmJuq3K+LIaJNZ/AM0E5mljFc7CtwYtrF7XB43Tg7NAkTgxUdh4WxcgMZo0YRbRp6nQYWIHK39w7FFD+LksqIxQjGZFlWc0YuXxmE7oSVU3TYiThGelq8qEt0aoZqEIx8u/PnkI0LuOWFTPxdzcuynrbJR3JVk2hEYFnZts0gCYSvow296pipN6DOq8Lb1yoeKN2HKrsVg3FiDrey8qIXlQDq5ttGiDpGWkxOdYLAD4RBx+JVXw51iwXRoMYmYjA5ZCwuLNeFSP+UFQdATVC75hyAdLV6ENbYkFeNQafiVCtW1fMhCRJWW+7JGFiPVYEE6swnebVpinHyohfiBHlOXnjsg4AwI4K941QjDD4zBDxuGxoNw2Q3GRbqWLESs+ILCupomQ6wi+yqKMeXpcT9V4XGhIGRTPVEfE9XY0+tAsxUoVGdiPP38XCxFqE8V5L2jRlaJ4XgliIkbcmxMje14cxWkZ/h1EoRtimMYS2jaB/tFd5wyin8TojWDFN49NsQKZvJD1ikmZ5wnAKIK9WjTBhdjb50FavPHbV6BkZSrz5teoQI2Ki5ngRdtRY0aZJekbKp+KVbNMoYqRnRi2WdNYjFpex69hAKQ+toFCMJNo0F0cnEYnxijQXoioiSYBPZ8CXWioto76tEayojLidDridSomcvpH0JCdpmtTPqWLE4HivPxhRWztT2zTVJUaCkZi63mFGfe7n7/y2OrgcEvyhaF4x/Hqwok0zo055XIfKqKIgnoPtCR8TALx1WScA4OlDfSU5pmJQ9WKkrd4Lj8uBuAxcHKmOhUT5oGaMuJ1wOLL3lwXV4hkxu5dG4ON4b1bUSZpuTWWkUVRGjFU2xVhvg8+FOq9LNbBWm2dELHh0OyW15ZUNj8uBeW1iR01hWzVWtGnUilcZtd8G1DZN8nwiWjU7jw4gWqEXzVUvRhwOCbPF9l76RnKSHOvVf7VSyWIkFpfVQKWWPNo0ACdqsjE6EcH5EUVwaNs0IifI6FW6OkmTEDPtVVoZuTQuzNeenOZVQbFMrMk2jfnKSGuiMnIpUD6Pq2pg1VRGrprTjKYaN0YmIth/dqRER1ZYql6MAMwaMYLRsV5AI0bKqFSql9HJCETr3OySPIHIbaFnZDoHLyp+kdktNerzCQC6TGaNiLaOaPOoo71ldAVtBaIyYqSqt7hI4735JrACQGuiunCpTCpesiyr4+VCIANKQOcNS9sBVG4aK8UINCZWVkZyolZG3PrFiCiz+kPRosVtR2JxbPzObtz7i1cL+nvEXppGnwtuZ34vp2QKa2WWYfNBm7yqpdukZ0S0aUSKa5vmTauaRquHTLQYkwvzClsZEQmsjTV5VEYSj+vQRLgsluX5Q1GEE9N0bRoxAiRbNU9XaN4IxQi0lRFO1OQiEEpEwevoLwu0C6v8QeN5EGY42ufH86eG8KM9ZwoqgMxcWWbCxzZNRl5T/SJNUz7f2WhumkbspRFiRpz4w7G4+iZYDYiKgTExorRpjvcXdqLGb0FlZEatB5KknHuGy2CiRrRo6jzOaQnX1y9ph9Mh4UifvyKr+BQjSGaNsDKSm+SSPP2VEa/LqV71F8s3IsrtkVhh940kN/bmL0boGclMMnk1fWXkUiBsqL0lPCNCzPjcTtXAWU0prGbE9Ly2OridEsZDUVwo0ESNLMsYC4rdNObFiMvpUL1c5dCqUTNGGrzTvtZc68HqOcrOoGeOVF51hGIErIwYQQ08MyBGgOKbWLVTEYV8c7EiY0SgekY4TTOFYCSmtgSWp4iR5lo3vIn18v0GlreJNo0wsALQTNRUjxi5ZKJN43Y6ML/AEzUT4ZjaVsmnTQMk81PK4XFNzRhJ5a2XJVo1FegboRhB0jMyOB6ieTAHqoHVwDQNoNmeWaSsEa0RsZCmxOGJ/PfSCFgZSc+xvnHE4jJaat1qJUQgSZIp30iqgRVAVQafmR1LF0msxwokRkQ71+WQDPnT0tFaRo+rdi9NOkQ0/HMnLqnn4kqBYgTKG6Uo0TIWPjtGN/YKil0Z0QqQfn/h8mPoGSk82uTVdOOnotVyUWfWSCQWV0/6U8VI9UXCm6mMANqFecZMrJFYHB/+jz34m++/mPXCT0zSNPhcukeOM9GaeFzLok3jnx54pmVRRz16ZtQgHI3jj8cvFfPQCg7FCJSrq9kz2KrRgxAjRgysQPE392qvggpZGRGekXzHegGgRizLY5tmCtpNvenoNhgJ3+8PQZaVoC9te60al+WZmaYBtFkjxiojL5waws4jA/jNwT78r5+/mtEAK9JX8wk8E7Ql/rZyyBoZSNlLk4okSbhRpLEerqw0VoqRBAw+04coDRotnZayMlLQNo2VnhE3c0bSkS55VYuaNaKzTSNES0eDb0qKcDVGwufdpukfNzSttl0TZ/7Tvefw78+eSns7K/bSCMqqMpLDMwJoRnwP91fUGDrFSAIGn+ljQh3ttbkYKVZlxIK9NAJ6RqYTj8s4lKiMpJpXBV2Nyolbb2WkL41fBADaGsrHW2AF8bhsus04r7UWHqcDE+GYmoybC1mW8buEGHlLIsDrX/77EHammQzRtmnypZwqXuJclU2MrFswA7UeJ/rGQqpQrwQoRhJwe68+Aupor7GThGhjFGtzr/YNpb8YlRErPCMe7qZJ5fSlACbCMXhdDixITHCkIiojeiPhhWhJFSMi8XKgDN60rGB0MgJR1DC6ysDldGBBu/J4HOvX16o51j+Os0OT8Lgc2PbBq/DeNbMRl4G//dF+nBiY6j1R2zSWVEbKR2Qml+Rlfjy8LifetKgNQGVN1VCMJFArI2zTZKUcRnvD0ThGNNHzxfCM5LuXBmBlJB3CL7KsqwGuDAm3Rj0jvWnGegHNaG+VGFgv5ZkeLFo1ek2s219TqiJvWtSGWo8LX7rtCqyZ2wJ/MIq7vvfilHURImMk37FeQJOua3PPiCzLuto0AHBjYsR3B8VI5aEGn7FNk5WkGDE52luE/TSpJ51C5YxEYnH1pGlFZYSekemofpEM5lUgKUYGxkO6NpqqlZHGTJWRUEX14jMhhHRrjje+TCzuUEyserNGRItmw2WKAdPrcuLbH1qNmU0+nBwM4G8f368+fsk2jQWVkbry8IwEwjEEI+mj4FN5y1JFjLx0dqRi9ilRjCQQBtaxYLQit8taRTlURsSLUxzjyEQEoaj1b/BCWEkSpixvM4sYl2ZlJIkaA5/BLwIob6ZOh4RYXNblCxCVkc5Uz4iIhI/G4Q9VVoZDOpJVPXPPXSPbe/v9QRxIbJsVV/WAMsL6yJ1rUON24vdHB3D/rw8D0OylsbBNMxGO2TqbQ1TkatzOnNOKHY0+XDlbEejpPDflCMVIgjqvS03qY9ZIZsxs7QWKO9orxMiCdiW2GiiMeU2Y/5pr3HA68stCADQ5I/SMqBzMsCBPi9MhoTPRYtGTNSIMrKkBajUeJ+oSgrAaWjXJsV6TlZFEm+a4jomaZw73Q5aBK2c3qbkwgstnNuGBv1gBAPjus6fwkxfPJvfSWNCmqfe64Emk9Nq5OqK2aLL4RbRop2oqAYoRDcwayU1ya6+5Nk0xxMigZgW3WnovwJuLlXtpAK1nhFt7AeVqenA8BElSPCPZEGbUvhzjvbIsq0bX1DYNoI2Et++bllUkJ2nMVR/mzlAmaiYjMZwbzn7O3P6a8oYpWjSpvPPKbvzdjYsBAJ998lW1imJFm0aSJPU8IHwydkR73tLDuvmtAKBOm5U7FCMaehKtGlZGMjMRMlcZEWLEH4wWfJX3gCbFUCQZFkKMWJkxAmh207BNAyBZFVnQVpfToyTESK6JmpGJiLqivaNx+km/mrJGkht7zVVGtBM12XwjwUgMzx4fAJBZjADAp25cjD+7vAvhWFwVN40WjPYCmokaG1e8cgWepSKe85UinClGNMxm1khWZFnGRCQ/AyuQXA1eKMSLs9BixMqMEUBTGWGbBoDWL5LZvCroakwEn+UQI8IvMqPOA69ruqCupv00Qwmjd2sez98lYqImy3jvH48PIhiJY1ZzDS7rzlzhcjgkfP29K6ZUwaxIYAWSf6OdJ2rUjJEMUfCpiHPbeChqay+MXihGNKhZIzlKjtVKMBKHGDIwamD1uBzq9xS6VaMNDmpvUK4eCrGfRhhYraqMcDfNVF7T4RcRdOusjKjm1TQtGqC69tMMWbDkUY+JNTlF05Fzz0yd14Xv3rkGrXUeOKTklGO+tJZB8JnesV5BncepXsAM+u37d+nFmhpYhcAU1uwENOrbzCbNpho3JsKxoomR9gavulW3LDwjnKaZgsgYyRQDr6VL5+bevtH05lVBWxUFn1lRGUlmjaSvjMTjMn53KOEXWZ65RaNldkstfv2p69A/FsKs5hrTx6ZFtGlsbWAV560MG3tTkSQJ7Q1enBmawMB4EHNarRFupYKVEQ1ChZ8bnqyKnAGjTKrmVeeUnR56KVbWyBQDaxE8I2ZHI1MRAi8cjRfcV2N3xkNRnBoMAMg+1ivo0hl8JionGSsjDdXjGRkOWFEZSU7UpHvOvnx+FAP+EOq9LtVwqYeOBh+umJW7PaeXNpE1YuM2jdHKCICCnt+KDcWIhpnNPkiScmVq53JeqQiYHOsViEj4oQI72rW91w7xYi3Am0uhPCMATayHE1WRzkavrpOzmIzpHQ1mvZDoy5C+KmivJgOrBZWROTNq4XU5EIrG01aUf5dIXb1+Sbs6XlsKyqIyIgysOj0jQNLjRDFSYXhdTvUkxVj46ahjvQb9IoI5icrT6UsBy44plWAkpgZWaQ2s/WP2n6bxak7W1d6qSeaL6Ls6FpWOcCyeVeyqUfBN6U/47VWyLG8iHFXTPvMR006HhIXtmZNYVb/I8o5pXysm5TAlxcoImYLwjeSam69G1I29BidpBPPblJOWKL8XAvGi9LgcaPC6ChrxbXVlxOGQ4HMrL8lqn6hRJ2l0+EUA5fEWV4nZfCPJJXnpvQhtmlyaSm7VCsHmcTnUoDezqCbW/qkm1rNDEzjc64fTIanx5aUiuSzPnpWRiXBUvdhr0+kZAYD2erEKwZ5/lxEoRlKYrW7vZWUkleTGXnMnr/lticpIIcWIxi8iDF6A4sMQe2SsQvTcrdhLI+B+GoWDF0cB6JukEejxjWRakicQYiQYiSNQwYJQ3UtT58k54ZKLTCbWHYmqyJq5LWi2qHpoFvG4DgVCOdNiS4GYhvG5HajPEQWvhZWRCiZZGaEYSWXS5JI8gaiMnBwMFOyqc1AzSQMo47IiOMnKF2woGsN4oh1kVZsG4OZeQFlAeLRXucrWY14ViKyRTOO9wUhMNU9nEiN1XpdmXLL8T/CZsHLb9JIM23vFFM1NOqdoCon4O+MyMGLD3WMDmhaNEXHYXkBPXLGhGElBLMxjJPx08q2MzE2MnvmD0YKZWAfS9F1V34iFWSPiTc3pkNBgUUokAPjUFNbqjYQ/3j+OcCyOBq9LvTjQQ3eOSHjxeZ/bkXXnSVsV+EaSG3utECPKRcaJgeREzVgwgj+dvAQAuDFL6mqx8Lgc6jTfJRs+rtpsJCOIc1slCGeKkRTEeC8NrNOZNLmxV+BzOzEz8YZRKBPrQEplRPv/VlZGtBtPzYw5Z4KVkaRf5LLuRkP3ba5I+F41Y6Qm69VnOZgd88XKykhPSy18bgfC0TheT7yudx0ZQDQuY2F7Hea31eX9O6zAzr4RM+ZVYOq5rdw9ThQjKQgxcmFksuqzHlIJJAystQZ6mqnMT+yyODlQGDGiZoxMESMJk5eFYmTYwpO5FkbCa8LODLRogKnjvelIpq9mP+FXQ/BZcmNv/s9fh0PCog4xUaO0apJTNKWvigja1GV59hOZyfOWscdDmF3DsTjGJss7Ep5iJIWuRh/cTgmRmJwzzbHamIgk2jQm0lcF81oVMVLwyoim/FyIrBGrJ2kEvio3sB7v9+MnL54FoKybN0IyEj59i7U3y7ZeLdUQCa81sFrBkg7FN3Ksz49ILI5nEmvtb7JBi0bQZuNleWYrI16XU20/DYyX9/sVxUgKToeEmc2cqEnHhBWVkUTJtlDjvdoleQK1lGlh1ojVGSOCat5P0+8P4s5HX8BYMIqr5jTjHW/oNvT9napnJP3jrFZGMkTBC9qrYFneJYtXGagTNf3jePH0MMaCUcyo82DVnBZLfr4VtKoprPareIlpGqNiBNB64sr7+UoxkgbuqEmPmsCaRy5BUowU5r5NZwTTZo1YxbAFS8bSoe6nqbI2TSAUxUceewHnRyYxr7UW373zalWY6UVUPMZD0bSboYWBtTtXZaQKIuGHra6MqAvz/GqL5q3LOuC00E+VL5XoGQE057cyFyNclJcGbu9NT74GViApRk4nxnvzzThIpdgG1hl11uylEdSI0LMqqoxEY3Fs/s99ePX8GGbUefDYprWmvAx1XhcafS6MBaPoHQ2iwTf1sbmoBp7lqozYf8Nrvli95FGM954cCKgXLRts1KIBkpt77ThNkxQjxh+PSskaYWUkDbOZNZKWQJ45I4BiEHY6JExGYhnL6WYJhKLqm7j2CqOj0foy5vBEYQ2s1eIZkWUZn/vFQTxzZAA+twP/fucazMtj+qI7kayazu/Vl2NJnqAaKiPC82RVZWRWcw1q3E6EY3GcHZqEx+nAdYvbLPnZVtGW+Ftt2aZJ017WixVZIz9+8SyeeOEM+kvok6QYSYO6vZdZI1OYzDNnBADcToea5WK1b0RcGdR6nKjT+Fra1fTFMCIxa/I7rByN1OKrsjbNv+08gR/tOQNJAr7xvlV5eww6M4z3xuOyKkZzVUbaKqTsnYloLK7m5FiVHuxwSFicaNUAwDWLWqe8Bu2AEJl2q4xMhpMBikaW5AmsqIxse+Y4/un/vILTl0p3AU4xkoYeEXzGysgUrBjtBQpnYh1IM9YLKIJB9K6t2topKiNWRsED1ZUz8vP95/G13xwBAHz+lstx8+Vdef/M7gzjvYOBEKJxGQ4pKU4zIUrlE+EYJsLlPS6ZDuF3kiRYGtO+ODFRA9ivRQMkq0B2a7+JCpzYp2WUfMVzPC7j4ojyepnZnF2oFxKKkTSINk3vWBChaOW/KehFvEHmUxkBCjfeO5ghxdDhkCxftS320lhuYK0SMfLciUH8409fAgDcdd183HnNPEt+bqbgs77RpFB1ObOf9uq9LnWDsphyqCSEkG6ucVtqMF2iqYzceFlpF+OlQ3hGxkNRW7VBU/dpGSXfyshgIIRwLA6HlLuFWUgoRtLQVu9BjdsJWQYujJT37LaVBEL5t2kAYEF7gSsjaa58OxLBZ1ZFwg8VaLS3xlP5npGjfX78zff3IhKT8c43dOOet19m2c/uyhAJL7JHcmWMAIAkSZrgM3uV9K1AVAetFtJXzVVabKvntqjeHTvR6HPB7UxUSG3kG0leRJl7PNrzTAwW73GdjT64cwj1QkIxkgZJkjQ7aiq3VROJxfGtHcdwuHdM1+3Fiuu6PAysQLIyYrUYSV2Sp8VKx/lkOKZWLlosnqbxVXgCa99YEB9+dA/8wSjWzG3B19+7wtI4/YyVkTF95lVBJZtYhy02rwqunjcD//lX6/DtD15l6c+1CkmSklkjNnpcRdvIzFgvkDy3XQqEETXhibswogj17hxeqkJDMZKBathR8/P95/H17Ufx+f86mPO2siyr/fN8KyPCM3Lm0oSlkfvpluQJrJzFFydzt1MytO5bD5Xeptn8n/twYTSIBe11eOSONYazRHIhTqi9KSmsYroml3lVUMnBZ5csjIJP5ZpFbegoYak/FyJrxCrvmBXkkzECKI+jQwJkGaYWkAoxIsI+SwXFSAZ6qmB7r9gB8sq5UcRziIJQNA5xk3wNrDOba+BxOhCOxdUXghWkyxgRiPFeK8ru2kkaq3NSkmKk8rb2Hu4dwwunh+FxOvDYh9da3iYAgO5G5XU7PBGZ0urqHdU3SSNIRsLb503LKobGCydG7E6rDZcgqmLE4F4agdMhqX+XmfgC0aaZRTFiT6qhMnK0zw9AyQ95PUc7akLTNqjJ82rW6ZAwp1W5f61s1QxkmdVXI5MtyDYp1CQNoPGMVGCb5uf7LwAAbljarj7+VtNY44IvERyn9Y30jun3jACVvbm3kM9fu9NmwxTWfCsjQH6+EVZGbE4y+KxyKyNHesfV/z94YTTrbYV51ed2WOLAV5NYLZyoyWYEszISvlAZI0Dl7qaJx2X88iVFjNy2albBfo8kSap5Uusb0bskT9BWBW2aQjx/7U6bDVNYRfXNTOCZIB9P3IVRihFbIyLhz1WogfXSeGjKifbghewmVvHmmK95VSDEyMkBa8SILMtZ2zRWGliHC9hzr1TPyIuvD+P8yCQavC68dVlhxz670mSNiLTfXEvyBO2J6atKFCPqXhqT0xvlTKsNU1gtqYzkkcKarIzQwGpLRGXkUiCsVgUqiaN941P+nUuMiPugJk/zqsDqrJGxYBThhJM83YtajPYO+EOQ5fxMs0PqkjxrJ2kAoM6r3L8jE2Gct9BPU2p+fuA8AODPruiy3LSaimpiTbRp/MGImnBpvDJinzctq0gaWM2/+ZUrdvSMpFvuaRSzF1vBSEx9jtMzYlOaatxo9ClVACtaNbIs41s7juHXr1zM+2dZgfCLdCSexK9dGM36Jm3VWK/A6hRW8SJs8LnSvtkJc9hkJBm9bJaRicJkjADAnBm1WNHTjEhMxqcfP2DptFGpCEfj+O/E8/7WlYVr0Qg6m6ZWRoR3pMHn0h1R3lYhy8fSMRRQ/qZCPH/tjt2maYKRGPyJ81GuZOBsmJ0WFK3MGrcTTTXWX1wZgWIkC6qJ1YJWzbH+cXx9+1H8z5++nHNypRgcSYiR/3HlTDgk5QowmxNbiBGrKiNCjJwbnrRkX8xghih4Qa3HpY7h5vsGIzwjVkZpCyRJwjfftxJ1Hif2nB7Cvz1z3PLfUWx2HR3AyEQEHQ1erF/YWvDf161mjSgXEeokjYGR0zabpnXmiyzLanrwjCps07SJnJGAPUSmGgXvdKCxxvyFntnKyEVNi8bqyUCjmBIj27Ztw7x58+Dz+bBu3Trs2bMn420feeQRXHfddWhpaUFLSws2bNiQ9fZ2oqfFuokaoUD9oagtyu9HexUxsqKnCQvalRjnbCZWkTEi2gj50tnoRY3biVhctkTs6Sl1WuUbKfQ0wtzWOnzptisAAA/tOIa9rw8X5PcUC9GiuWXFTEvjxzOR6hkxmjECKGmdnkQaZSVVR8ZDyXZmNVZGRIX00ng473atFYgWSWt9fjEBZj0j520ySQOYECNPPPEEtmzZgvvuuw/79u3DihUrcPPNN6O/vz/t7Xfu3In3v//9eOaZZ7B792709PTgbW97G86fP5/3wRcaYWK1ImtEu5r50EV9iaeFQpZltTKytKsBl89sBAAcPJ/5uNTKiNuaNo0kSeqqeCtaNdnMqwIrVm0DwFCB9tJouX3VLNy6ciZicRmffHw/xoKRgv2uQjIeiuJ3r/UBAG4rQosGSIoOIUJEm8ZIZUSJhK+8iRpRFalxOy2rcpYT4gIiGpcxOln611SmfVpGMXuhZZeMEcCEGHnwwQdx1113YdOmTVi+fDkefvhh1NbW4tFHH017+x/+8If4xCc+gZUrV2LZsmX47ne/i3g8jh07duR98IXGyqwR7Rvg4URVolT0jgXhD0bhckhY0FafFCNZTKzCwGpVZQQAFlgoRgaz7KURWJU1MlygvTRaJEnCl267ArNbanBueBL/68lXbXElZ5TfvNqLUDSOBe11uGJWY1F+pxAj/f4QIrF4ci+NwbjrZCS8PfwFViDaE9WYMQIAXpcTDQkvoB0e1+QkTX6Phzi3+YPG2op2yRgBDIqRcDiMvXv3YsOGDckf4HBgw4YN2L17t66fMTExgUgkghkzZmS8TSgUwtjY2JSPUqC2aSxsIwDQvQumUBxJiKH5bXXwuBy4fGYTAODgxcxtGrErpdYiAysAzGuzLvhMV2XEgqwRWZYxNCEWjRXW8NXoc+Mb71sFp0PCf710AT/bZ/9qYiqiRXPrillF60m31XnhckiQZeV5ITwjRjeSVmLw2VABx9LLBTtljVgx1gsADV4XPC7jbUW7ZIwABsXI4OAgYrEYOjs7p3y+s7MTvb29un7GP/3TP2HmzJlTBE0qW7duRVNTk/rR09Nj5DAtQ80aGZ7M+6p0ihi5WNrKiBAjS7oaAECtjJwdmsxYugyoYsS6yoiV471GKiP5eAAmwjGEo4meexFO6KvntuBTNy4GANz7i1dx2uLlgoWk3x/EH48PAgBuXTmzaL/X4ZBU4XFxNGiqTQNoxnsryDNCMWKvrJHBLKnRRpAkydTF1nmbZIwARZ6muf/++/H444/jySefhM+X+Y+/5557MDo6qn6cPXu2iEeZRGSNjIeiefcXtW+Apy4FSrqVVfWLdCpipLnWo/YMX8vQqlENrBaKkQXtCTEyaF0bLNt+hw4LxIg4mXtdjrxj8fXyibcswtr5MxAIx/DJx/dbMn1UDH710kXEZWBlT7PqDyoWoiXTNxY0ZWAFWBmpVJLjvaV/XLMt9zSK0YstWZaTbZqmMquMtLW1wel0oq+vb8rn+/r60NXVlfV7H3jgAdx///347W9/iyuvvDLrbb1eLxobG6d8lAKf26k+wPmaWLVqVZaTOR+lQPzuJQkxAgDLVd9I+lZNcrTXwjZNojJyfmQy7/FJtU1Tn/kNR/WM5CFGtJM0xWo7OB0SHtq4Eo0+F146N4oHtx8tyu/Nl18kWjS3FbEqIhDC4+zQhComzIuR0l9BW8VQFe+lEdjpcVWnAPOsjADGxcjIRATBxEJOo6+NQmBIjHg8HqxevXqK+VSYUdevX5/x+7761a/iS1/6Ep566imsWbPG/NGWAHV7b54mVvEEEaXiUvlGYnEZxxLpq0u7kmJEtGpyVkYsNLDOqPOowXKvXzJ//8bjshpipGuaxoLKSLH3esxsrsH971ZE/MO7TuC5RPvDrpwaDOClc6NwOiS888rii5HuxOvs5fOjkGXA7ZQMG46tmr6yE9W8sVdgpxRWqwysgPHzm2jRtNV7C56KrAfDbZotW7bgkUcewfe+9z0cOnQIH//4xxEIBLBp0yYAwB133IF77rlHvf1XvvIVfO5zn8Ojjz6KefPmobe3F729vRgfH8/0K2zFbAtMrMFIDP6g8mZ+3eI2AMChEvlGzgxNIBSNw+tyYM6M5OZU1cSaUYyI0V7rnrSSJGmSWM0/H0YmI4gmguSy7dsQL9ahQMh0smkpN56+4w3deN/VPZBl4NM/PqBO9dgRURW5dlFb3v1wM4grvQNnRgAo6wAcBjNO2KapTNpslMI66M/tddOLUc+IaNHMsoFfBDAhRjZu3IgHHngA9957L1auXIkDBw7gqaeeUk2tZ86cwcWLycjzb3/72wiHw3jPe96D7u5u9eOBBx6w7q8oILNapm8ANYpQqh6nA2vnK1NEpaqMCPPq4s76KQFUojJyfGA8bctkIpSIg9cZp62XZNaIebEn7t+WWjfczsxP6dY6LxwSEJfNJzAWI2MkG/feshwL2uvQNxbCP/2fl2057ivLMn5xILGhtwQtGiApRsTVX7eJMnR7wn9USaFnbNMo5wGg9CmsoWgMY4mL1FJ4Ruw01gsApt5ZNm/ejM2bN6f92s6dO6f8+/Tp02Z+hW0QbZW+sTzEiCaq/LJu5U3/cK8fsiwXPYI3nV8EUE7WLbVuDE9EcKTXjxU9zVO+PhFRXjRWTtMAyVj4fKZEckXBC5wOCa31Xgz4Q+gfC6nL84yQzBgpzR6HWo8L33zfKty27Y/47Wt9eP3SRNHNobl4+dwoTg0G4HM78LbLs3vJCkWq+NC7rVeLeIMQ2Q12KGXnCysj9tlPI36/yyFZshfGsBhJXGDbRYxwN00OOhuVB7g3HzGiMSkt6lAqEiMTEXWteTFJnaQRSJKUtVUjKiNW5owA1izMM7L1Mt+sEdGmKcReGr1cMatJnUSyYomj1YhskZuWd6n7gIpNV8p0gNGxXkBZlul2KhcLdhgDtQKKEdgmWVf8/tZ6j+EWYjraG4y1Fe0UBQ9QjORE5BX0WdCmaU8YhUTy6KEStGqOpmSMaLl8VuaJmkC4sJWRU3lkjeitjABAR2N+JtZSeka0iOdlPiK5EERjcfzyJaVNW6oWDaCMcWuLjmbEiCRJakm/ErJGwtG46l1rrWIxIh7TsWBUzQwqBVYFngm0m3v1tG/VJXk2mKQBKEZyIk76/f6Q6W27qemgyxKtmiNFjoUPRWNqBSK1MgJkN7FOFCD0DEh6Rgb8IfhN7l8xVRkx+eaiTtOU+GQu2hC9o/aqjOw+eQmD4yE017px3eL2kh2H2+mY8nww06YBkrk1pb6KtgIhpJ0OCY2+0q6LLyVNNW64HKLiVbrHddCvPB6WiZHE+0soGoc/sb4jG2IvDSsjZUJ74gorGpdNl2oHUq7clyWqEoeLvDDv1GAA0biMBp8rraFPmFgP945NmTaRZVkVI1YbWBt9bvUqzex4r54oeEG+473q+vUSbzztsmll5Of7FePqO9/QrcZTlwrtc9yMgRWorIma5Fi625K2QLnicEhqZbOUvpHU94V88bmTe3dynd8isTj6/BQjZYX2CsusiTX1zfKy7oQYKXJlRFRilnY2pDXOzm+tQ63HiWAkjpMDyVHbcCyuipNCbPrM1zcyoCMKXpCvGCnWXppcCE9Ebx7tQ6sJRmL4zUFlLcRtq4qzoTcb2l00Zto0gL0CsvKlVBk5dsQOWSNGKrp60Xt+6x0NQpYBj8thm5YdxYgOhIk1bzFSLyojiTHa/vGi9izVSZo0fhFAuWIQ0z7aVo0wrwJAbQEmCublK0YMpBiKCRozYkSW5eQ0TYlfwF1Nyt+az8i51fzuUB/GQ1HMaq7B6jktpT6cKdUQ4RUySluebT07cckmz107YIesESsDzwR629AXNH4Ru1TJKEZ0kG9JPLUy0t3kQ6PPhWhcxomB4oW/HelNJK+m8YsILk8TCz+RyB3xuhxwZcnxMEu+473qsikjlRETV0T+UFQNVyv11WVXo1IZyWfk3GpEi+bWlTNtcYITWSMz6jzwusyJaLtMXliBENLZggGrheSyvBJ6Rixu02h/Vk4xYqNtvQKKER2oEzUmRnFlWVbf+MSiNkmSVBNrMcPPMmWMaEmKEW1lpDCTNAIhRk6aECOxuIyhgHHPSL+JN3FxMq/1OEueOSGu+gfHwwhFS7d0UTAWjGDX0X4AwK0rS9+iAZL3UafJFg1gfFzSzlxim0ZFtGlKWxmx1sCq/Vm5LrbsZl4FKEZ0kc94r3Z8TPtmeZlqYi2Ob2QiHMWZRKT9ks76jLfTTtSI8bBAuDAZIwKxMO+0ifHeS4EQ4jLgkPSVn8VjEAjHENDhONdip557c61bNYj2lyCvJpUjvX5EYjJmNvmm7DwqJW9e3I5Vc5rxl2+ca/pntFeQZ0StjLBNo/tNu5BYPdoLGKiM2GysF6AY0UU+bRrxpGjwuaZcTYvKyKEimVjFcry2eq96VZCOxZ31cDkkjE5G1FCciQJljAjmtSk7ckYmIob3rYjxuBl13inx9pmo97rUv8Po1a5dMkYApbqmjvfaoFVzvF95fi3KUnUrNq31Xjz5iWvxgXVzTP+MtjwNz3bCLmPpdqDUKayRWBwjE8pknqWeEaNihJWR8qIjDwNrprHTYo/3qsmrXZmrIgDgdTmxOPGGIlo1avpqgdI0az0uVfAZDT8bMGECMztRU+q9NKmowWc2MLGqYqQ9+/Or3BBXraOTkZIGZFmB8EfYQUyXGtXAWiLPiBBBTodkaaVVvxhhm6YsEUY4U2Ikw9jpks4GSJISpnapCKVCMdabzS8iSPWNCANrISZpBGZNrEYyRgTiseg3KEZKvZcmlWTwWenFyDEhRjoqS4w017jVilupF6vli8jIEQmk1Yy6LK9ElRFRlZ1RZ00UvEDvugtWRsoUcdU+PBExbBbM9GZZ53VhzgylPVGMJNajGXbSpEOIkdcSEzXCwFrnLZwYMTvea8aRbroyMmGvMrd4XtphvPdEhYoRh0NSPRaiJViuqAbWEmfk2AFtm6YUm69T4x6sQgxJXBoPTQmu1DIWjKgJrTOb6RkpK5pqzJsFs125i1ZNMXwjR7LspEklNRZ+osAGVgDqvh6jYsTMi7rDpBgZmbCPgRXIr2JnJYFQVPUXVZoYASojhVWWZdXzxMpI8jENx/RFp1uN2l62cKwXUCotkgTE5aRHKBVRFWmpdRf0nG4UihEdSJJk2sSaXYwkxnsL7BsZDoTVlsRiHW8WIiH24mgQQ4FwwQ2sQLIyYnSipqiVEZsZAEWb5mKJ99OcHFAes9Y6T0X6EdryyKaxC2OTUfVKmZURJTpdbJS2slUTjsYxOpl7x1YhAs8AwOVMJqpmOr9dtKFfBKAY0U1Xo7mr0GxR5cWKhRctmlnNNWjQsSCrwefGvFalhXTwwmjBR3sBYH5ioubUQMBQ2dRMpLKaNeI39ljaZS+NIJ/8Gys5PqA8vxZWYFUEqIzgM+F3qfe6TAfAVRqtBXhcNz22B+u37sC+M8NZbydafla3aYDcY8uiitndRDFSloiJGqNmQT2VkaN9fkRj+p36D/72CK69/2kc79cnYlS/iIH8B22rZrJAG3u19MyohUNS8j+MXIGaMbCqkfAGT0J22UsjECeTvrGg6Y3SVnC8Qv0iAjVrpIw9I3YaS7cLagqrRWLk4ugk/nj8EibCMWz+4b6sMQWFyBgR5Kr8ijbNLBv5RQCKEd2YroxkebOcM6MWNW4nQtE4TuvcWDscCOPh35/E+ZFJfOWpI7q+54iO5NVUlmsmakQ4WG0BDaxelxOzWpQ311MD+ls1xWzT2GUvjaCt3gNHYqP0YAknPSp1rFdQCZ4R0YqwS4vRDrRaHGj3zOEB9f8vjAbx6R8fyHiRoIqRBusfD71ihG2aMsVMSTxXVLnDIanVCr2x8P9n3zk172D7a3146exIzu85KnbS5MgY0aLdUVOM0V4AmN+mHJ9e30gkFsewGhxkXIwMjoczOs5TiceTBkC7tGlcToda5SnleG+ljvUKKiESPmletcdz1w5YvSzv6cPKOoRbVsyE1+XAziMD+PauE2lvW4zKSKbnqx0zRgCKEd10mki71EaVZ3Kwq74RHbHwsizjh8+fAZCcCHlw+9Gc32OmMiLaNKcGAxhMKOxChZ4J5id8KqcG9VWJxEnE5ZDQXKO/ddKacJzHNAIjF2PBCIRuabaJGAE0z8sSiZFwNI7XE1W9ShUjFVEZsdEqA7ugZo1YUFUMRmL44/FBAMDHrl+AL956OQDg6789gt0nLk27fSH20ghybe49z8pIeSPaNEYWrIknQ7aocnWiRkdl5LkTl3BqMIB6rwvf+8hauBwSdh0dwAunhzJ+T78/hNHJCBwSsNBAGb29wYuOBi9kGXj5nJI3UlfgMbBk1oi+TcZa86qR4CA9jvNUxCRNg9eljnnbge48N0rny+uXAojFZdR5nOp0T6UhSunlHAk/NM6NvalYGQn/p5OXMBmJoavRh+XdjXjvmh68+6rZiMvA3/5o/xSzvFLRLaAYydKmicVl1Wowi2KkPOkUBtaxoO5pDz3mSjUWXsdEzQ+ffx0AcNuqmbisuxHvvboHAPDAb45kPCaRLzKvrc7wplnRqpmMFN7ACmhTWPVVRgbGlReVmb5rW46rh1SGbRZ4JuhSx3tLI0a05lVJsi5J0k6I58rwRAQRA0ZzOzFEA+s0rFyW90yiRfOWZe2QJAmSJOHLt12BpZ0NGBwP4e9+tF8dUhgKhCEbWO5plPYso+gD/hCicRkuh2TIZ1cMKEZ0IjwjwUgcY5P6QnL0iRHlDf/c8CTGgpnn0/vHgvjtwT4AwAfWKltI//ati+BxOfD8qSE8l6YUCBhLXk1FtGoERRMjlwK6pkPyGY9LjvfqrYzYay+NQA0+K7EYqdSxXkBpbYjCW6YgKbszFLCX38kOJCsj+YkRWZbx9JGEGFnaoX6+xuPEv33oKtR5nPjTySH86++Ulrqeink+ZGvTiBZNZ6OvIL87HyhGdOJzO9Gc2EnSpzOfIlvGiKCp1q2ucT6apTry4xfPIhqXcdWcZnXSpbupBh9MbCR94LfpqyNGdtKkIiojgkKn9c1qroHbKSEUjeOijrbDQB4mMKMTNXbbSyPoLnVlZKCyzauAssxMjFEf0GEYtyN2mwSzA+K8cSlPgXliYBxnhybhcTpw7aK2KV9b2F6P+999JQBg2zMn8Mzh/oIFngnEuW10cvr6kuRYr71aNADFiCE6DU4u6M3AWNatvOlnioWPxWX8aM9ZAMCH3jh3ytc+fsNC+NwO7D8zgmcS6lyLqIwsM5AxIphWGSngaC+geDl6Evt69CzMM5MxIlCzRvRWRmzapuk0OXJuFZU+1iv4H1d2AwB+tOdMiY/EHJdslh5sB4RvbCTP9puYonnjwlbUpTH537JiJu5Yr5y3P/3jA6oHr1BtkqYaN9xOpeqROracHOu1n7+LYsQAnQZ3gegWI8I3kiEWftfRfpwfmURzrRvveEP3lK91NPhw5zXzAABf/+3RKe2NeFzG0T7lzULPTppUembUoMGXfHEVuk0DAPNblVbNST1ixETGiCBbXzUdwzYtc2srI8Ve+BWPyzhRBZURAHjfWqUCuevoAM4O6fM02QnRpuFob5JmTfstW0BZLoQYeevS9oy3+ew7L8OK2U0YmYjgGzuOASiMeRVQ1pdkatXYNWMEoBgxRGfiDcxyMdItJmrSV0Z++Cflauw9V81Oa0L92JsXot7rwsELY/jNwV718+eGJzEZicHjcmBuouJgBEmSsLw72aopxlKlxYl20vbX+nLe1kwUvED1jOh8LO1qYBWVkclIDGPB4i78Oj8yiWAkDo/ToW6grlTmt9XhmoWtkGWlZVpOBCMxddnlDE7TqDgdktq2Mht8NjoZwQunlej3ty7rzHg7r8uJ//2Bq9BU41azjQrVpgEyt6HP2zRjBKAYMUSXwawRPZ4RALgsUbU40uufZtw8NzyhmqPen/CHpNJS58FH3jQfAPCvvzuqPtlFvsii9nq4nOYeam2rphiVkfev7YHLIeH3Rwfw/Mn0plyBmfRVQbtBJ71qYLVZZcTndqIl4WMpdtaIaNHMa6s1/fwqJz6QeP098cLZspqqEVURt1NCQ4GzgsqNfDNk/nBsALG4jIXtdZjTml2Q98yoxYPvXTHtdxeCTGJELNWkZ6TMMZrCqrcyMr+tDh6nA+OaVeyCx/echSwD1yxszZoT8tE3zUdTjRtH+8bxq5cvADC3kyYVYWL1OB1wF+ENZ25rHd63VhlZ/mqWkWUgT89Io7nR3hk22UujRTwvi729V4iRxR3mn1/lxNuWd6G1zoN+fwg7Dk33Z9mVIU3gWaWOX5tFnagxGXymtmiWdeS4pcKNl3Xif/7ZUnQ0ePHmJZnbOvmSSYywTVMhGDELBiMx+BNl81xvli6nA4s7FaFxSOMbicTiePwFpST8wXVz036voKnGjb9+8wIAwL9uP4poLK62fcxM0ghW9DQDKG5Y0t+9dTF8bgf2vj6svthT0d6/+bRp/MEogpFYjlsne8p2q4wASd9IsU2s1TDWq8XjcuA9a2YDKC8j6xAnaTKiprCaaNPE4zJ2HVH20bxFpxgBgE/csAh7PrsBl3U35r6xSZKV3+Q5YSIcVddndNPAWt6IFFY95XChSD0uBxp9uUujySTWpG9k+2t9GBwPoa3ei5uWZ+5HCj58zTzMqPPg9KUJ/GzfeXVU2MhOmlQWddTjXzeuwL9uXGn6Zxilo9GHD1+jtJ2+9psjaTNHRFlV7/2bSoPXBW8iSVVPdcTOoVFdibHTYo/3VsNYbyrvv1pp1fz+WPkYWSlGMiMussx4Rl46N4JLgTAavC5cPW+G1YeWF+kqI2InTYPXhUaf/Sq8FCMG6GxK9hejOXrGWr+IntLosjQL80Ti6sarZ+uKIK/zuvCJGxYCAL6x4xhOJmLV86mMAMDtq2bjjQta8/oZRvn49QvR4HPhcK8f//XShWlfV1s0Ou/fVCRJ0h18Fo3FMTppz9AzwPxG6XyQZblqxnq1zGurw5sWtUGWgcdfKI/qCMVIZtSsEROeEZG6et2StqK0sI2QXozYt0UDUIwYojWRmBeXcytpo36GZSkL804OjOOPxy9BkoD3r01vXE3Hh944Fx0NXpwfmUQkpuwMsaNZKRdNtW587HpFWD24/ai6qVigLprKY1a/Q2fw2ehkBMK6YmQhX7EoRfDZwLiy80iSgAXtdUX7vXZAvB5//OK5sjCyUoxkRow6mwk+E4MF2aZoSkW66AI7Z4wAFCOGcDok9Q0s11WoYTGSaNOcuhTAZDiG/0xs533L0g7MbtE/NulzO/G3b12k/ntJV0PZmtY2XTsPbfVenBmawBMp45TayohZ9GaNCPNqU43bllMjpdjcK6oiPS21hncelTs3Le9EW70HA/4QdhzKPYJeauzcYiw1Zqdp+saCePX8GCQJuCFLvkipaK9PhjqKIYALo/Yd6wUoRgzToXNLqlEx0t7gRVu9J7EldwQ/3XcOANS4dyO89+oetRpiZieNXaj1uFRh9c0dxzAZThpNk/ev+ROsKkZyPJZirNeuJ/NugyPnVnCiv/r8IgKPy4G/WKNMfP3wefu3asTGXrs+f0uJ2c29okVz5ezmgo7omkUsDw1G4hgPKUZ/tmkqjK5GnZURnRkjWkR15MHtRzEyEcHMJh9uWKrfpS3wupz48u1XYGF7Hd69erbh77cT7187B7NbajDgD+E/njulfn7QxP2bihoJn+OqKDkaab8WDZCc8hqZiOiaDLKC5Fhv9YkRIGlk/cOxQZy5ZG8jK9s0mdFWRowkGCdTV42fn4tBrceF+kSmjLhws/NeGoBixDB6zYJmMjCEifX5U0MAlDdis5sV37K0Azv+/gbbubyN4nE5sOWmJQCAh3eewGhiNC2fjBGB3mV5wzYvczf6XGogXbFaNWKSplrGelOZ01qL6xYrS9HsbmRlmyYzojISisYRCOsT8qFoDM8eHwSgP1+kFLSlTAoJMSIqqXaDYsQgaptmNPsbmCkxopk7dzokbLy6x8QRVh63rpyFJZ31GAtG8Z3fnwCQ38ZeQbZV21qGbJwxAiiTQV2NxTWxHq/iNo3gA2ViZGVlJDO1HhdqEp4nvRM1e04NYSIcQ3uDd9pmczuhvdiKx2V6RiqNYlRGAOBtyztV4VPtOB0S/uFtSwEA//HH0+j3B/OKghfoHe0th/XrXUUMPhsLRtQU4moWIxuWd6Kt3ovB8ZCuXUqAMia+/8zwtOmwQhGLy7av7JUao1kjokXzlqXtcJisXBeDpBgJ4lIgjHA0DklKnivsBsWIQfSc9GVZNuUZWdRRr65+zpW4Wm3ctLwTq+Y0YzISw/9++nheS/IEIhJ+cDyUNlhNIFILm21aGQGSz8tiVEZEVaSjwWvL8KRi4XY68F4DiaynBwN498O7cfu/PYdtzxwv9OEBmDqWbtfKXqlpNZg18sxh+470atHu3xItms4Gn+0yUQTcmmSQzsQbWLbJhbFgVL3yMXLl7nM7cf+fX4k+fxDXLipuyJjdkSQJ/3jzUnzgkefxn8+fQTQhHvKpjIgo6EhMxvUPPINYTEYkLiMSiyMaS/w3LquLB+24l0ZQzOAztmiSvH/tHHx71wn84dggXr8UwNzW6Zkrsizjp3vP4fP/dVD1JTx7fBCfTnihCslQYudKo89l2zehUtNuoDJycmAcpy9NwO2U8KaEZ8iuaNs0Ym+VXTNGAFZGDCMmF/zBKCbC6Ve2i6v2Bp/LcAbDu1fPxiduWFS22SCF5JqFbbhucZsqRGo9TtTlsYXU43KorbGzQ5O4MBrEgD+EkYkIxkNRhKJxVYjUeZxYPbcl/z+iQCSDzwq/LK+ax3pT6ZlRi+sWKzkTP9pzdtrXRyci2Pyf+/GPP30ZgXBM9Ri8cn60KK0aMZbeasPxU7uQ3E+TuzIiWjTr5req0yp2RStGzo/Y2y8CsDJimHqvMrkwEY6hbyyE+W3T70IrJj1Iev7x5qX4wzHFyW7FfP+PP7Yehy6MweV0wO2U4HIo/3U7HXCJ/zok1Ptc8LrsG+7VqebfmNs+aoRqH+tN5QNr5+D3Rwfw071nseWmJerqht0nLmHLjw/g4mgQLoeET9+0BH/z5gW4+p9/h+GJCA5eGMWqOYUVuKIyYtexdDuQ3NybuzKi+kVsPEUj0IY62n2sF6AYMYyYXDg5GEDvaBDz26aXZc34RYg+rpzdjHe8oQv//UqvOrqWD40+N9YVee9OIehOLMvrLUJlpNrHelO58bIOtDd4MeBXjKw3Le/Ev/7uKB7edQKyDMxvq8NDG1eqG7BXzWnB04f7sf/MSMHFyCXVfM1zUSZadaaw+oMR7EnELth5pFegTWG1+1gvwDaNKcRVaL8/fX+elZHCcs/bL8O6+TNwx/p5pT4U2yCWOA74cy9xzIdgJKZuq2WbRsHtdGBjIpH1//39Cbzn4efw7Z2KENm4pge/+ts3qUIEAK6ao/z/vjPDBT+25CQYKyOZEBc1e18fxnd2ncDzJy+lbcE/e2wQ0biM+W11aS9C7YZ4/xkcD+PcsL3TVwFWRkyhmlgzTC5QjBSWnhm1eOJv1pf6MGxFW50XLoeEaFyZ5BKVEqs5ORBAXFYMkaz8Jdl4dQ+27TyOl86NAlD2GN3/52/A29/QPe22ohqy/8xIwY+LlZHcLO5QfGMXR4PY+uvDAJQ4gaWdDVg5pxmrepqxak4zdqgjvfavigDJ9lMsLuNIn7KAlWKkwuhUx3vTl/VExYRihBQLh0NCZ6MP50cmcXE0WDAxIlo0izrqabLW0DOjFm9b3onfHOzDNQtb8fX3rsj4GKzoaYYkAedHJtE/FixonpCojLQyYyQjy2c24ld/+yb88fgg9p8Zwf6zw+gbC+G1i2N47eKYurRUUA4tGkCp2M2o82AokTEC0DNSceQao7RioywhRulqUsRIXwGzRjjWm5mHNq7CaxfHsKqnOWsYVr3XhaWdDTjc68e+M8P4syumV0+sQlRGWihGsnLFrCZcMatJ/ffF0UkcODOC/WdHcODMCF4+P4JgJI7ORi/Wzi+fFRvt9V41gbfG7USzjY3MFCMm6MyxuZdtGlIKihF8xrHezNQYGP9eNacFh3v92H9mpKBiZIiVEVN0N9Wg+w01apstEovjeP842uq96rRUOdDe4NW0aHy2rmaWz71qIzpzVEasiConxCjFCD5LjvU25LglyUYxTKzBSAznE1MUjILPD7fTgcu6G8vunK49Xjv7RQCKEVMIA2v/2PS109FYXC2NltsTl5Q33QWujERjcZwaDABgZSRfhIn15XOjBVuy9+gfT2FkIoKZTT4s66Z4rEamiJEC+cisgmLEBB0Nykk/HIurZVDBUCAMWQYcUjLZj5BioLYPCyRGzg5PIhyLw+d22NoIVw4saKtDU40boWgchy6OWf7zL42H8G/PKBuu//HPlto6sI8UDm0WEysjFYjH5VAf5NSJGrEBdkadF04bb3QklYeojGTbm5QPxxK95wVt9bbeVloOOBwSVolWzevWt2q+seMYxkNRXDGrEbeumGX5zyflwdQ2jX0DzwCKEdOI6khqf36AfhFSIro0YiS1fWgF2rFekj+rehJ5I2dHLP25JwbG8cPEOOr/847LKByrGJHCCth7rBegGDFNV1MGMcJJGlIi1PZhNI7hiYjlP59jvdZy1dxmANabWO//9WHE4jI2XNaBaxbae7MsKSw0sFYBmcZ7mTFCSoXSPlSed4XY3suxXmsR4WdnhybV80a+/OnkJWx/rQ9Oh4TPvH2ZJT+TlC9djT44JMDjdKgX0HaFYsQkYqKGlRFiJ7qa0j8v80WWZZwYUCZpuK3XGhp9bvW+3G9BdSQel/Ev/30IAPD+tT1YxPHrqqep1o0H37sS33jfSvjc9jYxU4yYJJnpMPWKhp4RUkq6GpVSrNXjvb1jQYyHonA6JMxttf+SsHLhqsSI7z4L9tT88uULePncKOq9Lnxqw5K8fx6pDG5bNSvtjiS7QTFikkxjlKyMkFIiKiNWj/cKv8jc1tqySqC0O2KiJt/KSDASw1efOgIA+PgNC9V2HSHlAs8qJhFiRCzFEwzSM0JKiFjOZrUYOdaX8Iu0s0VjJVdpws+ieYSfPfbcaZwfmUR3kw8ffdN8qw6PkKJBMWISYQYaHE9uRARYGSGlJdfeJLNwrLcwLGyvR4PPhclIDId7/aZ+xlAgjG1PHwcA/OPNS23vDSAkHRQjJmmpdcPjVO4+UR2ZDMfgD0UBUIyQ0qAGnxWoTUMxYi0Oh4SVPc0AzLdqvrnjGPyhKC6f2YjbVjLgjJQnFCMmkSQJHepEjVINEQvyPC4HGn1ciEyKT1eBxAjHegtHPibWkwPj+MGfXgcAfJYBZ6SMoRjJg9Qtqf0av4idVzWTykU8J/2hKMYTVbp8GQ6E1eWPC+kZsZx8TKxfeeowonEZNy7rwDWLGHBGyhdTYmTbtm2YN28efD4f1q1bhz179mS87cGDB/Hud78b8+bNgyRJeOihh8weq+1InaihX4SUmjqvCw2JqpxV1ZGdR/sBKHHSdV5W/KxGxMKfvjSBS+P6w8/2nBrCbw4qAWf3vIMBZ6S8MSxGnnjiCWzZsgX33Xcf9u3bhxUrVuDmm29Gf39/2ttPTExgwYIFuP/++9HV1ZX3AdsJIUb6Ep4RZowQO5BasTNLIBTF//r5K/j0Ey8BAK5d1Jr3sZHpNNW61fbXAZ17auJxGf+cCDh739UMOCPlj2Ex8uCDD+Kuu+7Cpk2bsHz5cjz88MOora3Fo48+mvb2V199Nb72ta/hfe97H7zeynqTVlNYWRkhNkL4RvIJPnvh9BDe8c0/4Ad/Uhau3bF+Lj7/rsstOT4ynVUJE6vePTU/2XsWL50dQZ3HyYAzUhEYqrmGw2Hs3bsX99xzj/o5h8OBDRs2YPfu3ZYdVCgUQiiULFeOjY1Z9rOtJLksTzlW7qUhdqBLbR8a308TjMTw4PajeOQPJyHLwMwmH776nhV402L6EQrJVXNb8JO957Dv9ZGctx0KhLH114cBAJ++aQkvfkhFYEiMDA4OIhaLobOzc8rnOzs7cfjwYcsOauvWrfjCF75g2c8rFJ0p5XBWRogdUMd7DbZpXj43gi0/fkkd4/2L1bPxuVuWo9HntvwYyVSEifWlcyOIxWU4s0zFfOXXhzEyEcGyrgZ8+Jp5xTlAQgqMLadp7rnnHoyOjqofZ8+eLfUhpUUbMCXLMj0jxBZ0GUxhjcTieHD7Udz+b8/heP842uq9+O4da/C1v1hBIVIkFnc0oN7rwkQ4hiNZws9ePD2EJ15Uzof/fPsVcDlteQonxDCGKiNtbW1wOp3o6+ub8vm+vj5Lzaler7cs/CWiHD4RjmE8FE1GwVOMkBKi7qfRURk5OzSBj/1gLw5eUFqh77yyG1++9Qq01HkKeoxkKs5E+Nmzxwex78wwls9snHabSCyO//XzVwEAG9f0YPXcGcU+TEIKhiFZ7fF4sHr1auzYsUP9XDwex44dO7B+/XrLD87u1HicarhZ72iQnhFiC8Tm3lyVkWgsjs0/2o+DF8bQXOvGt96/Cts+cBWFSIlI5o2MpP36Y388jcO9frTUuvGZt3OUl1QWhkMDtmzZgjvvvBNr1qzB2rVr8dBDDyEQCGDTpk0AgDvuuAOzZs3C1q1bASim19dee039//Pnz+PAgQOor6/HokWLLPxTSkNnow9jwXEc6x9HOLHoipURUkpS9yZl2rL7nd+fxEtnR9Dgc+GXm9+Enhm1xTxMkoJIYk0XfnZhZBL/+rujAIB73n4ZBSOpOAyLkY0bN2JgYAD33nsvent7sXLlSjz11FOqqfXMmTNwOJInvwsXLmDVqlXqvx944AE88MADuP7667Fz5878/4IS09Xkw7H+cbxyfhQA0OhzcVEVKSkttW54XA6Eo3H0jQXTiozXLozhocSb2xfedTmFiA0QO2pODgYwHAhPERxf+tVrmAjHsHpuC96zenaJjpCQwmEqTnHz5s3YvHlz2q+lCox58+ZBlmUzv6Ys6GhQrkJfTYgRVkVIqZEkCV2NPpwZmkBvGjESisaw5ccHEInJeNvyTty+isvV7EBLnQcL2upwcjCAA2dH8JZlHQCAZ47049ev9sLpkPDl267g/hlSkdCKnSfCLEgxQuxEtoV53/jdMRzu9WNGnQf/8udv4B4lG7FKXZqntGqCkRju+8VBAMBHrp2Hy7qnG1sJqQQoRvJETNQMT0QAAO2JSgkhpaSrMb0Y2XdmGA/vOgEA+Jfbr0Abzda2ItXEuu2Z4zgzNIGuRh+TVklFQzGSJx2NU8UHJ2mIHUgXfDYZjuEffvwS4jJw28qZ+LMrukt1eCQDwsR64OwIjvf78Z1dJwEA992ynEsKSUVDMZInXalihG0aYgPStWm+8tRhnBwMoLPRiy+864pSHRrJwtKuBtR6nBgPRfHX39+LcCyOG5a248+uqKwlo4SkQjGSJ+KkL6AYIXagq3FqZeS5E4N47LnTAICvvPtKNNUyWdWOOB0SVsxuBgCcHAjA63Lgi++6gr4eUvFQjORJa50HWnM7xQixA9rKiD8YwT/+5GUAwPvXzsENSztKeWgkB1fNbVb//+63LMKcVo5dk8qHYiRPXE7HFAFCzwixA8mN0kF88Zev4fzIJHpm1OCz77ysxEdGcnHtImVD8oK2OvzN9QtKfDSEFAc6oiygs9GHvjHupSH2ob3eC4cEROMyfrL3HCQJeOA9K1BPE6TtuWZhG/6/j6zFZd2N8LoYoEiqA1ZGLEBs73VIwAzGNBMbkFqx++i187FuQWsJj4gY4c1L2nlhQ6oKihELEGbB1novnExHJDahq0lZmLeoox7/cPPSEh8NIYRkhjVbC+hsVK5g6BchduL2lTMxOhHGQxtXcl8SIcTWUIxYwNzWOgDA7JaaEh8JIUk+fO18fPja+aU+DEIIyQnFiAXcfHkXvnTr5XjzkvZSHwohhBBSdlCMWIDH5cBfrp9X6sMghBBCyhIaWAkhhBBSUihGCCGEEFJSKEYIIYQQUlIoRgghhBBSUihGCCGEEFJSKEYIIYQQUlIoRgghhBBSUihGCCGEEFJSKEYIIYQQUlIoRgghhBBSUihGCCGEEFJSKEYIIYQQUlIoRgghhBBSUspia68sywCAsbGxEh8JIYQQQvQi3rfF+3gmykKM+P1+AEBPT0+Jj4QQQgghRvH7/Whqasr4dUnOJVdsQDwex4ULF9DQ0ABJkiz7uWNjY+jp6cHZs2fR2Nho2c8l6eH9XVx4fxcX3t/Fhfd3cTF7f8uyDL/fj5kzZ8LhyOwMKYvKiMPhwOzZswv28xsbG/lkLiK8v4sL7+/iwvu7uPD+Li5m7u9sFREBDayEEEIIKSkUI4QQQggpKVUtRrxeL+677z54vd5SH0pVwPu7uPD+Li68v4sL7+/iUuj7uywMrIQQQgipXKq6MkIIIYSQ0kMxQgghhJCSQjFCCCGEkJJCMUIIIYSQklLVYmTbtm2YN28efD4f1q1bhz179pT6kCqC3//+97jlllswc+ZMSJKEn//851O+Lssy7r33XnR3d6OmpgYbNmzAsWPHSnOwFcDWrVtx9dVXo6GhAR0dHbjttttw5MiRKbcJBoO4++670draivr6erz73e9GX19fiY64vPn2t7+NK6+8Ug1/Wr9+PX7961+rX+d9XTjuv/9+SJKET33qU+rneH9by+c//3lIkjTlY9myZerXC3V/V60YeeKJJ7Blyxbcd9992LdvH1asWIGbb74Z/f39pT60sicQCGDFihXYtm1b2q9/9atfxTe/+U08/PDDeP7551FXV4ebb74ZwWCwyEdaGezatQt33303/vSnP2H79u2IRCJ429vehkAgoN7m05/+NH75y1/iJz/5CXbt2oULFy7gz//8z0t41OXL7Nmzcf/992Pv3r148cUX8da3vhW33norDh48CID3daF44YUX8J3vfAdXXnnllM/z/raeyy+/HBcvXlQ/nn32WfVrBbu/5Spl7dq18t13363+OxaLyTNnzpS3bt1awqOqPADITz75pPrveDwud3V1yV/72tfUz42MjMher1f+0Y9+VIIjrDz6+/tlAPKuXbtkWVbuX7fbLf/kJz9Rb3Po0CEZgLx79+5SHWZF0dLSIn/3u9/lfV0g/H6/vHjxYnn79u3y9ddfL3/yk5+UZZnP7UJw3333yStWrEj7tULe31VZGQmHw9i7dy82bNigfs7hcGDDhg3YvXt3CY+s8jl16hR6e3un3PdNTU1Yt24d73uLGB0dBQDMmDEDALB3715EIpEp9/myZcswZ84c3ud5EovF8PjjjyMQCGD9+vW8rwvE3XffjXe+851T7leAz+1CcezYMcycORMLFizABz/4QZw5cwZAYe/vsliUZzWDg4OIxWLo7Oyc8vnOzk4cPny4REdVHfT29gJA2vtefI2YJx6P41Of+hSuvfZaXHHFFQCU+9zj8aC5uXnKbXmfm+eVV17B+vXrEQwGUV9fjyeffBLLly/HgQMHeF9bzOOPP459+/bhhRdemPY1PretZ926dXjsscewdOlSXLx4EV/4whdw3XXX4dVXXy3o/V2VYoSQSuXuu+/Gq6++OqXHS6xn6dKlOHDgAEZHR/HTn/4Ud955J3bt2lXqw6o4zp49i09+8pPYvn07fD5fqQ+nKnj729+u/v+VV16JdevWYe7cufjxj3+Mmpqagv3eqmzTtLW1wel0TnMA9/X1oaurq0RHVR2I+5f3vfVs3rwZv/rVr/DMM89g9uzZ6ue7uroQDocxMjIy5fa8z83j8XiwaNEirF69Glu3bsWKFSvwjW98g/e1xezduxf9/f246qqr4HK54HK5sGvXLnzzm9+Ey+VCZ2cn7+8C09zcjCVLluD48eMFfX5XpRjxeDxYvXo1duzYoX4uHo9jx44dWL9+fQmPrPKZP38+urq6ptz3Y2NjeP7553nfm0SWZWzevBlPPvkknn76acyfP3/K11evXg232z3lPj9y5AjOnDnD+9wi4vE4QqEQ72uLufHGG/HKK6/gwIED6seaNWvwwQ9+UP1/3t+FZXx8HCdOnEB3d3dhn9952V/LmMcff1z2er3yY489Jr/22mvyX//1X8vNzc1yb29vqQ+t7PH7/fL+/fvl/fv3ywDkBx98UN6/f7/8+uuvy7Isy/fff7/c3Nws/+IXv5Bffvll+dZbb5Xnz58vT05OlvjIy5OPf/zjclNTk7xz50754sWL6sfExIR6m4997GPynDlz5Kefflp+8cUX5fXr18vr168v4VGXL5/5zGfkXbt2yadOnZJffvll+TOf+YwsSZL829/+VpZl3teFRjtNI8u8v63m7//+7+WdO3fKp06dkv/4xz/KGzZskNva2uT+/n5Zlgt3f1etGJFlWf7Wt74lz5kzR/Z4PPLatWvlP/3pT6U+pIrgmWeekQFM+7jzzjtlWVbGez/3uc/JnZ2dstfrlW+88Ub5yJEjpT3oMibdfQ1A/o//+A/1NpOTk/InPvEJuaWlRa6trZVvv/12+eLFi6U76DLmIx/5iDx37lzZ4/HI7e3t8o033qgKEVnmfV1oUsUI729r2bhxo9zd3S17PB551qxZ8saNG+Xjx4+rXy/U/S3JsiznV1shhBBCCDFPVXpGCCGEEGIfKEYIIYQQUlIoRgghhBBSUihGCCGEEFJSKEYIIYQQUlIoRgghhBBSUihGCCGEEFJSKEYIIYQQUlIoRgghhBBSUihGCCGEEFJSKEYIIYQQUlIoRgghhBBSUv5/uoy34qzuEvQAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Squared Error: 0.09421305668796993\n",
            "R2 Score: 0.5747979797344294\n"
          ]
        }
      ],
      "source": [
        "#Another attempt https://github.com/daenuprobst/theia/blob/main/src/theia/ml/mlp_classifier.py \n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "class theiaMLP(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(theiaMLP, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.fc1 = nn.Linear(self.input_size, self.hidden_size)\n",
        "        self.tanh = nn.Tanh()\n",
        "        self.fc2 = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        hidden = self.fc1(x)\n",
        "        tanh = self.tanh(hidden)\n",
        "        output = self.fc2(tanh)\n",
        "        return output\n",
        "    \n",
        "\n",
        "#initialize dataloader with random sampling of size 10 \n",
        "dataset = dataLoader(X, y)\n",
        "trainloader = torch.utils.data.DataLoader(dataset, batch_size=10, num_workers=0, shuffle = True)\n",
        "testloader = torch.utils.data.DataLoader(dataset, batch_size=10, num_workers=0, shuffle=True)\n",
        "\n",
        "#mlp init\n",
        "mlp = theiaMLP(init_features, 1000, 1)\n",
        "#set loss function and gradient descet optimizer\n",
        "loss_function = nn.L1Loss()\n",
        "optimizer = torch.optim.Adagrad(mlp.parameters(), lr=1e-4)\n",
        "\n",
        "#train loss\n",
        "train_loss = []\n",
        "mlp.train()\n",
        "\n",
        "#train for this many epochs\n",
        "for epoch in range(0,50):\n",
        "    print(f'Starting Epoch {epoch+1}')\n",
        "\n",
        "    current_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, targets = data\n",
        "        inputs, targets = inputs.float(), targets.float()\n",
        "        targets = targets.reshape((targets.shape[0], 1))\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = mlp(inputs)\n",
        "\n",
        "        loss = loss_function(outputs, targets)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        current_loss += loss.item()\n",
        "        if i%10 == 0:\n",
        "            print(f'Loss after mini-batch %5d: %.3f'%(i+1, current_loss/500))\n",
        "            current_loss = 0.0\n",
        "    train_loss.append(loss.item())\n",
        "    print(f'Epoch {epoch+1} done')\n",
        "\n",
        "\n",
        "plt.plot(train_loss)\n",
        "plt.show()\n",
        "\n",
        "test_data = torch.from_numpy(testX.to_numpy()).float()\n",
        "test_targets = torch.from_numpy(testY.to_numpy()).float()\n",
        "\n",
        "#print mse and r2\n",
        "mse_r2_calculator(mlp, test_data, test_targets)\n",
        "#Results\n",
        "# Mean Squared Error: 0.11795077403554882\n",
        "# R2 Score: 0.46766500127569677"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting Epoch 1\n",
            "Loss after mini-batch     1: 0.000\n",
            "Loss after mini-batch    11: 0.007\n",
            "Loss after mini-batch    21: 0.007\n",
            "Loss after mini-batch    31: 0.005\n",
            "Loss after mini-batch    41: 0.005\n",
            "Loss after mini-batch    51: 0.006\n",
            "Loss after mini-batch    61: 0.006\n",
            "Loss after mini-batch    71: 0.005\n",
            "Loss after mini-batch    81: 0.005\n",
            "Loss after mini-batch    91: 0.006\n",
            "Loss after mini-batch   101: 0.006\n",
            "Loss after mini-batch   111: 0.006\n",
            "Loss after mini-batch   121: 0.006\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.005\n",
            "Loss after mini-batch   151: 0.005\n",
            "Loss after mini-batch   161: 0.005\n",
            "Loss after mini-batch   171: 0.005\n",
            "Loss after mini-batch   181: 0.005\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.005\n",
            "Loss after mini-batch   211: 0.006\n",
            "Loss after mini-batch   221: 0.005\n",
            "Loss after mini-batch   231: 0.005\n",
            "Loss after mini-batch   241: 0.006\n",
            "Loss after mini-batch   251: 0.005\n",
            "Loss after mini-batch   261: 0.006\n",
            "Loss after mini-batch   271: 0.005\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.005\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.005\n",
            "Loss after mini-batch   321: 0.006\n",
            "Loss after mini-batch   331: 0.005\n",
            "Epoch 1 done\n",
            "Starting Epoch 2\n",
            "Loss after mini-batch     1: 0.000\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.005\n",
            "Loss after mini-batch    31: 0.005\n",
            "Loss after mini-batch    41: 0.005\n",
            "Loss after mini-batch    51: 0.005\n",
            "Loss after mini-batch    61: 0.005\n",
            "Loss after mini-batch    71: 0.005\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.005\n",
            "Loss after mini-batch   101: 0.005\n",
            "Loss after mini-batch   111: 0.005\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.005\n",
            "Loss after mini-batch   141: 0.005\n",
            "Loss after mini-batch   151: 0.005\n",
            "Loss after mini-batch   161: 0.005\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.005\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.005\n",
            "Loss after mini-batch   231: 0.005\n",
            "Loss after mini-batch   241: 0.005\n",
            "Loss after mini-batch   251: 0.005\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.005\n",
            "Loss after mini-batch   281: 0.005\n",
            "Loss after mini-batch   291: 0.005\n",
            "Loss after mini-batch   301: 0.005\n",
            "Loss after mini-batch   311: 0.005\n",
            "Loss after mini-batch   321: 0.005\n",
            "Loss after mini-batch   331: 0.005\n",
            "Epoch 2 done\n",
            "Starting Epoch 3\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.005\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.005\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.005\n",
            "Loss after mini-batch   101: 0.005\n",
            "Loss after mini-batch   111: 0.005\n",
            "Loss after mini-batch   121: 0.005\n",
            "Loss after mini-batch   131: 0.005\n",
            "Loss after mini-batch   141: 0.005\n",
            "Loss after mini-batch   151: 0.005\n",
            "Loss after mini-batch   161: 0.005\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.005\n",
            "Loss after mini-batch   191: 0.005\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.005\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.005\n",
            "Loss after mini-batch   251: 0.006\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.005\n",
            "Loss after mini-batch   301: 0.005\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Epoch 3 done\n",
            "Starting Epoch 4\n",
            "Loss after mini-batch     1: 0.000\n",
            "Loss after mini-batch    11: 0.005\n",
            "Loss after mini-batch    21: 0.005\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.005\n",
            "Loss after mini-batch    51: 0.005\n",
            "Loss after mini-batch    61: 0.005\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.005\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.005\n",
            "Loss after mini-batch   121: 0.005\n",
            "Loss after mini-batch   131: 0.005\n",
            "Loss after mini-batch   141: 0.005\n",
            "Loss after mini-batch   151: 0.005\n",
            "Loss after mini-batch   161: 0.005\n",
            "Loss after mini-batch   171: 0.005\n",
            "Loss after mini-batch   181: 0.005\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.005\n",
            "Loss after mini-batch   211: 0.005\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.005\n",
            "Loss after mini-batch   241: 0.005\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.005\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.005\n",
            "Loss after mini-batch   301: 0.005\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Epoch 4 done\n",
            "Starting Epoch 5\n",
            "Loss after mini-batch     1: 0.000\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.005\n",
            "Loss after mini-batch    31: 0.005\n",
            "Loss after mini-batch    41: 0.005\n",
            "Loss after mini-batch    51: 0.005\n",
            "Loss after mini-batch    61: 0.005\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.005\n",
            "Loss after mini-batch    91: 0.005\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.005\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.005\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.005\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.005\n",
            "Loss after mini-batch   231: 0.005\n",
            "Loss after mini-batch   241: 0.005\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.005\n",
            "Loss after mini-batch   271: 0.005\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.005\n",
            "Epoch 5 done\n",
            "Starting Epoch 6\n",
            "Loss after mini-batch     1: 0.000\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.005\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.005\n",
            "Loss after mini-batch    61: 0.005\n",
            "Loss after mini-batch    71: 0.005\n",
            "Loss after mini-batch    81: 0.005\n",
            "Loss after mini-batch    91: 0.005\n",
            "Loss after mini-batch   101: 0.005\n",
            "Loss after mini-batch   111: 0.005\n",
            "Loss after mini-batch   121: 0.005\n",
            "Loss after mini-batch   131: 0.005\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.005\n",
            "Loss after mini-batch   161: 0.005\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.005\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.005\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.005\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.005\n",
            "Loss after mini-batch   301: 0.005\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Epoch 6 done\n",
            "Starting Epoch 7\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.005\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.005\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.005\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.005\n",
            "Loss after mini-batch   111: 0.005\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.005\n",
            "Loss after mini-batch   151: 0.005\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.005\n",
            "Loss after mini-batch   181: 0.005\n",
            "Loss after mini-batch   191: 0.005\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.005\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.005\n",
            "Loss after mini-batch   241: 0.005\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.005\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.005\n",
            "Loss after mini-batch   321: 0.005\n",
            "Loss after mini-batch   331: 0.005\n",
            "Epoch 7 done\n",
            "Starting Epoch 8\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.005\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.005\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.005\n",
            "Loss after mini-batch    71: 0.003\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.005\n",
            "Loss after mini-batch   111: 0.005\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.005\n",
            "Loss after mini-batch   151: 0.005\n",
            "Loss after mini-batch   161: 0.005\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.005\n",
            "Loss after mini-batch   231: 0.005\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.005\n",
            "Loss after mini-batch   261: 0.005\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.003\n",
            "Loss after mini-batch   311: 0.005\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Epoch 8 done\n",
            "Starting Epoch 9\n",
            "Loss after mini-batch     1: 0.000\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.005\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.005\n",
            "Loss after mini-batch    51: 0.005\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.005\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.005\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.005\n",
            "Loss after mini-batch   161: 0.005\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.005\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.005\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.005\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.005\n",
            "Epoch 9 done\n",
            "Starting Epoch 10\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.005\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.005\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.005\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.005\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.005\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.005\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.005\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.005\n",
            "Loss after mini-batch   221: 0.005\n",
            "Loss after mini-batch   231: 0.005\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.005\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.005\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Epoch 10 done\n",
            "Starting Epoch 11\n",
            "Loss after mini-batch     1: 0.000\n",
            "Loss after mini-batch    11: 0.005\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.005\n",
            "Loss after mini-batch    61: 0.005\n",
            "Loss after mini-batch    71: 0.005\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.003\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.005\n",
            "Loss after mini-batch   131: 0.005\n",
            "Loss after mini-batch   141: 0.003\n",
            "Loss after mini-batch   151: 0.005\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.005\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.005\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.005\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.005\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.005\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.005\n",
            "Epoch 11 done\n",
            "Starting Epoch 12\n",
            "Loss after mini-batch     1: 0.000\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.005\n",
            "Loss after mini-batch    41: 0.005\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.005\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.005\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.005\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.005\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.005\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.005\n",
            "Loss after mini-batch   281: 0.005\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.005\n",
            "Loss after mini-batch   321: 0.005\n",
            "Loss after mini-batch   331: 0.004\n",
            "Epoch 12 done\n",
            "Starting Epoch 13\n",
            "Loss after mini-batch     1: 0.000\n",
            "Loss after mini-batch    11: 0.003\n",
            "Loss after mini-batch    21: 0.005\n",
            "Loss after mini-batch    31: 0.005\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.005\n",
            "Loss after mini-batch   111: 0.003\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.005\n",
            "Loss after mini-batch   161: 0.005\n",
            "Loss after mini-batch   171: 0.005\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.005\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.005\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.005\n",
            "Loss after mini-batch   251: 0.005\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.005\n",
            "Loss after mini-batch   321: 0.005\n",
            "Loss after mini-batch   331: 0.005\n",
            "Epoch 13 done\n",
            "Starting Epoch 14\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.005\n",
            "Loss after mini-batch    41: 0.005\n",
            "Loss after mini-batch    51: 0.005\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.005\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.005\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.005\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.003\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.005\n",
            "Loss after mini-batch   181: 0.005\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.005\n",
            "Loss after mini-batch   231: 0.005\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.005\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.005\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.005\n",
            "Epoch 14 done\n",
            "Starting Epoch 15\n",
            "Loss after mini-batch     1: 0.000\n",
            "Loss after mini-batch    11: 0.005\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.005\n",
            "Loss after mini-batch    91: 0.005\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.005\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.005\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.005\n",
            "Loss after mini-batch   171: 0.003\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.005\n",
            "Loss after mini-batch   201: 0.005\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.006\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.005\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.005\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.005\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Epoch 15 done\n",
            "Starting Epoch 16\n",
            "Loss after mini-batch     1: 0.000\n",
            "Loss after mini-batch    11: 0.003\n",
            "Loss after mini-batch    21: 0.005\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.005\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.005\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.005\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.005\n",
            "Loss after mini-batch   211: 0.005\n",
            "Loss after mini-batch   221: 0.005\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.005\n",
            "Epoch 16 done\n",
            "Starting Epoch 17\n",
            "Loss after mini-batch     1: 0.000\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.003\n",
            "Loss after mini-batch    61: 0.005\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.005\n",
            "Loss after mini-batch   121: 0.005\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.003\n",
            "Loss after mini-batch   161: 0.005\n",
            "Loss after mini-batch   171: 0.005\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.005\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.005\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.005\n",
            "Epoch 17 done\n",
            "Starting Epoch 18\n",
            "Loss after mini-batch     1: 0.000\n",
            "Loss after mini-batch    11: 0.005\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.005\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.003\n",
            "Loss after mini-batch   171: 0.005\n",
            "Loss after mini-batch   181: 0.005\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.005\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.005\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.003\n",
            "Loss after mini-batch   301: 0.005\n",
            "Loss after mini-batch   311: 0.005\n",
            "Loss after mini-batch   321: 0.005\n",
            "Loss after mini-batch   331: 0.004\n",
            "Epoch 18 done\n",
            "Starting Epoch 19\n",
            "Loss after mini-batch     1: 0.000\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.005\n",
            "Loss after mini-batch    31: 0.005\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.005\n",
            "Loss after mini-batch    61: 0.005\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.003\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.005\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.005\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.003\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.005\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.005\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.005\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Epoch 19 done\n",
            "Starting Epoch 20\n",
            "Loss after mini-batch     1: 0.000\n",
            "Loss after mini-batch    11: 0.005\n",
            "Loss after mini-batch    21: 0.003\n",
            "Loss after mini-batch    31: 0.005\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.005\n",
            "Loss after mini-batch   101: 0.005\n",
            "Loss after mini-batch   111: 0.005\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.005\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.005\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.003\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.005\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.005\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.005\n",
            "Loss after mini-batch   331: 0.004\n",
            "Epoch 20 done\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGdCAYAAAAxCSikAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAABqzklEQVR4nO3deXhb5Zk3/u+RbEneN3mP9+yrQ0JMwg4mNmWAtLQNDNMEl6ZtIO/AeChM2pKwzS9Aad4MnZT0pYS1QOgMpTMtNQQXBygmIVsJ2e1435fYsmVbsqTz+0M6x0vsxJK1HEnfz3XpamMfHT9CcXz7ee5FEEVRBBEREZGCqXy9ACIiIqJLYcBCREREiseAhYiIiBSPAQsREREpHgMWIiIiUjwGLERERKR4DFiIiIhI8RiwEBERkeKF+HoB7mCz2dDc3IyoqCgIguDr5RAREdEUiKKIvr4+pKWlQaW6+B5KQAQszc3NyMjI8PUyiIiIyAUNDQ2YMWPGRa8JiIAlKioKgP0FR0dH+3g1RERENBUGgwEZGRnyz/GLCYiARToGio6OZsBCRETkZ6aSzsGkWyIiIlI8lwKWnTt3Ijs7GzqdDgUFBThw4MCUnvf2229DEASsWbNmzMfvueceCIIw5lFcXOzK0oiIiCgAOR2w7NmzB6Wlpdi6dSsOHz6MJUuWoKioCO3t7Rd9Xm1tLR566CFcffXVE36+uLgYLS0t8uOtt95ydmlEREQUoJwOWLZv344NGzagpKQE8+fPx65duxAeHo7du3dP+hyr1Yq7774bjz/+OHJzcye8RqvVIiUlRX7ExcU5uzQiIiIKUE4FLGazGYcOHUJhYeHIDVQqFBYWorKyctLnPfHEE0hKSsK999476TUVFRVISkrCnDlzsHHjRnR1dU16rclkgsFgGPMgIiKiwOVUwNLZ2Qmr1Yrk5OQxH09OTkZra+uEz/nss8/w0ksv4cUXX5z0vsXFxXjttddQXl6OZ555Bvv27cPNN98Mq9U64fXbtm1DTEyM/GAPFiIiosDm0bLmvr4+fO9738OLL74IvV4/6XV33nmn/P8XLVqExYsXIy8vDxUVFbjxxhsvuH7z5s0oLS2V/yzVcRMREVFgcipg0ev1UKvVaGtrG/PxtrY2pKSkXHB9dXU1amtrceutt8ofs9ls9i8cEoLTp08jLy/vgufl5uZCr9ejqqpqwoBFq9VCq9U6s3QiIiLyY04dCWk0Gixbtgzl5eXyx2w2G8rLy7Fy5coLrp87dy6OHTuGo0ePyo/bbrsN119/PY4ePTrprkhjYyO6urqQmprq5MshIiKiQOT0kVBpaSnWr1+P5cuXY8WKFdixYweMRiNKSkoAAOvWrUN6ejq2bdsGnU6HhQsXjnl+bGwsAMgf7+/vx+OPP4477rgDKSkpqK6uxsMPP4yZM2eiqKhomi+PiIiIAoHTAcvatWvR0dGBLVu2oLW1Ffn5+SgrK5MTcevr6y85cXE0tVqNr776Cq+++ip6enqQlpaG1atX48knn+SxDxEREQEABFEURV8vYroMBgNiYmLQ29vLWUJERER+wpmf35wlRERERJOy2kSU7jmK//joLIaGJ2434g0MWIiIiGhSTecH8e6RJuysqIJG7buwgQELERERTaqmywgAyE4Ih0ol+GwdDFiIiIhoUrWdUsAS4dN1MGAhIiKiSdU4ApYcPQMWIiIiUqha6UiIAQsREREpFY+EiIiISNGGrTY0nB8EwCMhIiIiUqjG84Ow2kSEhaqRHO3b7vMMWIiIiGhC0nFQVkI4BMF3Jc0AAxYiIiKahFIqhAAGLERERDQJpVQIAQxYiIiIaBLyDouPK4QABixEREQ0CSlg4Q4LERERKZLJYkVzjzJKmgEGLERERDSBhu4B2EQgUhsCfaTG18thwEJEREQXqukcAABk631f0gwwYCEiIqIJKKUlv4QBCxEREV2gpks5PVgABixEREQ0Ae6wEBERkeLVKqikGWDAQkREROMMDVvR3DsEgEdCREREpFB1XfYKoWhdCOLCQ328GjsGLERERDTG6KGHSihpBhiwEBER0ThKaskvYcBCREREYyitQghgwEJERETjSD1YchMZsBAREZFCcYeFiIiIFM1osqC9zwSAOSxERESkULWO46D4CA1iwpRR0gwwYCEiIqJRaqUpzQnhPl7JWC4FLDt37kR2djZ0Oh0KCgpw4MCBKT3v7bffhiAIWLNmzZiPi6KILVu2IDU1FWFhYSgsLMTZs2ddWRoRERFNg7TDoqTjIMCFgGXPnj0oLS3F1q1bcfjwYSxZsgRFRUVob2+/6PNqa2vx0EMP4eqrr77gc88++yyef/557Nq1C/v370dERASKioowNDTk7PKIiIhoGuSmcQpKuAVcCFi2b9+ODRs2oKSkBPPnz8euXbsQHh6O3bt3T/ocq9WKu+++G48//jhyc3PHfE4URezYsQM///nPcfvtt2Px4sV47bXX0NzcjPfee8/pF0RERESuU9rQQ4lTAYvZbMahQ4dQWFg4cgOVCoWFhaisrJz0eU888QSSkpJw7733XvC5mpoatLa2jrlnTEwMCgoKJr2nyWSCwWAY8yAiIqLpk46ElDL0UOJUwNLZ2Qmr1Yrk5OQxH09OTkZra+uEz/nss8/w0ksv4cUXX5zw89LznLnntm3bEBMTIz8yMjKceRlEREQ0AcPQMDr7zQD8fIfFWX19ffje976HF198EXq93m333bx5M3p7e+VHQ0OD2+5NREQUrKTjIH2kFpHaEB+vZiynVqPX66FWq9HW1jbm421tbUhJSbng+urqatTW1uLWW2+VP2az2exfOCQEp0+flp/X1taG1NTUMffMz8+fcB1arRZardaZpRMREdEljExpVlZJM+DkDotGo8GyZctQXl4uf8xms6G8vBwrV6684Pq5c+fi2LFjOHr0qPy47bbbcP311+Po0aPIyMhATk4OUlJSxtzTYDBg//79E96TiIiIPGOkB4uyjoMAJ3dYAKC0tBTr16/H8uXLsWLFCuzYsQNGoxElJSUAgHXr1iE9PR3btm2DTqfDwoULxzw/NjYWAMZ8/MEHH8RTTz2FWbNmIScnB48++ijS0tIu6NdCREREniMn3Cpo6KHE6YBl7dq16OjowJYtW9Da2or8/HyUlZXJSbP19fVQqZxLjXn44YdhNBrxwx/+ED09PbjqqqtQVlYGnU7n7PKIiIjIRUrtwQIAgiiKoq8XMV0GgwExMTHo7e1FdHS0r5dDRETkl/Kf+BA9A8P4ywNXY16q53+eOvPzm7OEiIiICD0DZvQMDANQZg4LAxYiIiKSj4NSonUI06h9vJoLMWAhIiKiUUMPlVfSDDBgISIiIgA1jpJmpbXklzBgISIiopGhhwrMXwEYsBARERFGcliUNkNIwoCFiIgoyImiKO+w8EiIiIiIFKnLaEafyQJBADLjmXRLRERECiTtrqTFhEEXqrySZoABCxERUdCrUfhxEMCAhYiIKOgpvQcLwICFiIgo6NU6erAotaQZYMBCREQU9HgkRERERIomiuKoIyEGLERERKRAHX0mDJitUAlARhxzWIiIiEiBpOOgGXHh0IQoNyxQ7sqIiIjI45Tekl/CgIWIiCiI1TjyV3ISlHscBDBgISIiCmq13GEhIiIipZN7sDBgISIiIiWy2UZKmnMU3DQOYMBCREQUtFoNQzBZbAhRCZgRF+br5VwUAxYiIqIgJeWvZMaHI0St7JBA2asjIiIij6nxgw63EgYsREREQUquEFJ4/grAgIWIiCho1TgqhHL0yu7BAjBgISIiClr+MPRQwoCFiIgoCFltIuq7HD1YeCREREREStTcMwiz1QaNWoW0WGWXNAMMWIiIiIKSNPQwMyEcapXg49VcGgMWIiKiICTnr/jBcRDgYsCyc+dOZGdnQ6fToaCgAAcOHJj02nfffRfLly9HbGwsIiIikJ+fj9dff33MNffccw8EQRjzKC4udmVpRERENAXSDos/VAgBQIizT9izZw9KS0uxa9cuFBQUYMeOHSgqKsLp06eRlJR0wfXx8fH42c9+hrlz50Kj0eBPf/oTSkpKkJSUhKKiIvm64uJivPzyy/KftVqtiy+JiIiILsVfpjRLnN5h2b59OzZs2ICSkhLMnz8fu3btQnh4OHbv3j3h9ddddx2++c1vYt68ecjLy8MDDzyAxYsX47PPPhtznVarRUpKivyIi4tz7RURERHRJdU6KoSUPvRQ4lTAYjabcejQIRQWFo7cQKVCYWEhKisrL/l8URRRXl6O06dP45prrhnzuYqKCiQlJWHOnDnYuHEjurq6Jr2PyWSCwWAY8yAiIqKpsVhtaOh2BCyJ/hGwOHUk1NnZCavViuTk5DEfT05OxqlTpyZ9Xm9vL9LT02EymaBWq/HrX/8aN910k/z54uJifOtb30JOTg6qq6vx05/+FDfffDMqKyuhVqsvuN+2bdvw+OOPO7N0IiIicmg8PwiLTYQuVIXkKJ2vlzMlTuewuCIqKgpHjx5Ff38/ysvLUVpaitzcXFx33XUAgDvvvFO+dtGiRVi8eDHy8vJQUVGBG2+88YL7bd68GaWlpfKfDQYDMjIyPP46iIiIAkHNqAohlR+UNANOBix6vR5qtRptbW1jPt7W1oaUlJRJn6dSqTBz5kwAQH5+Pk6ePIlt27bJAct4ubm50Ov1qKqqmjBg0Wq1TMolIiJykT8NPZQ4lcOi0WiwbNkylJeXyx+z2WwoLy/HypUrp3wfm80Gk8k06ecbGxvR1dWF1NRUZ5ZHREREU+BvFUKAC0dCpaWlWL9+PZYvX44VK1Zgx44dMBqNKCkpAQCsW7cO6enp2LZtGwB7vsny5cuRl5cHk8mE999/H6+//jpeeOEFAEB/fz8ef/xx3HHHHUhJSUF1dTUefvhhzJw5c0zZMxEREblHTZf/TGmWOB2wrF27Fh0dHdiyZQtaW1uRn5+PsrIyORG3vr4eKtXIxo3RaMR9992HxsZGhIWFYe7cuXjjjTewdu1aAIBarcZXX32FV199FT09PUhLS8Pq1avx5JNP8tiHiIjIA2o6+wH415GQIIqi6OtFTJfBYEBMTAx6e3sRHR3t6+UQEREpltliw9xH/wKbCBz46Y1IivZdlZAzP785S4iIiCiI1HcPwCYCERo1EqP85ySDAQsRUZA42WLA3b/9Aofqun29FPIhKeE2KyECguAfJc2Al/qwEBGR7+35sgF/q+pCUlQ9lmXF+3o55CPSlOYcP6oQArjDQkQUNKra+8f8LwWnGrmk2X8qhAAGLEREQaO6o1/+X5vN7+styEUjOyyRPl6JcxiwEBEFgX6TBS29QwCAAbMVLYYhH6+IfKW20/96sAAMWIhoAlabiADoeECjVI87BuKxUHAaGraiuXcQgH/1YAEYsBDROP0mC6559mNsfOOwr5dCbiQdB0kYsASn+u4BiCIQpQtBfITG18txCquEiGiMY429aOoZRJthCMNWG0LV/L0mEIwPUBiwBCcp4TZH718lzQB3WIhonPpu+z9oFpuI5p5BH6+G3EUKUJZkxAK48IiIgkONH05pljBgIaIx6hxD0QCgdtT/J/8mHQkVL0gBAFR1MGAJRv44pVnCgIWIxqjvHglS6hzlj+Tfhq02ORBdvcA+qLbbaEa30ezLZZEPjBwJ+VeFEMCAhYjGGR2wSP+4kX+r6zLCYhMRrlEjVx+B9NgwAMxjCUZSDxYeCRGR3xt9JFTHI6GAUNVu/yGVlxgJQRAwMynS8XEGLMFkwGxBm8EEwP/a8gMMWIholN6BYfQODst/ruWRUECQ8lekQIUBS3CSGsbFhociNty/SpoBBixENEqdo0IoVG0vd2zoHoCVLdz9nhSYjA9Yzrb3+WxN5H3+fBwEMGAholGkI6BF6THQqFUYtrK0ORBIOyx5ifYfVFLAwtLm4CLlpOX64XEQwICFiEaREm6z9RHIiLcnZjKPxb+JoigHJvIOS6L9f5t7h2A0WXy2NvIufy5pBhiwENEo9Y7gJCs+Qt42Zh6Lf2vpHYLRbEWISkCW4z2Ni9BAH2nPYRjfsp8Cl3wkxICFiPydlMOSlRAu/3BjLxb/JgUkmQnhY8Ys5CUy8TbY1EhTmpnDQkT+TtphyUwIR7ajsRS73fo3OeHWEaBIWCkUXPqGhtHZby9pzvbDpnEAhx8SkYPJYkWLYQgAkBkfjr4he24Dd1j82/gKIQkDluAilTTrIzWI0oX6eDWu4Q4LEQEAGroHIYpAhEaNhAgNshPsv4XVdQ3AxtJmvzVSITRJwMIclqBQ4+clzQADFiJykKY0ZybYx86nx4YhRCXAZLGhrW/Ix6sjV0ldbifbYanrGoDZYvP6usi7/L1CCGDAQkQOdXKFkH1nJUStwow4e2mztJ1M/qV3YCRvITdx7A+qlGgdIrUhsNpEHvsFgVp56CEDFiLyc1IPlqyEkYQ8Vgr5N+m4JyVad0HegiAIciM55rEEPh4JEVHAGF0hJJHyWFgp5J/GN4wbL09u0c+AJdCNHAn5Z4UQwICFiBzqukeaxkm4w+LfxrfkH4+VQsGhd2AY5wfsQ025w0JEfs1mE+Ujocz4UTss7MXi1yYraZbMSooacx0FJuk4KClKiwit/3YzYcBCRGjrG4LZYkOISkBarE7++OgdFlFkabO/kXJY8iYJWKRA5lxnP0vXA1ggJNwCDFiICCMVQulxYQgZ1b49Iy4cKgEYMFvR4ag2If8wNGxFg2PXbHyXW0lGXBg0ahWGhm1o4lTugFUTzAHLzp07kZ2dDZ1Oh4KCAhw4cGDSa999910sX74csbGxiIiIQH5+Pl5//fUx14iiiC1btiA1NRVhYWEoLCzE2bNnXVkaEblATriNH5uQpwlRIT2OU5v9UW2XETYRiNKFIDFKO+E1IWqV/EOMx0KBy9+HHkqcDlj27NmD0tJSbN26FYcPH8aSJUtQVFSE9vb2Ca+Pj4/Hz372M1RWVuKrr75CSUkJSkpK8MEHH8jXPPvss3j++eexa9cu7N+/HxERESgqKsLQEJtVEXnDRCXNEilJT/otjfzD6PwVQRAmvY6Jt4FP+t7154RbwIWAZfv27diwYQNKSkowf/587Nq1C+Hh4di9e/eE11933XX45je/iXnz5iEvLw8PPPAAFi9ejM8++wyAfXdlx44d+PnPf47bb78dixcvxmuvvYbm5ma8995703pxRDQ1E1UISbLkFv0MWPxJtaPD7fiW/OPlMWAJaKIoBueRkNlsxqFDh1BYWDhyA5UKhYWFqKysvOTzRVFEeXk5Tp8+jWuuuQYAUFNTg9bW1jH3jImJQUFBwaT3NJlMMBgMYx5E5Lr6Lqkt/+Q7LKwU8i9Swu1kFUISzhQKbN1GszzIdKIdVH/iVMDS2dkJq9WK5OTkMR9PTk5Ga2vrpM/r7e1FZGQkNBoNbrnlFvzqV7/CTTfdBADy85y557Zt2xATEyM/MjIynHkZRDRO3QQlzRL2YvFP8pHQJXZYpM9XtfezEiwASfkraTE66ELVPl7N9HilSigqKgpHjx7Fl19+iX//939HaWkpKioqXL7f5s2b0dvbKz8aGhrct1iiINM7OIweR1OpiQIWeWpz5wB/oPkJm03EuUuUNEtyEyMgCPa/B539Zm8sj7yoxjEHzN8TbgHAqQ4yer0earUabW1tYz7e1taGlJSUSZ+nUqkwc+ZMAEB+fj5OnjyJbdu24brrrpOf19bWhtTU1DH3zM/Pn/B+Wq0WWu3EWe9E5BypQkgfOXFTqYz4cAgC0GeyoNtoRkIkv/eUrqlnECaLDRq1ChmOKq/J6ELVyIgLR333AKra+yetKCL/FAhTmiVO7bBoNBosW7YM5eXl8sdsNhvKy8uxcuXKKd/HZrPBZLL3dMjJyUFKSsqYexoMBuzfv9+pexKRa+q67f+gTXa+rQtVIzXa3kyOeSz+QToOytFHjOmrM5mRSqE+j66LvE/qcpvj5xVCgJM7LABQWlqK9evXY/ny5VixYgV27NgBo9GIkpISAMC6deuQnp6Obdu2AbDnmyxfvhx5eXkwmUx4//338frrr+OFF14AYJ8Y+uCDD+Kpp57CrFmzkJOTg0cffRRpaWlYs2aN+14pEU1I6q+SNcFxkCQrIQLNvUOo6zJiWVact5ZGLpJnCCVN7YfUrKRI/PVUOyuFAlAg7bA4HbCsXbsWHR0d2LJlC1pbW5Gfn4+ysjI5aba+vh4q1UhEbzQacd9996GxsRFhYWGYO3cu3njjDaxdu1a+5uGHH4bRaMQPf/hD9PT04KqrrkJZWRl0Ot0FX5+I3EvqhjpRhZAkWx+OynNd3GHxE1NNuJXksVIoIImiOKotv39XCAEuBCwAsGnTJmzatGnCz41Ppn3qqafw1FNPXfR+giDgiSeewBNPPOHKcohoGuQdlosELKwU8i9SwHKphFsJm8cFpo5+E4xmK1SCPRfN33GWEFGQm2hK83hSpRB3WPyDfCQ0xR0WKWBpM5hgGBr22LrIu2o7R2aEaUP8u6QZYMBCFNRMFiuae+1D7zIn6HIr4Q6L/+jqN+H8wDAEYeoBS7QuFEmO6qBq7rIEjNoAackvYcBCFMQazw9CFIFwjRr6SM2k10nHRT0Dw+gZYK8OJZOOddJjwxCmmfpv1TwWCjznAqQlv4QBC1EQGz2l+WID8sI1IfJv4JzarGzVHVObITSeP7To/+hEG8pPtl36QgLAHRYiCiDSEc9UZoyMzBTisZCSjZ7S7AzpeqUeCXX1m/CjNw7hR68fQu8A82ymQvpe5Q4LEfm9+m57/krWFH4DG5nazB0WJaue4tDD8UbPFFKiQ3XnYbWJsNhEHG/p9fVyFM9mE+WAJRB6sAAMWIiCWr2jy+3FKoQk0j963GFRNrmk2cUjofruAQwNW92+ruk6VH9e/v8nmg0+XIl/aOsbwtCwDWqVgBmXGM/gLxiwEAWxuq5LlzRLuMOifANmC5p67Ltmzu6wJEZpEaULgU0EajqVF5QeqmXA4gzpPcyIC0PoFMYz+IPAeBVE5DSbTZR7sDiTw8LSZuU650i4jQsPRXzE5FVfExEEAbMUWilksljxVdPIMdCJFgYsl1IbQFOaJQxYiIJUe58JJot9yzgt9tJbxlJQ09lvRh+biymSq/krEqWWNn/dZIDZYoMu1P4jq6q9X5HHVkoi568ESIUQwICFKGhJOyXpsVPbMo7Shcq9WngspEyuVghJlFrafKiuGwBw9axExIWHwmITcbZNWWtUmpoA68ECMGAhClp1ThwHSbJY2qxozrbkH0+ppc0HHfkry7PiMD8tGgBwgpVCF1XLgIWIAkXDFGYIjcfEW2VzdujheDMTowDYO6RabaLb1jUdoijisKNCaFlWHOanOgIWJt5OymoT5V9IGLAQkd+bypTm8eTmcQqsIgl2FqtNPgaY6eIOi31Ingpmi00OaH2trmsAnf1maNQqLEyPwYK0GADAcQYsk2ruGYTZYoNGrZpSfpq/YMBCFKTquMMSUBrOD2LYKkIXqkK6iz+k1CoBuQprIHewzr67smhGDHShavlI6GSLATaF7AIpjXRkmxEfBrVq8pEb/oYBC1GQqu+SmsZNfcuY7fmVSwowcvWRUE3jh5TSEm8P1Y0cBwFArj4C2hAVjGarHHTTWIGYvwIwYCEKSoahYZx3zGPJdOFIqL3PhAGzxSNrI9dMt0JIorQW/VKFkBSwhKhVmJtiz7VhHsvEaqQeLAFU0gwwYCEKStKUZn2kBpHakCk/LyY8FLHhoQB4LKQ0060QkiipF0vvwDDOOMqXpYAFACuFLiHQZghJGLAQBSFnWvKPl8WOt4rkth2WUaXNoujbHJHDDfbjoOyEcOgjtfLH5zPx9qJ4JEREAWOkJb/z/6BlO46QarnDohiiKMq9U6YbsGTrw6FWCegzWdBmMLljeS6T5gcty4of83GWNk/OYrXJ39/cYSEiv+fMlObxuMOiPB19JvSZLFAJ9oBjOrQhamQ5/l74+ljooCN/ZXl23JiPz02JgiDYc6k6+nwbVClNU88gLDYR2hAVUqN1vl6OWzFgIQpC0zkSkndYOrnDohRSYJEZHw5tiHra98uT81j6pn0vVw1bbfh7gz1HZXT+CgBEaEPk4w4OQhxL6sWTlRA+rWoxJWLAQhSEXGkaJ+EOi/JUTXPo4XhKKG0+2WLA4LAV0bqQCRvh8VhoYlL+SqBVCAEMWIiCjtliQ0vvIADnSpol0g5Lc+8QJ+YqhJS/Mt0KIYkSSptH91+ZaKdgpOMtK4VGk3LLAi3hFmDAQhR0Gs8PwCYC4Ro1EkdVXkxVfIQGUY5SaKW0bw920k6IqzOExhspbfbdLtrBcQ3jxhspbeYOy2iBOKVZwoCFKMiMbskvCM6fcQuCgCw9K4WUxF0lzRIp8OnsN6HX0WDQm0RRnLRCSCIdCdV0GtnEcBQpYAm0CiGAAQtR0HFlSvN4zGNRjr6hYbn82F1HQpHaEKTG2CtMqjq8n3jb3DuEVsMQ1CoBSzJiJrwmMUqLpCgtRBE42eK75GAlMVtsaDzPIyEiChDTSbiV5HCmkGJUd9jfg8QoLWLCQt12X192vD1Yay9nXpAWjXDN5J2YeSw0VsOo496kKOePe5WOAQtRkJlOSbOEU5uVQz4OctPuiiTPh4m34wceToaVQmPVyiXNES4d9yodAxaiICM3jZtG2aN0Ps4dFt+TZwglufcIwJc7LFMNWKRKoROsFAIwOuF2es0DlYoBC1EQEUVxpC2/G3ZYms4PwmyxuWVt5BpP7bDMcgQsZ70csPSbLDjpOOJZPknCrUQ6EjrV2geLlX8P5aGHAdiDBXAxYNm5cyeys7Oh0+lQUFCAAwcOTHrtiy++iKuvvhpxcXGIi4tDYWHhBdffc889EARhzKO4uNiVpRHRRbT3mTA0bINaJSA9Lszl+yRGahGuUcMm2s/NyXeq5aZxUW69r7TD0tQziEGz9/rtHK3vgU0E0mPDkBJz8dbyWfHhiNCoYbLYcK6Tu31S9+lArBACXAhY9uzZg9LSUmzduhWHDx/GkiVLUFRUhPb29gmvr6iowF133YWPP/4YlZWVyMjIwOrVq9HU1DTmuuLiYrS0tMiPt956y7VXRESTknJO0mJ1CFW7vsEqCAIrhRTAbLHJ76m7j4QSIrWICw+FKI4ERd4w1eMgAFCpBMxjHosskHuwAC4ELNu3b8eGDRtQUlKC+fPnY9euXQgPD8fu3bsnvP53v/sd7rvvPuTn52Pu3Ln47W9/C5vNhvLy8jHXabVapKSkyI+4uEv/ZSUi50jBRVb89P9B40wh36vrMsJqExGpDUGKBwbdSbss3gxYJht4OBlWCtkNDVvR7OhgzSMhAGazGYcOHUJhYeHIDVQqFBYWorKyckr3GBgYwPDwMOLjx55NVlRUICkpCXPmzMHGjRvR1dXlzNKIaArkHizTKGmWcIfF9+SE20TPVIV4O/HWahNxpL4HwNR2WAB76TPAFv0N3QMQRXsPHX2kxtfL8YjJC9wn0NnZCavViuTk5DEfT05OxqlTp6Z0j0ceeQRpaWljgp7i4mJ861vfQk5ODqqrq/HTn/4UN998MyorK6FWXzh51GQywWQaGSluMAR3ZE00VXVuaBonkXdYWNrsM1VuniE0nrdLm8+09aHfZEGERo05yVPLyZmfKlUKGSCKYkCW807FSIdb1zpY+wOnApbpevrpp/H222+joqICOt3I9uWdd94p//9FixZh8eLFyMvLQ0VFBW688cYL7rNt2zY8/vjjXlkzUSCRm8a5IWDhDovvyQGLm1ryj+ftHRZpftDSzDiETDHHalZyJNQqAecHhtFqGEJqjOvJ5P5sJH/FM38XlMCpIyG9Xg+1Wo22trYxH29ra0NKSspFn/vcc8/h6aefxocffojFixdf9Nrc3Fzo9XpUVVVN+PnNmzejt7dXfjQ0NDjzMoiCVr0bj4SyHb0eGs8PYpglpT4hdbn11A6LFLDUdhm9UjZ82ImEW4kuVC2XYB9vCt7ddqmkOccN39tK5VTAotFosGzZsjEJs1IC7cqVKyd93rPPPosnn3wSZWVlWL58+SW/TmNjI7q6upCamjrh57VaLaKjo8c8iOji+oaG0W00AxjZHZmO5CgdtCEqWGwimnsGp30/co7NJo4qafZMwJIWE4awUDWGraJ8nOhJUsKtMwELMKrjbRAm3vYNDeOD46344pz9v12gljQDLhwJlZaWYv369Vi+fDlWrFiBHTt2wGg0oqSkBACwbt06pKenY9u2bQCAZ555Blu2bMGbb76J7OxstLa2AgAiIyMRGRmJ/v5+PP7447jjjjuQkpKC6upqPPzww5g5cyaKiorc+FKJgpt0HJQQoUGkdvqnwSqVgKyEcJxp60dt14BbgiCauhbDEAbMVoQ43gdPUKkE5CVF4OsmA6ra+z22kwMA7YYhNHQPQhCApZmxTj13flo03j3SFBSlzTabiK+be/HJmQ58cqYTh+vPw2IT5c9LVVOByOl/tdauXYuOjg5s2bIFra2tyM/PR1lZmZyIW19fD5VqZOPmhRdegNlsxre//e0x99m6dSsee+wxqNVqfPXVV3j11VfR09ODtLQ0rF69Gk8++SS02sAb3kTkK+48DpJkJUTgTFu/I48l0W33pUurduSVZCWET6unzqXMTIyUA5aiBR77MnL/lTnJUYjSOTfEUfohfbwlMCuF2g1D+ORsJz4504HPqjrlnVJJjj4C18zSo3hhKuamMGAZY9OmTdi0adOEn6uoqBjz59ra2oveKywsDB988IEryyAiJ7ijJf947MXiO3JLfg8dB0lmOap1qj2ceCsl3E61/8po0pFQQ/cgegeH3Tq12hdMFisO1Z7HvrP2XZST4466IrUhWJWXgGtmJ+La2YnIcOP3tJJ5tUqIiHzHHVOax2OlkO9UeTh/RSIdA3l6ppAcsFxiftBEYsM1SI8NQ1PPIE62GHBFboK7l+dRoiiiptNoP+Y524nK6i4MDo+MQxAEYFF6DK6ZlYhrZidiaWasR3fVlIoBC1GQcMeU5vGkjpqc2ux91R7uwSIZ3e3WZhOhUrm/x8fQsBXHm+zHOc4m3Ermp0WjqWcQJ5r9I2AxDA3j86oufHK2A5+c6UDj+bGJ64lRWkeAosdVM/VIiGSKBAMWoiAh92Bxaw6L/V4N3YOw2kSoPfDDjCbm6QohSVZCOEJUAgbMVrQYhpAe6/4+J39v6IHFJiIpSosZLg7lnJ8ajb0n2hRbKSSKIr5uMqDidDs+OduBw/U9sI5KltWoVVieHYdrZifimlmJmJcaFbAN4FzFgIUoCJgtNrn02J05LGmxYdCoVTBbbWjpHcSMuOA4S/e1ngEzOvvtiZee3mEJVauQrY9AVXs/qtr7PRKwjM5fcfWH9EiLfmUGLC99VoOn/nxyzMdy9RH2AGW2HlfkJiBcwx/JF8P/OkRBoKlnEDYRCAtVIzHKfVvLapWAjPgwVHcYUdc1wIDFS6TdldQYHSLcUKJ+KTMTI+WA5drZ7q8GkxrGXZbp+tBbqVKoqr0PZosNmhBl5Xj8z9+bAQCr8hJwy+JUXDMreJJl3UVZ7ygReYSUFJsZ7/45I8xj8T5vVQhJPNmi32YTcahe2mFxPuFWkh4bhpiwUAxbRZxt73PX8tyis9+ErxrtOTo77szH3QVZDFZcwICFKAi4c0rzeCOVQixt9hZPDz0cT0689UDAcq6zHz0Dw9CFquRjHVcIgiCXNyvtWOjTsx0A7MdWSVG6S1xNk2HAQhQEPFHSLJFmCtV2cofFW+QZQt7eYelwf8AiNYxbPGP6pbrSsZDSOt7uO20PWDxxnBZMGLAQBQFpDownWrhn8UjI6+QjIS/tsOQm2t/jbqP5gi6r03WwVuq/4nr+imSBAgMWm03EJ2c7ATBgmS4GLERBoN6TOyyOIKiuawC2UWWa5BlDw1Y0nLe/n97KYQnXhMjVQe7OYzk0jQ6348k7LC0Gxfxd/Lq5F91GM6K0IbjMDUFZMGPAQhTgRFEcacvvgQGF6bFhCFEJMFlsaOsbcvv9aayaTiNEEYjWhUAfqfHa152V7P7E226jGeccR4nTqRCS5CVGQhOiQr/JckEjNl+RjoOunKkPyu607sT/ekQBrqPPhMFhK1QCPNJDI0Stkpt9caaQ542uEPJmY7GZcot+91XgSLsrM5MiERs+/eArVK3CHMfso+PNyhiEWHHGkb8yh8dB08WAhSjASfkrabFhHutNwZlC3uPtkmaJJ0qbpYBlmRt2VyRSpZASOt72DgzjiKNk+xrmr0wbAxaiAFfvgZb848lTm1na7HFS0zhvlTRLPFHafKiuGwCwzA35K5IF6cpJvP2sqhM2EZiVFOmR3c1gw4CFKMBJOyyeSLiVcIfFe3y9w9LcOwSjyTLt+5ksVvzd0UzNHRVCEiX1Ytl3ph0Aq4PchQELUYCrl7vcuj/hViL3YuEOi0dZbSJqHEmq3g5YYsM1cpJvtRv6sRxvNsBssSE+QoMcvfv+bs5NjYYgAK2GIXT1m9x2X2eJooh9zF9xKwYsRAHOkz1YJKN3WERRGeWkgajp/CBMjjk5vpjbJB1DuSOP5VDtyPwgdyYPR2pD5HERvsxjOd3WhzaDCWGhalw+jZEDNIIBC1GA82QPFsmMuDCoBGDAbEWHD3+rDXRVHfYKnVx9BNQq71UISdyZeHvQkb/ijv4r48mJtz48FqpwlDOvzEuALlTts3UEEgYsRAGs32RBl6MzqSd3WLQhaqQ5kgo5U8hzqtu925J/PHcFLKIo4lBdDwBgmQeaqY1uIOcrbMfvfgxYiAKYlAQbH6FBlC7Uo19LntrMmUIe4+2hh+O5a6ZQffcAOvtN0KhVWJQe446ljSEFLL5KvO03WeQdJAYs7sOAhSiAeeM4SJI1qkU/eYYUKHg74VYifd26rgGYLTaX7yPND1qYHu2R45IFjiOhcx39GDRb3X7/S6ms7sKwVURWQjiy3ZhQHOwYsBAFsHovlDRLsjkE0aNEUfT60MPxUqJ1iNSGwGoTp1XCfsjRTM0Tx0EAkBStgz5SC5toT371NpYzewYDFqIA5o0KIYn0myR3WDyjy2hG7+AwBGFkerK3CYIg58+cnUYei1QhtCzLc9UzI8dC3m3RL4qinHB7HcuZ3YoBC1EA8+aR0Ei3W5Y2e4K0uzIjLsynVSczp1na3Ds4jDOOeUSe2mEBfFcpdK7TiMbzg9CoVbgiN8GrXzvQMWAhCmB13fZte09MaR4vIz4cggD0DVlwfmDY418v2PiqJf94060UOlJ/HqJo3/VLjNK6c2ljLPBR4q1UHbQiJx7hmhCvfu1Ax4CFKEANW21o7hkC4J0jIV2oGqnROgDMY/EEX+evSKYbsMgDDz24uwKMHAmdajXAavPejp/c3Zb5K27HgIUoQDWdH4TVJkIXqkKSB3+THY0zhTzHVzOExpO+/rnOfthcCAQO1nonYMlOiEBYqBpDwzZ5nIGnDQ1b8cW5LgBsx+8JDFiIAtTooYfubH1+MfJMoU4m3rrbuQ7fNo2TZMSFQaNWYWjYhqaeQaeea7HacLShBwCw3IMJtwCgVgmYlxoFwHuJt1+c64LJYkNajA6zfPw+BSIGLEQBypslzZIsljZ7hNFkkYMDXx8JhahV8rBCZ4+FTrb0YXDYiihdiFd+oHu74+3oYYfe+iUhmDBgIQpQ3pjSPN5IpRB3WNxJ2l1JiNAgLkLj49W4nsdyyNH99bLMOKi8MAtpQZq9i663KoWYv+JZDFiIApTUD8UbCbcS5rB4hlIqhCR5LgYsBx0Jt8s9nL8iGV3a7OlS+4buAZzrMEKtErBqpt6jXytYMWAhClDykZBXAxb71+oZGEbPgNlrXzfQyTOEFJIX4epMIblCyAMTmicyJyUKapWALqMZ7X2enSIu7a4sy4xDtIfndgUrlwKWnTt3Ijs7GzqdDgUFBThw4MCk17744ou4+uqrERcXh7i4OBQWFl5wvSiK2LJlC1JTUxEWFobCwkKcPXvWlaUREezfU1LAkuXFHJZwTYhckcSOt+6jlAohyaxROyxT3blo7hlES+8Q1CoB+RmxHlzdCF2oGnmOrsCeTryVutuyOshznA5Y9uzZg9LSUmzduhWHDx/GkiVLUFRUhPb29gmvr6iowF133YWPP/4YlZWVyMjIwOrVq9HU1CRf8+yzz+L555/Hrl27sH//fkRERKCoqAhDQ0OuvzKiINbRb8KA2QqVAMyI817AAnCmkCeMHAkpY5Bejj4CKsHetbazf2o7adJx0PzUaK82VPNGx1uzxYbPqzsBMH/Fk5wOWLZv344NGzagpKQE8+fPx65duxAeHo7du3dPeP3vfvc73HfffcjPz8fcuXPx29/+FjabDeXl5QDsvwnu2LEDP//5z3H77bdj8eLFeO2119Dc3Iz33ntvWi+OKFhJLflTY8KgCfHuyS+nNruXxWqTgz+l7LDoQtXIcOzcnW2f2nDBQ7X2hFtP918ZzxuVQgfrujFgtkIfqZUDJHI/p/4lM5vNOHToEAoLC0duoFKhsLAQlZWVU7rHwMAAhoeHER9vr8GvqalBa2vrmHvGxMSgoKBg0nuaTCYYDIYxDyIa4YuSZok0BJE7LO5R1z2AYauIsFA10mLCfL0cmVReXT3FxFtPT2iejFQp5MkW/VL+yjWz9V6pfgpWTgUsnZ2dsFqtSE5OHvPx5ORktLa2TukejzzyCNLS0uQARXqeM/fctm0bYmJi5EdGRoYzL8Mp9V0DXm3rTOQOvqgQknCHxb2kgCA3MUJRPwydKW02miw42WLfiVnupYRbyTzHjkdd1wD6hjwz40qaH8TjIM/y6l7x008/jbfffht/+MMfoNPpXL7P5s2b0dvbKz8aGhrcuMoRNpuI23Z+hvwnPsSG1w7ilb/V4ExbHyfRkuL5okJIks3SZreSKnGUchwkyXOiUuhoQw+sNhHpsWFI9fIuUXyEBqkx9p83p1qndnzljDbDEE619kEQgKtnMWDxJKcyn/R6PdRqNdra2sZ8vK2tDSkpKRd97nPPPYenn34aH330ERYvXix/XHpeW1sbUlNTx9wzPz9/wntptVpotZ6fjdLUY5/F0jdkwd4Tbdh7wv669ZFarMpLwKq8BFw5Uy+f5ZL/ONfRj5JXvsQ/FWRhwzW5vl6O20nBQpYXm8ZJpCCps9+MvqFhRLHEc1qq2x35KwrpwSJxZodFKme+zMvHQZIFadFo6R3C8aZeXJ7t3pEA0u7K4hmxiFdAU79A5tQOi0ajwbJly+SEWQByAu3KlSsnfd6zzz6LJ598EmVlZVi+fPmYz+Xk5CAlJWXMPQ0GA/bv33/Re3pDRnw4jjx6E/54/5V4uHgOrp6lhy5Uhc5+E/7n7834t3eP4epnP8ZVz/wVD//X3/HHo01oN7CyyR/8bn896roG8EzZKbkCI5DIJc0+2GGJ1oUiwfEPN4+Fpk/awVBKDxaJFLC0GUwwXOKoxdsN48aTK4U8kHgr5a9cx+Mgj3O6tqy0tBTr16/H8uXLsWLFCuzYsQNGoxElJSUAgHXr1iE9PR3btm0DADzzzDPYsmUL3nzzTWRnZ8t5KZGRkYiMjIQgCHjwwQfx1FNPYdasWcjJycGjjz6KtLQ0rFmzxn2v1EUhahWWZMRiSUYs7rtuJkwWK47U9+Dz6i5UVnfiSH0PGs8P4p2DjXjnYCMA+zfylXkJWJmnxxW58YgNZ9StJKIoouxr+99Di03Ev//5JHbfc7mPV+U+/SaLXGrqiyMhwB4odRnNqOsawML0GJ+sIRCIoijnsCjtSChaF4qkKC3a+0yobu/H0syJgxGrTcSROt8k3ErmSy363RywWKw2fHqW/Ve8xemAZe3atejo6MCWLVvQ2tqK/Px8lJWVyUmz9fX1UKlGNm5eeOEFmM1mfPvb3x5zn61bt+Kxxx4DADz88MMwGo344Q9/iJ6eHlx11VUoKyubVp6Lp2hD1LgiNwFX5CYAN82G0WTBl7XdqKzuwt+qO3G82YCq9n5Utffj1co6CAKwMC0Gq/ISsDIvASty4r3ag4AudLzZgKaeQWhDVLDaRPz1VDs+Pt2O6+ck+XppbiGVNMeFh/qs42a2PgKH63tYKTRN7X0m9JssUKsEn+yWXcrMpEi095lQdZGA5Wx7H/pMFoRr1JibEuXlFdotcJQ2n2ntx7DVhlC1e9I3/97YA8OQBTFhoVgyI9Yt96TJufSTc9OmTdi0adOEn6uoqBjz59ra2kveTxAEPPHEE3jiiSdcWY5PRWhDcN2cJFzn+GHXM2DGF+e68Hm1/VHV3o9jTb041tSL33xyDqFqe5fHVXl6rMpLQH5mLLQhah+/iuDywXH77sp1cxIxIy4cL31Wg6f+dAJXzdS77R8yX/JlSbOEibfuIeWHZMaHK/LfiZlJkfZ/5y5yrHqw1r67sjQzFiE++v6aEReGKF0I+oYsqGrvlyuHpkvKX7l6lh5qBVVwBSr+qu9mseEaFC9MRfFCewJxm2EIldVd+Ly6E3+r6kJTzyC+rD2PL2vP4z/Kz0IXqkJmfDgSIrSIj9RAH6FBfIQWCZEaJERoEB+hQUKkFgkRGsSEhSqqrNFfSQFL8cIU3DA3GX840oTqDiNer6zD96/K8fHqpq++2zGlOcF3XVGzOLXZLeQZQgpLuJVILfov1otFnh80yQ6MNwiCgPmp0dhf043jzQa3BSwVnM7sVQxYPCw5Woc1S9OxZmk6RFFEQ/egPXhx5MB09ptxpq0fwKUTP9UqAXHh9kAmIdIezOgjtYiPkP7/2GAnWscAZ7xzHf0409aPEJWAG+YkIyYsFA+tnoOf/uEY/u9HZ3B7fhoSIj1fgeZJcg8W7rD4vWqFljRLpjK1eWTgoXurc5w1P80esJxoNgDLpn+/zn4Tvmq0zydiwOIdDFi8SBAEZCaEIzMhE3euyLQn1HUY0dI7iG6jGV39ZnQZTeg2mtHZb0a30ez4/yb0DVlgtYno7Dehs98EtF3666lVAlJjdHikeC5uXZLm+RfoBz44bv8PtzIvATHh9vyOtZdn4PUv6nCyxYDte8/g37+5yJdLnDZf9mCRSAFLm8GEAbOFeVsuGtlhUcYMofGkQKq+ewBDw1boQsceW7X3DaG+ewCCYD8S8qWRSiH3DEH87GynfN+kaOXlWwYi/iviQ4IgYGZS5JR+ezJZrDhvHJYDGntwY0ZXv+PP4/6/FOA0nh/E/3nrCDr6TAFx3DFdZY7joKIFI32D1CoBW2+djzv/3xd460A9/umKLLdtGfuCEnZYYsJDERseip6BYdR3D2Buiv/+9/QlpU1pHi8xUotoXQgMQxbUdBov+L457NhdmZMc5bMEcInUov9EswGiKEIQprf7LJUzszrIexiw+AltiBopMWqkxEwtkpcCnF37qvHK57V44k8n0Nlvwk+K5kz7G9VftfQO4u8NPRAEYPX8saMgrshNwDcWpeD9Y6144n9P4M0NBX7532nYakNTzyAAIMuHOSzS1+8Z6EFtJwMWVxiGhtHeZwKgvB4sEumXrsP1PRMms0oJt74qZx5tZlIkQtUCDEMWNJ4fnFbDT5tNxCfMX/E6/y+JoAnZAxwdtt46Hw+tng0A+HVFNf7tv4/BYrX5eHW+8aHjOOiyzLgJt3A33zwPmhAVKs91yYm5/qbZ0Z1ZG6JCUpRvc3Gy5cRb5rG4QkpkTYrS+nx34mIu1vFWbhjn5flBE9GEqDA72V5WPd1+LF8396LLaEakNgSX+TCZONgwYAlwgiBg0w2zsO1bi6ASgD0HG7Dxd4cxNGz19dK8Tq4OWjDxGImM+HD8yNGm/6k/n/TL/0ZS/kpGfLjPE66zmHg7LUo/DpLMnGSm0NCwFceb7fkiyzJ9m3ArkfJYpju5WSpnXpWXAE0If4x6C/9LB4m7VmTi13cvgyZEhb0n2rDupQPoHfTM5FIlOm80Y39NN4Cx+SvjbbwuDynROjSeH8RLn9V4a3luo4T8FYm8w9LJ0mZXVHfYAz2lljRLZk5S2vxVYy+GrSISo7TIiPfuwMPJzHc0kDsx3YBFascfIM0m/QUDliBSvDAFr31/BaK0IThQ2421v6kMmtlHH51sg9UmYl5q9EWrZ8I1Ifi3m+cCAHZ+XIU2P/vvo4QKIQl3WKbHb3ZYEu3HLOc6jbDaRibZH6yz/4KwPCtOMflgI4m3rlcK9Q4M43C9/ajrmtl6t6yLpoYBS5C5IjcBe360EolRWpxq7cO3XvgcNZ2B/wPlA7k6KPkSVwK356dhaWYsBsxWPFN2ytNLc6uRKc2+D1ikHZbm3iG/PF7zNaX3YJGkx4VBG6KC2WJDQ/fIbtphH88PmsjcVHtw1dw7hPNGs0v3+Ft1J2yi/X2ZEef777NgwoAlCM1Pi8Z//3gVshPC0Xh+EN9+4XMca3RPbwIlMpos+MTRM6F44eTHQRJBELD11gUAgHcPN+GI47cpfyAfCfm4QggA4iM0iNLaCxFH/yCjSzNZrPJumdKPhNQqAbmJYxNvRVEcaRinoIAlWhcqj6w46WLibcXpdgCsDvIFBixBKjMhHL//8SosTI9Gl9GMO/9fpdwIKdBUnO6A2WJDVkI45iRPbfhafkYs7rhsBgDg8f89AduorW6lEkVRUUdCgiAgS88W/a6o6xqA1SYiUhuC5Gjld16eNS7xtrrDiPMDw9CGqORjGKWQBiG6kngriuJI/xUGLF7HgCWIJUZp8daGK7AqLwFGsxUlrxzAn75q9vWy3G50dZAzZ+mPFM9BhEaNow09eO9ok6eW5zad/WYMmK0QBPuwNyVgHotr5A63SZGKyf+4mPGlzdJx0JIZsYqrohnpeOt8wHK6rQ9tBhN0oSqsyFFG5VMwUdbfJPK6KF0oXi65HLcsSsWwVcT/eesIXqus9fWy3MZkseKvp+xbuKsvUh00kaRoHe6/YSYA4JmyUzCaLG5fnztJQw9To3WKmezLXiyuqVZ4S/7xxgcsUsLtMgX0XxlvQbrrlUJSOfPK3IQLxhCQ5zFgIWhD1Hj+rqX43hVZEEVgyx+PY/veMxBF5R+DXMrn1V3oN1mQFKXF0oxYp5///StzkBEfhjaDCS9UVLt/gW6kpOMgycgOC4+EnFHlJwm3ktEBiyiKcsM4X05onsz8VPsRVVVHv9PJ4DwO8i0GLATAnjj3xO0L8C+F9q64z5efxc/e+3pMmaI/+uBr+3HQ6gXJLjVS04Wq8bNvzAcA/L9Pzyk6eXSkB4tyfiuXhiByh8U5ckmzwhNuJdkJEVCrBPSbLDjV2odzjh4ySkq4lSRH2yfcW20izrT1Tfl5/SYLvqy17xxdy/4rPsGAhWSCIOCBwll4as1CCALw5v563O/HXXGtNhF7T9jb8RcvSHX5PkULkrEqLwFmiw3/3/sn3bU8t6vvUt4Oi3Qk1HR+EGZLcI6EcJbNJso/8JU6Q2g8TYhKLqV/52ADAPtxVlyExpfLmpAgCC4l3lZWd2HYKiIzPlz+e03exYCFLvBPV2Th1/94GTRqFcqOt+Kelw/AMOR/XXEP1najy2hGTFgoCnJdT5ATBAFbbp0PlQD85etWVFZ3uXGV7lPXLZU0K+cf08QoLcI1athEoPG8cnenlKS5dxCDw1aEqgVF9NOZKim4+sMRe4K6EndXJHLirRMBy74zI+XM/pAIHYgYsNCEbl6Uile+fzkitSH44lw37vzNF2jv86+urx84hh3eOC8Joerp/VWfmxKNuwuyAACP/+9xRR6VKfFISBAE5rE4SToOyk6IQMg0/956k5TH0jNg/+VmeZZyq2jkFv1TrBQSRREVp6V2/Mxf8RX/+W4gr1uVp8fbP7wC+kgNTrQY8O0XKv2mPFUUxVHdbZ2rDprMv9w0G9G6EJxq7cPbX9a75Z7uYjRZ0NlvAqCsIyGAlULO8pcZQuONz7dRYoWQRDoSOtlimNIvHzWdRjSeH4RGrcIVuQmeXh5NggELXdTC9Bj8149XITM+HPXdA7jjhUp83aT8rrjHmw1o6hlEWKga18xyz29E8REa/MtN9qTkX354RlHDI6UKoZiwUMSEhfp4NWNxh8U5/jJDaLzR640LD0WuXjk7fePl6COhC1VhwGyd0i9hUnXQ5TlxiHB0bybvY8BCl5Stj8B/bVyJ+anR6Ow34c7/9wU+r1Z2V9wyR3XQtbMTEaZxX7+Ef7oiCzOTItFtNOP58rNuu+901Sswf0XCHRbn+MsMofFGJwgvU9DAw4moVQLmpkz9WEg6DmI5s28xYKEpSYrS4e0fXYErcuPRb7Lgnt1f4i/HWny9rEnJ3W2nMDvIGaFqFR79B3uZ86uf18q/DfuaXCGkwCRN7rA4Z6RpnH8FLJHaEKTF6AAAyxScvyKZP8VKoaFhK744Z0+0v3Y2y5l9iQELTVm0LhSvlKxA8YIUmK023PfmYfxuf52vl3WB6o5+nG3vR4hKwPVz3f8PzLWzE1E4LwkWm4in/nzC7fd3RZ2jy60id1gc84QaugdgsbK0+WLOG83ockwRzktS7pHKZIoWpiBco57SVHRfm2ql0P6abpgsNqRE6zA72b+CyEDDgIWcogtVY+fdl+GuFZkQReBnf/haccdD0u7Kqpl6j+Vz/OyW+QhVC6g43YGPHa3/fUmJFUKS5CgdtCEqWGwimnv8q9LM2/bX2BuTpceGIVzjf7kSW29dgGOPFcnTm5Vsqr1Y9o2qDlLyMVcwYMBCTlOrBPx/31yI7y63TzP+xQenFdXGX+pu68nf8nL0ESi5MgcA8OSfTvi8KZoS2/JLVCpB3vlhHsvkbDYROz46AwC4LT/Nx6txndqFjtK+MDclGioB6Ow3XbRlw+j+K+RbDFjIJYIg4KGiOdCFqnCkvgcfn/b9LgMANPcM4u+NvRAE4Kb5nt2W3nTDTOgjNTjXafTpwEiL1Yam84MAlHkkBIzksTBgmdyfjrXgVGsforQh+NE1ub5eTsAL06iR46hkmuxYqKF7ANUdRqhVAlbN1HtzeTQBBizksqQoHdavygYAPPfBGdgU0EztQ8dx0LLMOCRF6Tz6taJ1ofhJ0RwAwH+Un5X7oHhbc88QLDYRmhAVkj38ml0lVwp1MvF2IsNWG7Z/eBoA8MNrchEbrryW9oFoQZp9EOJkx0JSOfNlmbGKaxcQjBiw0LT8+Jo8RGpDcKLFgDJHsOBLUndbd1cHTebbyzKwMD0afUMW/PLDM175muNJx0EZcWEuDXj0hpFKIe6wTOS/DzWitmsACREalFyV4+vlBI1LdbzldGZlYcBC0xIXocH3Hf/Abt97xqct67uNZuyvsZcfuqu77aWoVQK2/MMCAMDbX9bjeLP3m+qNVAgpL+FWwqnNkxsatuI/HD197rt+JiLZmMxr5I63E+ywmC02fF5lLyhgObMyMGChafvB1TmICQtFVXs//ni0yWfr+OhkG2yivVwxw4v9SFbkxOMfFqdCFIEn/veE1xOQldyDRSLl1jR0DypyDpMv/W5/PVp6h5Aao8PdBZm+Xk5Qmecoba7pMsJosoz53KG68zCardBHauTAhnzLpYBl586dyM7Ohk6nQ0FBAQ4cODDptcePH8cdd9yB7OxsCIKAHTt2XHDNY489BkEQxjzmzp3rytLIB6J1ofjRtfYkwR0fncWwj3ptjFQHeWd3ZbTN35gHbYgK+2u68ZevvXs0Jpc0KzThFgDSYsMQqhZgttrQ0jvo6+UohtFkwa8/rgIAPHDjLOhC3deVmS5NH6lFcrQWogicah27y1LhqA66ZlaiYo9ag43TAcuePXtQWlqKrVu34vDhw1iyZAmKiorQ3j5xlcjAwAByc3Px9NNPIyVl8h8kCxYsQEtLi/z47LPPnF0a+dA9q7Khj9SgvnsAvz/Y6PWv32+y4FPH9q238ldGS48Nw4+vzQMA/PufT2Jo2Oq1r12n4Lb8ErVKkHe92PF2xMt/q0GX0YzshHDcsWyGr5cTlCZLvJX6r1zL6cyK4XTAsn37dmzYsAElJSWYP38+du3ahfDwcOzevXvC6y+//HL84he/wJ133gmtVjvpfUNCQpCSkiI/9HqWkPmTcE0I7rtuJgDgV38969Uf2ABQcbodZosN2QnhPutG+eNr85Aao0NTzyBe/OScV76mKIqod+SFZCqwadxozGMZq2fAjN84/p78y02zEarmCb0vTNTxts0whFOtfRAE4CqWMyuGU98hZrMZhw4dQmFh4cgNVCoUFhaisrJyWgs5e/Ys0tLSkJubi7vvvhv19fWTXmsymWAwGMY8yPf+sSATqTE6tPQO4c39k79/niBVBxUtTPFZN8owjRr/drP9KPPXFdVo7fV8V9cuoxlGsxWCAMyIC/P415sOaQeIOyx2v/nkHPqGLJibEoVbF/tvozh/N1GlkFQdtDg9BgmRk/+iTd7lVMDS2dkJq9WK5OSxDbmSk5PR2ur6uX1BQQFeeeUVlJWV4YUXXkBNTQ2uvvpq9PX1TXj9tm3bEBMTIz8yMjJc/trkPrpQNf7PDbMAAL+uqMKA2XKJZ7iHyWKV2+P7In9ltNuWpGF5VhwGh614puyUx7+eVNKcEq1TfP6D1KSrtpM7LO19Q3j5bzUAgIdWz2GOhA9JCbWnWvvk/DuWMyuTIvYgb775ZnznO9/B4sWLUVRUhPfffx89PT145513Jrx+8+bN6O3tlR8NDQ1eXjFN5jvLZyAzPhyd/Wa8+rl3BiN+XtWFfpMFydFa5M+I9crXnIwgCNh66wIIAvCHI00o+9qzE639oUJIwqnNI379cTWGhm1YmhmLG+exZNaXMuLCEakNgdliw7kOIyxWGz6VApY5fG+UxKmARa/XQ61Wo62tbczH29raLppQ66zY2FjMnj0bVVVVE35eq9UiOjp6zIOUIVStwoOF9l2WXfuqYRga9vjXLHNU5ayen6KI31QXzYjBnZfbd/1+/MZhbPvLSY9NKfaHCiGJ1O22rtuoiK7IvtJ4fkCecv6T1XM4UM/HVCphJI+lpRd/b+yBYciCmLBQLJkR4+PV0WhOBSwajQbLli1DeXm5/DGbzYby8nKsXLnSbYvq7+9HdXU1UlNT3XZP8p7b89MxMykSvYPDeOnTGo9+LatNxN6T3u1uOxWP37YQ9zjGFvxm3zn844v70WZwf06LPzSNk6THhiFEJWBo2Ib2Pt+MMVCC//joLIatIq6cmcD5NAoh5bEcbzLI1UFXzdIjhInQiuL0u1FaWooXX3wRr776Kk6ePImNGzfCaDSipKQEALBu3Tps3rxZvt5sNuPo0aM4evQozGYzmpqacPTo0TG7Jw899BD27duH2tpafP755/jmN78JtVqNu+66yw0vkbxNrRJQetNsAMBLn9XgvNHssa/1ZW03uo1mxISFYkVOvMe+jrM0ISo8dtsC7PzHyxCpDcGB2m7c8vyncudMd/GnI6EQtUpODA7WSqGq9n7892F72f9Dq+f4eDUkGdlhMTB/RcGcDljWrl2L5557Dlu2bEF+fj6OHj2KsrIyORG3vr4eLS0j5/bNzc1YunQpli5dipaWFjz33HNYunQpfvCDH8jXNDY24q677sKcOXPw3e9+FwkJCfjiiy+QmMi/MP6qeEEK5qdGo99kwa5Pqj32dT5wzC8qnJesyLLQWxan4n82XYm5KVHo7Dfjn17aj1+Vn3XbkYjUg8UfAhaAM4X+794zsIn2SeJLM+N8vRxykHZY/t7Qg6+a7OM1GLAoj0tDKzZt2oRNmzZN+LmKiooxf87Ozr5kq/K3337blWWQgqlUAh4qmo3vv3IQr35ei3uvzEFStHsnCYuiiA+lcuYFyZe42ndyEyPx3v1XYssfv8Y7Bxvxy71ncLDuPP7v2nzER7g+lXfAbEGH42jFH3JYAHseyz4AtUGYePt1Uy/+fKwFggD86+rZvl4OjTIrORIhKgFGs71/1LzUaCS7+d8rmj7l/UpKAeP6OUlYmhmLoWEbfl3h/l2Wr5sMaOoZRFioGtco/LchXagaz357CX7x7cXQhaqw70wHbnn+UxyqO+/yPRu67S3uo3UhiA13PfDxpmDeYfnlh6cBALcvScPcFBYKKIk2RI2ZSSMNJ7m7okwMWMhjBEHATxzn9G/ur0dTj3tnyJQdtx89XjcnUfE9SCTfWZ6B9+6/Ern6CLT0DmHtbyrx0mc1Lg1MlH7o+0PCrSRbb98Jqu0Mrh2WL2u78fHpDqhVAh4s5O6KEkkt+gEGLErFgIU8atVMPVbmJsBsteFX5Wfdem+pu62SqoOmYm5KNP646UrcsjgVFpuIJ/90Avf97rDTJeBS07hMPzkOAsbusHh7qrWviKKIX5TZd1e+uzwD2Xr/CTCDiZTHEqFRY1kW84uUiAELedxDRfbfKH9/qNFtXU6r2vtR1d6PULWA6+f6X3OnKF0o/vOupXj8tgUIVQv4y9etuO1Xn+F4c++U7yH3YPGThFvAPj5AJQBGsxWd/Z6rHlOST8524kBtNzQhKvzzjTN9vRyaROG8JERo1Fh7eSY0IfzRqER8V8jjlmXF4/o5ibDaROz46Ixb7ilVB63K0yNaF+qWe3qbIAhYvyobv//xKqTHhqG2awDf/PXnePtA/ZR2H/xhSvN42hA10mKDp7RZFEU894F9d2XdFVlIjVH2vKdglpUQga8fL8Kj/zDP10uhSTBgIa/4V0cuyx//3owzbRPPiHKGFLD4enaQO+RnxOLP/3wVbpibBLPFhn979xj+9fd/v+QsJmlKc4Yf7bAAo6Y2B8FMoQ+Ot+JYUy8iNGpsvC7P18uhSxAEgZ2HFYwBC3nFwvQY3LwwBaIIbP9werssTT2D+KqxF4Jg72cRCGLDNfjtuuV4uHgOVALw7uEmrNn5N1S19094vcVqQ+N5exKzPyXdAsEztdlqE/Gc4+/6vVflcOov0TQxYCGv+ZebZkMQgLLjrTjWOPVcjfE+dOyuLM+KQ2JU4PwQUKkE3HfdTLy54QokRmlxpq0ft//nZ/ifvzdfcG1L7xAsNhEatQopftYvQprafKLF4OOVeNZ7R5pQ1d6PmLBQ/OCaXF8vh8jvMWAhr5mdHIU1+ekAgF/uPe3yfQLpOGgiV+Qm4M//fBVW5ibAaLbin986gkff+xomi1W+RqoQmhEfBrUCBj4640rH/Jy/VXVe8tjLX5ktNvxfR77Wxuvy/DbPikhJGLCQVz1w4yyoVQIqTnfgYG2308/v6jfhQI39eYEasABAUpQOb/ygAJuut1eVvP5FHb6zqxINjkDFHyuEJHNTojAjLgwmiw2fnnXvbCWl2HOwAY3nB5EYpcX6ldm+Xg5RQGDAQl6VrY/Ad5bNAAD80oVclvKT7bCJwIK0aL9LNnWWWiXgoaI5eLnkcsSGh+Krxl7c8vyn+OhEm19NaR5PEAQUzrPnHu090ebj1bjfoNkq9xz65xtmIkzjH00NiZSOAQt53f+5cRY0ahUqz3Xhb05OLy4L8OOgiVw/Jwl//uerkZ8RC8OQBT947SB+f9A+8ddfhh6Ot9qRLP3XU+2wumkQpFK8VlmL9j4TZsSFYe3lmb5eDlHAYMBCXpceG4Z/LLD/Q/7ch6en3PG032TBZ44jBH/rbjtd6bFheOdHK1FyZTYAoNtob7rmrwHL5TnxiNaFoNtoxuF61+cpKY1haBgv7LPPzXqwcDYbkBG5Eb+byCfuuz4PulAVjtT34K+n2qf0nI9PtcNstSFHH4FZowaVBQtNiApbb12AX999GSK1IVCrBLmduL8JVatwg6NDcSAdC/320xr0DAxjZlIkvrk03dfLIQooDFjIJ5KidFi/KhuAPZfFNoVjgdHVQcHc3Okbi1Lx8UPX4S8PXC13jfVHN82375LtPdEWEHOFuvpNeOnTcwCAf71ptt9VbxEpHQMW8pkfX5OHSG0ITrQY8JevWy967dCwFR87dmKKFgRGs7jpSIzSYnZylK+XMS3XzkmERq1CTacR1R0TN8jzJ7v2VcNotmJRekzQHVkSeQMDFvKZuAgN7r0qBwCwfe/piyZffl7dCaPZipRoHZbMiPXSCsmTIrUhWJmXAAD40M+PhVp6B/FqZR0A4KGiOUG9A0jkKQxYyKfuvToHMWGhqO4w4o9Hmya9rsyxA7N6QTJU3GoPGNJoBX/PY/nVX6tgttiwIjse18zS+3o5RAGJAQv5VLQuFD++1j4UbsdHZzFstV1wjcVqw0cn7cdBxUFUzhwMpIDlaEMP2vuGfLwa19R2GvHOlw0AuLtC5EkMWMjn1q/Kgj5Si/ruAbm/yGhf1p5Ht9GM2PBQrMiJ98EKyVOSo3VYMiMGomhvCuiPdnx0BhabiOvmJPLvJ5EHMWAhnwvXhOD+6+27LL/661kMDVvHfF6qDiqcl4wQNf/KBhp/PhY63dqHPzqGUz60eo6PV0MU2PivPynCXSsykRqjQ0vvEN7cXy9/XBRFeTpzMHW3DSZSefNnVZ0wmvxrGOIvPzwNUQRuWZSKhekxvl4OUUBjwEKKoAtV459vnAUA+HVFlTzF91hTL5p7hxCuUeNqJjMGpNnJkciMD4fZYsOnZzt8vZwpO9rQgw9PtEElAP9y02xfL4co4DFgIcX49rIZyIwPR2e/Ga98XgtgpDroujmJ0IVyiFwgEgRBPhbyp/Lm5z44DQD41mUzMDMIOy8TeRsDFlKMULUKDxbad1l+s+8cDEPDY7rbUuC6adQwRMsElWJK83l1Jz6r6kSoWsADjp1BIvIsBiykKLfnp2NmUiR6B4ex+d1jqO4wIlQt4HrH3BkKTMuz4hAbHoqegWEcqlP2MERRFOXdlX9ckYkMPx1ASeRvGLCQoqhVAkod+QB//qoFAHDlTD2idaG+XBZ5WIhahRvm+McwxL+easfh+h7oQlW4/4aZvl4OUdBgwEKKU7wgBQtGTSHmcVBwkMubTyp3GKIoinjuwzMAgJIrc5AUpfPxioiCBwMWUhyVSsC/rrbvsqgEe/8VCnzXzE6EJkSFuq4BnG1X5jDEL85142SLAeEaNX50Ta6vl0MUVEJ8vQCiiVw/JwmP/sN8xIWHIjFK6+vlkBdEaENwZV4CPj7dgb0n2hQ5jfq1yloAwLcuS0dsuMa3iyEKMtxhIUUSBAH3XpWDb102w9dLIS+Smsgpsby5pXdQXte6ldm+XQxREHIpYNm5cyeys7Oh0+lQUFCAAwcOTHrt8ePHcccddyA7OxuCIGDHjh3TvicRBabCefbE27839KDNoKxhiG/ur4fVJuKK3HhF7v4QBTqnA5Y9e/agtLQUW7duxeHDh7FkyRIUFRWhvX3iwWUDAwPIzc3F008/jZSUiZMnnb0nEQWmpGgd8jNiAQAfnVTOLovJYsVbB+wjI9Zzd4XIJ5wOWLZv344NGzagpKQE8+fPx65duxAeHo7du3dPeP3ll1+OX/ziF7jzzjuh1U6ci+DsPYkocClxGOJfjrWis9+MlGidvD4i8i6nAhaz2YxDhw6hsLBw5AYqFQoLC1FZWenSAly5p8lkgsFgGPMgosCw2hEQfF7VhX6FDEOUkm3vLsjkxHAiH3HqO6+zsxNWqxXJyWN/w0hOTkZra6tLC3Dlntu2bUNMTIz8yMjIcOlrE5HyzEyKRHZCOMxWGz454/thiMcae3G4vgehagF3rsj09XKIgpZf/qqwefNm9Pb2yo+GhgZfL4mI3GT0MEQlHAtJuyvfWJTKEnsiH3IqYNHr9VCr1WhrG/uPSFtb26QJtZ64p1arRXR09JgHEQUOqbz5r6faMezDYYjnjWb8z9+bAbCUmcjXnApYNBoNli1bhvLycvljNpsN5eXlWLlypUsL8MQ9ici/LcuKQ3yEBr2DwzhY67thiO8cbIDJYsPC9Ghclhnrs3UQkQtHQqWlpXjxxRfx6quv4uTJk9i4cSOMRiNKSkoAAOvWrcPmzZvl681mM44ePYqjR4/CbDajqakJR48eRVVV1ZTvSUTBRa0ScMNc3w5DtNpEvP5FHQBg3RX2PlJE5DtOt+Zfu3YtOjo6sGXLFrS2tiI/Px9lZWVy0mx9fT1UqpE4qLm5GUuXLpX//Nxzz+G5557Dtddei4qKiindk4iCT+G8ZPzXoUbsPdmKR/9hntcDhorT7Wg8P4jY8FDclp/m1a9NRBcSRKWORXWCwWBATEwMent7mc9CFCAGzBYsfWIvTBYbyh68GnNTvPu9vW73AXxypgM/uiYXm78xz6tfmyhYOPPz2y+rhIgo8IVrQnDVTD0AYO9x7x4LnevoxydnOiAIwD9dkeXVr01EE2PAQkSKJZc3e7lN/xtf2Nvw3zAnCRnx4V792kQ0MQYsRKRYN85LhiAAXzX2orXXO8MQjSYLfn/I3ttp3apsr3xNIro0BixEpFiJUVosdQxD9NYuy3tHm9A3ZEF2QjiudhxJEZHvMWAhIkWTmsh5o7xZFEW8XmkvZf7eymyoVCxlJlIKBixEpGhSHktldSf6hoY9+rUO1HTjVGsfwkLV+PayGR79WkTkHAYsRKRoM5MikauPwLBVxD4PD0N8zbG7smZpOmLCQj36tYjIOQxYiEjxvDEMsbV3CB8ct0+IX7eSpcxESsOAhYgUTwpYPvbgMMQ3D9TDYhOxIice81LZgJJIaRiwEJHiLc2MQ0KEBoYhC76s6Xb7/c0WG97cb++9wt0VImViwEJEiqdWCbhxnn0Y4oceOBYqO96Kzn4TkqK0KFqQ4vb7E9H0MWAhIr8wurzZ3SPQXvu8FgBwd0EWQtX8Z5FIifidSUR+4aqZeuhCVWjqGcTJlj633fd4cy8O1p1HiErAXSsy3HZfInIvBixE5BfCNGpcNTMRgHurhaRGcTcvSkVStM5t9yUi92LAQkR+Y7U8DLHVLffrGTDjvaNNAID1TLYlUjQGLETkN26YlwRBAL5uMqC5Z3Da9/v9wUYMDdswLzUay7Li3LBCIvIUBixE5Df0kVosy7QHFh9NcxiizSbi9S/sx0HrV2ZBEDg3iEjJGLAQkV9xV9fbfWc6UN89gGhdCG7PT3fH0ojIgxiwEJFfkQKWL851wTCNYYivVtYCAL67PANhGrU7lkZEHsSAhYj8Sm5iJPIS7cMQK067NgyxttOIfWc6IAjAP13BZFsif8CAhYj8zugmcq5444s6iCJw3exEZOsj3Lk0IvIQBixE5HekY6GKU+0wW5wbhjhotuKdgw0AgHUrs929NCLyEAYsROR3lmbEQh+pRZ/JggNODkP849EmGIYsyIwPx7WzEz20QiJyNwYsROR3VCoBhY5hiHtPTL2JnCiKeNXR2XbdyiyoVCxlJvIXDFiIyC+NLm+e6jDEg3XncbLFAF2oCt9ZxrlBRP6EAQsR+aUrZ+oRFqpGc+8QjjcbpvSc1xy7K2vy0xETHurJ5RGRmzFgISK/pAtV45rZegBTqxZqNwzhL8daAADf49wgIr/DgIWI/JYz5c1vHqiHxSZieVYcFqTFeHppRORmDFiIyG/dMDcJKgE40WJA4/mBSa8bttrw5v56AMC6VdleWh0RuRMDFiLyW/ERGizPigcAfHSRXZYPjreivc+ExCgtihekeGt5RORGDFiIyK/J1UIXmd782uf2ZNu7VmRCE8J/9oj8kUvfuTt37kR2djZ0Oh0KCgpw4MCBi17/+9//HnPnzoVOp8OiRYvw/vvvj/n8PffcA0EQxjyKi4tdWRoRBRkpYNl/rhu9gxcOQzzZYsCB2m6EqATcXZDp7eURkZs4HbDs2bMHpaWl2Lp1Kw4fPowlS5agqKgI7e3tE17/+eef46677sK9996LI0eOYM2aNVizZg2+/vrrMdcVFxejpaVFfrz11luuvSIiCirZ+gjMSoqExSai4vSF/w5JpcxFC1OQHK3z9vKIyE2cDli2b9+ODRs2oKSkBPPnz8euXbsQHh6O3bt3T3j9f/zHf6C4uBg/+clPMG/ePDz55JO47LLL8J//+Z9jrtNqtUhJSZEfcXFxrr0iIgo60i7Lh+PyWHoHh/HekSYAwDpOZSbya04FLGazGYcOHUJhYeHIDVQqFBYWorKycsLnVFZWjrkeAIqKii64vqKiAklJSZgzZw42btyIrq6uSddhMplgMBjGPIgoeEkBy77THTBZrPLH/+tQIwaHrZibEoUVOfG+Wh4RuYFTAUtnZyesViuSk5PHfDw5ORmtrRPP82htbb3k9cXFxXjttddQXl6OZ555Bvv27cPNN98Mq9U6/nYAgG3btiEmJkZ+ZGSwxTZRMFsyIxZJUVr0myz44px9GKLNJuL1yloA9kZxgsC5QUT+TBHp8nfeeSduu+02LFq0CGvWrMGf/vQnfPnll6ioqJjw+s2bN6O3t1d+NDQ0eHfBRKQoKpWAG+fZfzGSyps/OduB2q4BROlCsCY/3ZfLIyI3cCpg0ev1UKvVaGsbe07c1taGlJSJexukpKQ4dT0A5ObmQq/Xo6qqasLPa7VaREdHj3kQUXBb7TgW+uikfRji645k2+8sy0CENsSXSyMiN3AqYNFoNFi2bBnKy8vlj9lsNpSXl2PlypUTPmflypVjrgeAvXv3Tno9ADQ2NqKrqwupqanOLI+IgtjKvASEa9Ro6R3C+8da8VdHxRDnBhEFBqePhEpLS/Hiiy/i1VdfxcmTJ7Fx40YYjUaUlJQAANatW4fNmzfL1z/wwAMoKyvDL3/5S5w6dQqPPfYYDh48iE2bNgEA+vv78ZOf/ARffPEFamtrUV5ejttvvx0zZ85EUVGRm14mEQU6Xaga185OBABsfvcriCJwzexE5OgjfLwyInIHp/dJ165di46ODmzZsgWtra3Iz89HWVmZnFhbX18PlWokDlq1ahXefPNN/PznP8dPf/pTzJo1C++99x4WLlwIAFCr1fjqq6/w6quvoqenB2lpaVi9ejWefPJJaLVaN71MIgoGN81Pxl++boVhyAIAWM/dFaKAIYiiKPp6EdNlMBgQExOD3t5e5rMQBbGeATOWPfURrDYRM+LCsO8n10OtYnUQkVI58/NbEVVCRETuEBuuwRW59n4r37sii8EKUQBh6jwRBZSnv7UYn57txHeXz/D1UojIjRiwEFFAyYgPxz9yyCFRwOGREBERESkeAxYiIiJSPAYsREREpHgMWIiIiEjxGLAQERGR4jFgISIiIsVjwEJERESKx4CFiIiIFI8BCxERESkeAxYiIiJSPAYsREREpHgMWIiIiEjxGLAQERGR4gXEtGZRFAEABoPBxyshIiKiqZJ+bks/xy8mIAKWvr4+AEBGRoaPV0JERETO6uvrQ0xMzEWvEcSphDUKZ7PZ0NzcjKioKAiC4NZ7GwwGZGRkoKGhAdHR0W69t9IE02sFguv18rUGrmB6vXytgUcURfT19SEtLQ0q1cWzVAJih0WlUmHGjBke/RrR0dEB/ZdmtGB6rUBwvV6+1sAVTK+XrzWwXGpnRcKkWyIiIlI8BixERESkeAxYLkGr1WLr1q3QarW+XorHBdNrBYLr9fK1Bq5ger18rcEtIJJuiYiIKLBxh4WIiIgUjwELERERKR4DFiIiIlI8BixERESkeAxYAOzcuRPZ2dnQ6XQoKCjAgQMHLnr973//e8ydOxc6nQ6LFi3C+++/76WVum7btm24/PLLERUVhaSkJKxZswanT5++6HNeeeUVCIIw5qHT6by04ul57LHHLlj73LlzL/ocf3xfASA7O/uC1yoIAu6///4Jr/e39/WTTz7BrbfeirS0NAiCgPfee2/M50VRxJYtW5CamoqwsDAUFhbi7Nmzl7yvs9/33nCx1zo8PIxHHnkEixYtQkREBNLS0rBu3To0Nzdf9J6ufC94w6Xe13vuueeCdRcXF1/yvkp8X4FLv96JvocFQcAvfvGLSe+p1PfWU4I+YNmzZw9KS0uxdetWHD58GEuWLEFRURHa29snvP7zzz/HXXfdhXvvvRdHjhzBmjVrsGbNGnz99ddeXrlz9u3bh/vvvx9ffPEF9u7di+HhYaxevRpGo/Giz4uOjkZLS4v8qKur89KKp2/BggVj1v7ZZ59Neq2/vq8A8OWXX455nXv37gUAfOc735n0Of70vhqNRixZsgQ7d+6c8PPPPvssnn/+eezatQv79+9HREQEioqKMDQ0NOk9nf2+95aLvdaBgQEcPnwYjz76KA4fPox3330Xp0+fxm233XbJ+zrzveAtl3pfAaC4uHjMut96662L3lOp7ytw6dc7+nW2tLRg9+7dEAQBd9xxx0Xvq8T31mPEILdixQrx/vvvl/9stVrFtLQ0cdu2bRNe/93vfle85ZZbxnysoKBA/NGPfuTRdbpbe3u7CEDct2/fpNe8/PLLYkxMjPcW5UZbt24VlyxZMuXrA+V9FUVRfOCBB8S8vDzRZrNN+Hl/fl8BiH/4wx/kP9tsNjElJUX8xS9+IX+sp6dH1Gq14ltvvTXpfZz9vveF8a91IgcOHBABiHV1dZNe4+z3gi9M9FrXr18v3n777U7dxx/eV1Gc2nt7++23izfccMNFr/GH99adgnqHxWw249ChQygsLJQ/plKpUFhYiMrKygmfU1lZOeZ6ACgqKpr0eqXq7e0FAMTHx1/0uv7+fmRlZSEjIwO33347jh8/7o3lucXZs2eRlpaG3Nxc3H333aivr5/02kB5X81mM9544w18//vfv+ggUH9+X0erqalBa2vrmPcuJiYGBQUFk753rnzfK1Vvby8EQUBsbOxFr3Pme0FJKioqkJSUhDlz5mDjxo3o6uqa9NpAel/b2trw5z//Gffee+8lr/XX99YVQR2wdHZ2wmq1Ijk5eczHk5OT0draOuFzWltbnbpeiWw2Gx588EFceeWVWLhw4aTXzZkzB7t378Yf//hHvPHGG7DZbFi1ahUaGxu9uFrXFBQU4JVXXkFZWRleeOEF1NTU4Oqrr0ZfX9+E1wfC+woA7733Hnp6enDPPfdMeo0/v6/jSe+PM++dK9/3SjQ0NIRHHnkEd91110WH4zn7vaAUxcXFeO2111BeXo5nnnkG+/btw8033wyr1Trh9YHyvgLAq6++iqioKHzrW9+66HX++t66KiCmNZNz7r//fnz99deXPOtcuXIlVq5cKf951apVmDdvHn7zm9/gySef9PQyp+Xmm2+W///ixYtRUFCArKwsvPPOO1P6rcVfvfTSS7j55puRlpY26TX+/L6S3fDwML773e9CFEW88MILF73WX78X7rzzTvn/L1q0CIsXL0ZeXh4qKipw4403+nBlnrd7927cfffdl0yG99f31lVBvcOi1+uhVqvR1tY25uNtbW1ISUmZ8DkpKSlOXa80mzZtwp/+9Cd8/PHHmDFjhlPPDQ0NxdKlS1FVVeWh1XlObGwsZs+ePena/f19BYC6ujp89NFH+MEPfuDU8/z5fZXeH2feO1e+75VEClbq6uqwd+/ei+6uTORS3wtKlZubC71eP+m6/f19lXz66ac4ffq009/HgP++t1MV1AGLRqPBsmXLUF5eLn/MZrOhvLx8zG+go61cuXLM9QCwd+/eSa9XClEUsWnTJvzhD3/AX//6V+Tk5Dh9D6vVimPHjiE1NdUDK/Ss/v5+VFdXT7p2f31fR3v55ZeRlJSEW265xann+fP7mpOTg5SUlDHvncFgwP79+yd971z5vlcKKVg5e/YsPvroIyQkJDh9j0t9LyhVY2Mjurq6Jl23P7+vo7300ktYtmwZlixZ4vRz/fW9nTJfZ/362ttvvy1qtVrxlVdeEU+cOCH+8Ic/FGNjY8XW1lZRFEXxe9/7nvhv//Zv8vV/+9vfxJCQEPG5554TT548KW7dulUMDQ0Vjx075quXMCUbN24UY2JixIqKCrGlpUV+DAwMyNeMf62PP/64+MEHH4jV1dXioUOHxDvvvFPU6XTi8ePHffESnPKv//qvYkVFhVhTUyP+7W9/EwsLC0W9Xi+2t7eLohg476vEarWKmZmZ4iOPPHLB5/z9fe3r6xOPHDkiHjlyRAQgbt++XTxy5IhcGfP000+LsbGx4h//+Efxq6++Em+//XYxJydHHBwclO9xww03iL/61a/kP1/q+95XLvZazWazeNttt4kzZswQjx49Oub72GQyyfcY/1ov9b3gKxd7rX19feJDDz0kVlZWijU1NeJHH30kXnbZZeKsWbPEoaEh+R7+8r6K4qX/HouiKPb29orh4eHiCy+8MOE9/OW99ZSgD1hEURR/9atfiZmZmaJGoxFXrFghfvHFF/Lnrr32WnH9+vVjrn/nnXfE2bNnixqNRlywYIH45z//2csrdh6ACR8vv/yyfM341/rggw/K/12Sk5PFb3zjG+Lhw4e9v3gXrF27VkxNTRU1Go2Ynp4url27VqyqqpI/Hyjvq+SDDz4QAYinT5++4HP+/r5+/PHHE/7dlV6TzWYTH330UTE5OVnUarXijTfeeMF/h6ysLHHr1q1jPnax73tfudhrrampmfT7+OOPP5bvMf61Xup7wVcu9loHBgbE1atXi4mJiWJoaKiYlZUlbtiw4YLAw1/eV1G89N9jURTF3/zmN2JYWJjY09Mz4T385b31FEEURdGjWzhERERE0xTUOSxERETkHxiwEBERkeIxYCEiIiLFY8BCREREiseAhYiIiBSPAQsREREpHgMWIiIiUjwGLERERKR4DFiIiIhI8RiwEBERkeIxYCEiIiLFY8BCREREivf/AyPpfEIMB8MvAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Squared Error: 0.09783460591148274\n",
            "R2 Score: 0.5584532171244132\n"
          ]
        }
      ],
      "source": [
        "#Prelim mlp\n",
        "#Possible avenue for bias and weight matrix initialization:\n",
        "## Initialize weights using Xavier uniform initialization\n",
        "# init.xavier_uniform_(linear_layer.weight)\n",
        " \n",
        "# ## Initialize bias to zero\n",
        "# init.zeros_(linear_layer.bias)\n",
        "#---------------------------------\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "#Previous experiment\n",
        "class MLP(nn.Module):  # nn.Module is the base class for all models in PyTorch\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(init_features, 181),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(181, 90),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(90, 1),\n",
        "            nn.Sigmoid()\n",
        "            #try to make output binary (0 or 1)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "     #   x =  self.layers(x)\n",
        "        return self.layers(x)\n",
        "    \n",
        "\n",
        "#initialize dataloader with random sampling of size 10 \n",
        "dataset = dataLoader(X, y)\n",
        "trainloader = torch.utils.data.DataLoader(dataset, batch_size=10, num_workers=0, shuffle = True)\n",
        "testloader = torch.utils.data.DataLoader(dataset, batch_size=10, num_workers=0, shuffle=True)\n",
        "\n",
        "#mlp init\n",
        "mlp = theiaMLP(init_features, 1000, 1)\n",
        "#set loss function and gradient descet optimizer\n",
        "loss_function = nn.L1Loss()\n",
        "optimizer = torch.optim.Adagrad(mlp.parameters(), lr=1e-4)\n",
        "\n",
        "#train loss\n",
        "train_loss = []\n",
        "mlp.train()\n",
        "\n",
        "#train for this many epochs\n",
        "for epoch in range(0,20):\n",
        "    print(f'Starting Epoch {epoch+1}')\n",
        "\n",
        "    current_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, targets = data\n",
        "        inputs, targets = inputs.float(), targets.float()\n",
        "        targets = targets.reshape((targets.shape[0], 1))\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = mlp(inputs)\n",
        "\n",
        "        loss = loss_function(outputs, targets)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "     \n",
        "\n",
        "        current_loss += loss.item()\n",
        "        if i%10 == 0:\n",
        "            print(f'Loss after mini-batch %5d: %.3f'%(i+1, current_loss/500))\n",
        "            current_loss = 0.0\n",
        "    train_loss.append(loss.item())\n",
        "    \n",
        "    print(f'Epoch {epoch+1} done')\n",
        "\n",
        "\n",
        "plt.plot(train_loss)\n",
        "plt.show()\n",
        "\n",
        "test_data = torch.from_numpy(testX.to_numpy()).float()\n",
        "test_targets = torch.from_numpy(testY.to_numpy()).float()\n",
        "\n",
        "mse_r2_calculator(mlp, test_data, test_targets)\n",
        "#results\n",
        "# Mean Squared Error: 0.09783460591148274\n",
        "# R2 Score: 0.5584532171244132"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.005\n",
            "Loss after mini-batch    41: 0.003\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.005\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.005\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.005\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.005\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.003\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.005\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.005\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.003\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.005\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.003\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.005\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.005\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.003\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.005\n",
            "Loss after mini-batch   121: 0.003\n",
            "Loss after mini-batch   131: 0.005\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.006\n",
            "Loss after mini-batch   161: 0.005\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.003\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.003\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.005\n",
            "Loss after mini-batch   261: 0.005\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.003\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.003\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.005\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.005\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.005\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.003\n",
            "Loss after mini-batch   191: 0.005\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.005\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.005\n",
            "Loss after mini-batch   311: 0.005\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.003\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.005\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.005\n",
            "Loss after mini-batch   131: 0.005\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.005\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.003\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.005\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.000\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.005\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.005\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.003\n",
            "Loss after mini-batch   171: 0.003\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.005\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.005\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.005\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.003\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.005\n",
            "Loss after mini-batch   311: 0.003\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.005\n",
            "Loss after mini-batch    41: 0.005\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.003\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.005\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.003\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.005\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.005\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.003\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.005\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.003\n",
            "Loss after mini-batch   181: 0.005\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.005\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.003\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.005\n",
            "Loss after mini-batch   281: 0.005\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.005\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.005\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.005\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.005\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.005\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.005\n",
            "Loss after mini-batch   151: 0.003\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.003\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.005\n",
            "Loss after mini-batch   281: 0.003\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.005\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.005\n",
            "Loss after mini-batch    21: 0.005\n",
            "Loss after mini-batch    31: 0.003\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.005\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.005\n",
            "Loss after mini-batch   191: 0.005\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.005\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.003\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.003\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.003\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.005\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.005\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.005\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.005\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.003\n",
            "Loss after mini-batch   271: 0.003\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.003\n",
            "Loss after mini-batch   311: 0.005\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.003\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.003\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.003\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.003\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.005\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.005\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.005\n",
            "Loss after mini-batch   271: 0.005\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.005\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.005\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.005\n",
            "Loss after mini-batch   121: 0.003\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.005\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.003\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.005\n",
            "Loss after mini-batch   251: 0.005\n",
            "Loss after mini-batch   261: 0.005\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.005\n",
            "Loss after mini-batch   321: 0.003\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.003\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.005\n",
            "Loss after mini-batch    41: 0.003\n",
            "Loss after mini-batch    51: 0.005\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.005\n",
            "Loss after mini-batch   101: 0.003\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.005\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.003\n",
            "Loss after mini-batch   211: 0.005\n",
            "Loss after mini-batch   221: 0.005\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.003\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.005\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.005\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.005\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.003\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.005\n",
            "Loss after mini-batch   191: 0.003\n",
            "Loss after mini-batch   201: 0.005\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.003\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.005\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.005\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.005\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.005\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.003\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.003\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.003\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.005\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.005\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.005\n",
            "Loss after mini-batch   101: 0.005\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.005\n",
            "Loss after mini-batch   131: 0.003\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.005\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.005\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.005\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.005\n",
            "Loss after mini-batch    31: 0.005\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.005\n",
            "Loss after mini-batch    81: 0.003\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.005\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.005\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.003\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.005\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.005\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.003\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.005\n",
            "Loss after mini-batch   151: 0.006\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.003\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.005\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.005\n",
            "Loss after mini-batch   221: 0.003\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.005\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.005\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.003\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.005\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.005\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.005\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.005\n",
            "Loss after mini-batch    21: 0.005\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.003\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.005\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.005\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.005\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.005\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.003\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.005\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.003\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.003\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.003\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.005\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.005\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.005\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.005\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.005\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.003\n",
            "Loss after mini-batch    61: 0.003\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.003\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.005\n",
            "Loss after mini-batch   151: 0.003\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.005\n",
            "Loss after mini-batch   221: 0.003\n",
            "Loss after mini-batch   231: 0.003\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.005\n",
            "Loss after mini-batch   281: 0.005\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.005\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.003\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.005\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.005\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.003\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.003\n",
            "Loss after mini-batch   221: 0.005\n",
            "Loss after mini-batch   231: 0.003\n",
            "Loss after mini-batch   241: 0.005\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.005\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.005\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.003\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.005\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.005\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.005\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.005\n",
            "Loss after mini-batch    21: 0.003\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.003\n",
            "Loss after mini-batch    71: 0.005\n",
            "Loss after mini-batch    81: 0.005\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.005\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.005\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.005\n",
            "Loss after mini-batch   301: 0.005\n",
            "Loss after mini-batch   311: 0.003\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.005\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.003\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.005\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.003\n",
            "Loss after mini-batch   171: 0.005\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.005\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.005\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.003\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.003\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.005\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.003\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.003\n",
            "Loss after mini-batch   141: 0.003\n",
            "Loss after mini-batch   151: 0.005\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.005\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.005\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.005\n",
            "Loss after mini-batch   321: 0.005\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.005\n",
            "Loss after mini-batch    31: 0.003\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.003\n",
            "Loss after mini-batch    81: 0.005\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.003\n",
            "Loss after mini-batch   151: 0.005\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.005\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.005\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.005\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.005\n",
            "Loss after mini-batch   101: 0.003\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.003\n",
            "Loss after mini-batch   131: 0.005\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.003\n",
            "Loss after mini-batch   171: 0.005\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.003\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.005\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.005\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.003\n",
            "Loss after mini-batch   111: 0.005\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.005\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.005\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.003\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.003\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.003\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.005\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.005\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.003\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.003\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.005\n",
            "Loss after mini-batch   231: 0.005\n",
            "Loss after mini-batch   241: 0.003\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.005\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.003\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.005\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.003\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.005\n",
            "Loss after mini-batch   141: 0.005\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.003\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.003\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.006\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.003\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.003\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.003\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.005\n",
            "Loss after mini-batch    81: 0.005\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.005\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.003\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.005\n",
            "Loss after mini-batch   231: 0.003\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.005\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.005\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.003\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.005\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.005\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.005\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.005\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.003\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.005\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.003\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.005\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.005\n",
            "Loss after mini-batch   311: 0.005\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.005\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.005\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.005\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.003\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.005\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.005\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.005\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.005\n",
            "Loss after mini-batch   261: 0.003\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.005\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.003\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.005\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.005\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.003\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.003\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.005\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.005\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.005\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.005\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.003\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.005\n",
            "Loss after mini-batch   121: 0.005\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.005\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.005\n",
            "Loss after mini-batch   151: 0.005\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.003\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.005\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.005\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.005\n",
            "Loss after mini-batch    51: 0.005\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.005\n",
            "Loss after mini-batch    91: 0.005\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.005\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.005\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.005\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.003\n",
            "Loss after mini-batch   301: 0.005\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.003\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.005\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.003\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.005\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.005\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.005\n",
            "Loss after mini-batch   291: 0.003\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.005\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.005\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.005\n",
            "Loss after mini-batch   171: 0.003\n",
            "Loss after mini-batch   181: 0.003\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.003\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.005\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.003\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.005\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.003\n",
            "Loss after mini-batch   241: 0.005\n",
            "Loss after mini-batch   251: 0.005\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.003\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.005\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.005\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.005\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.005\n",
            "Loss after mini-batch   131: 0.005\n",
            "Loss after mini-batch   141: 0.003\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.003\n",
            "Loss after mini-batch   171: 0.003\n",
            "Loss after mini-batch   181: 0.005\n",
            "Loss after mini-batch   191: 0.003\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.005\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.003\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.005\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.003\n",
            "Loss after mini-batch    71: 0.003\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.005\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.003\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.005\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.005\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.005\n",
            "Loss after mini-batch   331: 0.005\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.005\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.005\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.005\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.005\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.003\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.005\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.005\n",
            "Loss after mini-batch   211: 0.005\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.005\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.003\n",
            "Loss after mini-batch   291: 0.003\n",
            "Loss after mini-batch   301: 0.003\n",
            "Loss after mini-batch   311: 0.003\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.003\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.005\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.005\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.005\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.005\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.003\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.003\n",
            "Loss after mini-batch   191: 0.003\n",
            "Loss after mini-batch   201: 0.003\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.005\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.003\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.005\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.005\n",
            "Loss after mini-batch   161: 0.005\n",
            "Loss after mini-batch   171: 0.003\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.005\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.005\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.005\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.005\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.005\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.003\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.003\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.003\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.005\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.003\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.005\n",
            "Loss after mini-batch   251: 0.005\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.005\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.005\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.005\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.003\n",
            "Loss after mini-batch    71: 0.003\n",
            "Loss after mini-batch    81: 0.003\n",
            "Loss after mini-batch    91: 0.005\n",
            "Loss after mini-batch   101: 0.005\n",
            "Loss after mini-batch   111: 0.003\n",
            "Loss after mini-batch   121: 0.003\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.005\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.005\n",
            "Loss after mini-batch   171: 0.005\n",
            "Loss after mini-batch   181: 0.005\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.005\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.005\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.003\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.003\n",
            "Loss after mini-batch   191: 0.005\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.005\n",
            "Loss after mini-batch   221: 0.006\n",
            "Loss after mini-batch   231: 0.005\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.003\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.005\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.003\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.005\n",
            "Loss after mini-batch   101: 0.005\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.005\n",
            "Loss after mini-batch   161: 0.005\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.005\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.005\n",
            "Loss after mini-batch   321: 0.003\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.003\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.005\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.005\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.005\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.003\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.005\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.003\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.005\n",
            "Loss after mini-batch   101: 0.005\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.005\n",
            "Loss after mini-batch   201: 0.005\n",
            "Loss after mini-batch   211: 0.003\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.005\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.005\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.005\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.005\n",
            "Loss after mini-batch   331: 0.003\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.005\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.005\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.005\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.005\n",
            "Loss after mini-batch   131: 0.003\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.005\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.005\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.003\n",
            "Loss after mini-batch   241: 0.005\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.003\n",
            "Loss after mini-batch   291: 0.003\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.005\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.005\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.005\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.003\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.005\n",
            "Loss after mini-batch   241: 0.005\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.003\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.003\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.003\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.005\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.005\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.003\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.003\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.005\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.005\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.005\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.005\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.000\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.005\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.003\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.005\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.005\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.003\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.005\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.005\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.005\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.003\n",
            "Loss after mini-batch   251: 0.003\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.003\n",
            "Loss after mini-batch   281: 0.005\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.005\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.005\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.003\n",
            "Loss after mini-batch   111: 0.005\n",
            "Loss after mini-batch   121: 0.003\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.005\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.005\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.003\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.005\n",
            "Loss after mini-batch   281: 0.005\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.005\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.005\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.003\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.005\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.003\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.003\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.005\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.005\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.005\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.005\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.003\n",
            "Loss after mini-batch   151: 0.005\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.003\n",
            "Loss after mini-batch   191: 0.005\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.005\n",
            "Loss after mini-batch   261: 0.005\n",
            "Loss after mini-batch   271: 0.003\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.005\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.003\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.005\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.005\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.003\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.005\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.005\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.003\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.005\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.005\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.003\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.005\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.005\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.003\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.005\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.003\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.005\n",
            "Loss after mini-batch   311: 0.005\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.003\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.003\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.005\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.005\n",
            "Loss after mini-batch   111: 0.005\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.005\n",
            "Loss after mini-batch   161: 0.005\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.003\n",
            "Loss after mini-batch   191: 0.005\n",
            "Loss after mini-batch   201: 0.005\n",
            "Loss after mini-batch   211: 0.003\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.003\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.005\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.005\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.005\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.003\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.003\n",
            "Loss after mini-batch   291: 0.005\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.005\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.003\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.005\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.005\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.005\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.005\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.003\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.005\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.003\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.005\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.003\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.005\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.003\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.005\n",
            "Loss after mini-batch   131: 0.005\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.005\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.003\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.005\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.005\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.005\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.005\n",
            "Loss after mini-batch    91: 0.003\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.003\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.003\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.005\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.005\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.000\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.005\n",
            "Loss after mini-batch    51: 0.005\n",
            "Loss after mini-batch    61: 0.005\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.005\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.005\n",
            "Loss after mini-batch   151: 0.003\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.005\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.003\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.003\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.005\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.005\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.003\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.003\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.005\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.005\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.005\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.005\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.003\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.005\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.005\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.005\n",
            "Loss after mini-batch    31: 0.005\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.005\n",
            "Loss after mini-batch   141: 0.003\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.005\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.005\n",
            "Loss after mini-batch   191: 0.003\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.005\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.005\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.003\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.005\n",
            "Loss after mini-batch    21: 0.003\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.005\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.003\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.005\n",
            "Loss after mini-batch   121: 0.003\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.005\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.005\n",
            "Loss after mini-batch   171: 0.003\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.005\n",
            "Loss after mini-batch   221: 0.005\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.005\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.005\n",
            "Loss after mini-batch    81: 0.005\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.003\n",
            "Loss after mini-batch   111: 0.005\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.003\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.005\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.005\n",
            "Loss after mini-batch   281: 0.005\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.005\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.003\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.005\n",
            "Loss after mini-batch    41: 0.005\n",
            "Loss after mini-batch    51: 0.005\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.003\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.003\n",
            "Loss after mini-batch   181: 0.003\n",
            "Loss after mini-batch   191: 0.005\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.005\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.005\n",
            "Loss after mini-batch   251: 0.005\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.003\n",
            "Loss after mini-batch   291: 0.003\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.003\n",
            "Loss after mini-batch   321: 0.005\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.005\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.005\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.003\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.003\n",
            "Loss after mini-batch   201: 0.005\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.005\n",
            "Loss after mini-batch   231: 0.003\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.005\n",
            "Loss after mini-batch   261: 0.005\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.003\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.005\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.005\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.005\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.005\n",
            "Loss after mini-batch   231: 0.005\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.005\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.005\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.005\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.005\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.005\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.005\n",
            "Loss after mini-batch   331: 0.005\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.003\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.005\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.005\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.005\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.003\n",
            "Loss after mini-batch   311: 0.005\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.005\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.005\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.005\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.005\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.003\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.003\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.005\n",
            "Loss after mini-batch   281: 0.003\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.005\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.005\n",
            "Loss after mini-batch    61: 0.005\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.005\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.005\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.003\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.005\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.003\n",
            "Loss after mini-batch   201: 0.003\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.005\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.005\n",
            "Loss after mini-batch   321: 0.003\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.005\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.005\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.005\n",
            "Loss after mini-batch   321: 0.003\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.005\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.006\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.003\n",
            "Loss after mini-batch   111: 0.005\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.005\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.005\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.003\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.003\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.005\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.003\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.005\n",
            "Loss after mini-batch   101: 0.005\n",
            "Loss after mini-batch   111: 0.003\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.005\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.003\n",
            "Loss after mini-batch   291: 0.005\n",
            "Loss after mini-batch   301: 0.003\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.005\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.005\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.005\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.005\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.003\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.003\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.005\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.005\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.003\n",
            "Loss after mini-batch     1: 0.000\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.003\n",
            "Loss after mini-batch    51: 0.003\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.005\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.003\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.005\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.005\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.005\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.005\n",
            "Loss after mini-batch   141: 0.003\n",
            "Loss after mini-batch   151: 0.005\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.003\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.003\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.005\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.005\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.005\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.005\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.005\n",
            "Loss after mini-batch   151: 0.005\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.005\n",
            "Loss after mini-batch   301: 0.003\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.005\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.005\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.005\n",
            "Loss after mini-batch   231: 0.005\n",
            "Loss after mini-batch   241: 0.003\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.003\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.005\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.005\n",
            "Loss after mini-batch    41: 0.005\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.005\n",
            "Loss after mini-batch    91: 0.005\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.003\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.005\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.003\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.003\n",
            "Loss after mini-batch   261: 0.005\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.003\n",
            "Loss after mini-batch    21: 0.005\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.005\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.005\n",
            "Loss after mini-batch   171: 0.005\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.005\n",
            "Loss after mini-batch   211: 0.005\n",
            "Loss after mini-batch   221: 0.005\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.003\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.003\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.003\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.005\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.005\n",
            "Loss after mini-batch    71: 0.005\n",
            "Loss after mini-batch    81: 0.005\n",
            "Loss after mini-batch    91: 0.003\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.005\n",
            "Loss after mini-batch   161: 0.003\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.003\n",
            "Loss after mini-batch   191: 0.005\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.005\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.003\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.003\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.005\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.003\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.003\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.003\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.005\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.003\n",
            "Loss after mini-batch   281: 0.003\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.005\n",
            "Loss after mini-batch   311: 0.005\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.005\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.005\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.005\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.004\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.003\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.005\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.003\n",
            "Loss after mini-batch   241: 0.003\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.005\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.005\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.005\n",
            "Loss after mini-batch    71: 0.005\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.005\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.005\n",
            "Loss after mini-batch   151: 0.003\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.005\n",
            "Loss after mini-batch   181: 0.005\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.005\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.003\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.003\n",
            "Loss after mini-batch   271: 0.003\n",
            "Loss after mini-batch   281: 0.003\n",
            "Loss after mini-batch   291: 0.003\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.005\n",
            "Loss after mini-batch    21: 0.004\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.005\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.003\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.004\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.005\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.005\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.005\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.005\n",
            "Loss after mini-batch   291: 0.004\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.005\n",
            "Loss after mini-batch   321: 0.003\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.003\n",
            "Loss after mini-batch    31: 0.003\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.005\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.004\n",
            "Loss after mini-batch   131: 0.005\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.003\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.003\n",
            "Loss after mini-batch   211: 0.005\n",
            "Loss after mini-batch   221: 0.004\n",
            "Loss after mini-batch   231: 0.004\n",
            "Loss after mini-batch   241: 0.005\n",
            "Loss after mini-batch   251: 0.005\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.003\n",
            "Loss after mini-batch   301: 0.005\n",
            "Loss after mini-batch   311: 0.005\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Loss after mini-batch     1: 0.001\n",
            "Loss after mini-batch    11: 0.004\n",
            "Loss after mini-batch    21: 0.005\n",
            "Loss after mini-batch    31: 0.004\n",
            "Loss after mini-batch    41: 0.004\n",
            "Loss after mini-batch    51: 0.004\n",
            "Loss after mini-batch    61: 0.004\n",
            "Loss after mini-batch    71: 0.003\n",
            "Loss after mini-batch    81: 0.004\n",
            "Loss after mini-batch    91: 0.004\n",
            "Loss after mini-batch   101: 0.004\n",
            "Loss after mini-batch   111: 0.004\n",
            "Loss after mini-batch   121: 0.005\n",
            "Loss after mini-batch   131: 0.005\n",
            "Loss after mini-batch   141: 0.004\n",
            "Loss after mini-batch   151: 0.004\n",
            "Loss after mini-batch   161: 0.004\n",
            "Loss after mini-batch   171: 0.004\n",
            "Loss after mini-batch   181: 0.004\n",
            "Loss after mini-batch   191: 0.004\n",
            "Loss after mini-batch   201: 0.004\n",
            "Loss after mini-batch   211: 0.004\n",
            "Loss after mini-batch   221: 0.005\n",
            "Loss after mini-batch   231: 0.005\n",
            "Loss after mini-batch   241: 0.004\n",
            "Loss after mini-batch   251: 0.004\n",
            "Loss after mini-batch   261: 0.004\n",
            "Loss after mini-batch   271: 0.004\n",
            "Loss after mini-batch   281: 0.004\n",
            "Loss after mini-batch   291: 0.005\n",
            "Loss after mini-batch   301: 0.004\n",
            "Loss after mini-batch   311: 0.004\n",
            "Loss after mini-batch   321: 0.004\n",
            "Loss after mini-batch   331: 0.004\n",
            "Last iteration loss value: 0.4497932493686676\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Squared Error: 0.09421305668796993\n",
            "R2 Score: 0.5747979797344294\n"
          ]
        }
      ],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "batch_size = 10\n",
        "#This one uses dropout before the output layer\n",
        "\n",
        "#Layer size\n",
        "n_hidden1 = 800  # Number of hidden nodes\n",
        "n_hidden2 = 100\n",
        "n_output =  1   # Number of output nodes = for binary classifier\n",
        "\n",
        "class ChurnModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ChurnModel, self).__init__()\n",
        "        self.layer_1 = nn.Linear(init_features, n_hidden1) \n",
        "        self.layer_2 = nn.Linear(n_hidden1, n_hidden2)\n",
        "        self.layer_out = nn.Linear(n_hidden2, n_output) \n",
        "        \n",
        "        self.relu = nn.ReLU()\n",
        "        self.sigmoid =  nn.Sigmoid()\n",
        "        self.dropout = nn.Dropout(p=0.1)\n",
        "        self.batchnorm1 = nn.BatchNorm1d(n_hidden1)\n",
        "        self.batchnorm2 = nn.BatchNorm1d(n_hidden2)\n",
        "        \n",
        "    \n",
        "    def forward(self, inputs):\n",
        "        x = self.relu(self.layer_1(inputs))\n",
        "        x = self.batchnorm1(x)\n",
        "        x = self.relu(self.layer_2(x))\n",
        "        x = self.batchnorm2(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.sigmoid(self.layer_out(x))\n",
        "        \n",
        "        return x\n",
        "    \n",
        "\n",
        "model = ChurnModel()\n",
        "\n",
        "#Loss Computation\n",
        "loss_func = nn.BCELoss()\n",
        "#Optimizer\n",
        "learning_rate = 0.001\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "#After plotting loss functions, lowest value at 17 epochs, but then it goes crazy the rest of the way. More epochs needed\n",
        "epochs = 100\n",
        "\n",
        "model.train()\n",
        "train_loss = []\n",
        "for epoch in range(epochs):\n",
        "    #Within each epoch run the subsets of data = batch sizes.\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, targets = data\n",
        "        inputs, targets = inputs.float(), targets.float()\n",
        "        targets = targets.reshape((targets.shape[0], 1))\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = mlp(inputs)\n",
        "\n",
        "        loss = loss_function(outputs, targets)\n",
        "        #This time optimizer initialized to zero with each epoch\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        current_loss += loss.item()\n",
        "        if i%10 == 0:\n",
        "            print(f'Loss after mini-batch %5d: %.3f'%(i+1, current_loss/500))\n",
        "            current_loss = 0.0\n",
        "    train_loss.append(loss.item())\n",
        "print('Last iteration loss value: '+ str(loss.item()))\n",
        "\n",
        "plt.plot(train_loss)\n",
        "plt.show()\n",
        "\n",
        "test_data = torch.from_numpy(testX.to_numpy()).float()\n",
        "test_targets = torch.from_numpy(testY.to_numpy()).float()\n",
        "\n",
        "mse_r2_calculator(mlp, test_data, test_targets)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<bound method Module.parameters of ChurnModel(\n",
              "  (layer_1): Linear(in_features=181, out_features=800, bias=True)\n",
              "  (layer_2): Linear(in_features=800, out_features=100, bias=True)\n",
              "  (layer_out): Linear(in_features=100, out_features=1, bias=True)\n",
              "  (relu): ReLU()\n",
              "  (sigmoid): Sigmoid()\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (batchnorm1): BatchNorm1d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (batchnorm2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              ")>"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = ChurnModel()\n",
        "model.parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "#to resolve missing distutils if your python is most recent:\n",
        "import setuptools.dist \n",
        "#other crap\n",
        "import tensorflow as tf\n",
        "from kerastuner.tuners import RandomSearch\n",
        "import keras_tuner\n",
        "import keras\n",
        "from keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "#need torch backend for keras to work\n",
        "os.environ[\"KERAS_BACKEND\"] = \"torch\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "from scikeras.wrappers import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7871 - loss: 0.4433\n",
            "Epoch 2/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9231 - loss: 0.2360\n",
            "Epoch 3/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9337 - loss: 0.1640\n",
            "Epoch 4/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9511 - loss: 0.1203\n",
            "Epoch 5/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9640 - loss: 0.0968\n",
            "Epoch 6/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9734 - loss: 0.0687\n",
            "Epoch 7/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9824 - loss: 0.0481\n",
            "Epoch 8/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9873 - loss: 0.0328\n",
            "Epoch 9/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9888 - loss: 0.0321\n",
            "Epoch 10/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9936 - loss: 0.0197\n",
            "Epoch 11/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9925 - loss: 0.0273\n",
            "Epoch 12/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9957 - loss: 0.0203\n",
            "Epoch 13/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9930 - loss: 0.0265\n",
            "Epoch 14/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9970 - loss: 0.0063\n",
            "Epoch 15/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9985 - loss: 0.0069\n",
            "Epoch 16/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0040\n",
            "Epoch 17/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0022\n",
            "Epoch 18/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9978 - loss: 0.0082\n",
            "Epoch 19/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0037\n",
            "Epoch 20/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9979 - loss: 0.0030\n",
            "Epoch 21/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0017\n",
            "Epoch 22/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 4.8782e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9949 - loss: 0.0245\n",
            "Epoch 24/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9823 - loss: 0.0530\n",
            "Epoch 25/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9919 - loss: 0.0273\n",
            "Epoch 26/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0220\n",
            "Epoch 27/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9985 - loss: 0.0050\n",
            "Epoch 28/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0026\n",
            "Epoch 29/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.1761e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.3987e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.2222e-05\n",
            "Epoch 32/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.4738e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.8532e-05\n",
            "Epoch 34/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.1384e-05\n",
            "Epoch 35/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.1023e-05\n",
            "Epoch 36/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3014e-05\n",
            "Epoch 37/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3703e-05\n",
            "Epoch 38/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1840e-05\n",
            "Epoch 39/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.1324e-06\n",
            "Epoch 40/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.1664e-06\n",
            "Epoch 41/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.6282e-06\n",
            "Epoch 42/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.0539e-06\n",
            "Epoch 43/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.7978e-06\n",
            "Epoch 44/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.3366e-06\n",
            "Epoch 45/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.7987e-06\n",
            "Epoch 46/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.5434e-06\n",
            "Epoch 47/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.2454e-06\n",
            "Epoch 48/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1533e-06\n",
            "Epoch 49/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9048e-06\n",
            "Epoch 50/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0362e-06\n",
            "Epoch 51/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4158e-06\n",
            "Epoch 52/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.6596e-06\n",
            "Epoch 53/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.5223e-06\n",
            "Epoch 54/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8478e-06\n",
            "Epoch 55/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8483e-06\n",
            "Epoch 56/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.1436e-06\n",
            "Epoch 57/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.5941e-06\n",
            "Epoch 58/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.5885e-06\n",
            "Epoch 59/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.1643e-06\n",
            "Epoch 60/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.3895e-06\n",
            "Epoch 61/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2619e-06\n",
            "Epoch 62/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0350e-06\n",
            "Epoch 63/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0255e-06\n",
            "Epoch 64/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.2095e-07\n",
            "Epoch 65/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.7592e-07\n",
            "Epoch 66/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.9452e-07\n",
            "Epoch 67/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.6670e-07\n",
            "Epoch 68/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.1480e-07\n",
            "Epoch 69/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.1134e-07\n",
            "Epoch 70/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.9513e-07\n",
            "Epoch 71/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.9652e-07\n",
            "Epoch 72/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.6572e-07\n",
            "Epoch 73/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.2172e-07\n",
            "Epoch 74/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0666e-07\n",
            "Epoch 75/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.3042e-07\n",
            "Epoch 76/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.2738e-07\n",
            "Epoch 77/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8707e-07\n",
            "Epoch 78/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.5019e-07\n",
            "Epoch 79/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.2047e-07\n",
            "Epoch 80/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.7115e-07\n",
            "Epoch 81/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.9677e-07\n",
            "Epoch 82/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9243e-07\n",
            "Epoch 83/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.5468e-07\n",
            "Epoch 84/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.0459e-07\n",
            "Epoch 85/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.7309e-07\n",
            "Epoch 86/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.9566e-07\n",
            "Epoch 87/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7879e-07\n",
            "Epoch 88/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2515e-07\n",
            "Epoch 89/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.5524e-07\n",
            "Epoch 90/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.2357e-07\n",
            "Epoch 91/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.3156e-07\n",
            "Epoch 92/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.3630e-07\n",
            "Epoch 93/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.1832e-07\n",
            "Epoch 94/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.1295e-07\n",
            "Epoch 95/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1096e-07\n",
            "Epoch 96/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.2975e-07\n",
            "Epoch 97/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 9.2481e-08\n",
            "Epoch 98/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0320e-07\n",
            "Epoch 99/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.7450e-08\n",
            "Epoch 100/100\n",
            "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.0871e-08\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#compile a keras model that is inspired by the first MLP model\n",
        "#LIke that model, it usees sigmoid at the end, but relu for its two hidden layerse\n",
        "def init_model():\n",
        "    inputs = keras.Input(shape=(init_features,), name = \"inputs\")\n",
        "    #first relu\n",
        "    actv1 = keras.layers.Dense(init_features, activation=\"relu\")(inputs)\n",
        "    layer1 = keras.layers.Dense(init_features, activation=\"relu\")(actv1)\n",
        "    #second relu\n",
        "    actv2 = keras.layers.Dense(init_features, activation=\"relu\")(layer1)\n",
        "    layer2 = keras.layers.Dense(90, activation=\"relu\")(actv2)\n",
        "    #sigmoid activation\n",
        "    actv3 = keras.layers.Dense(90, activation=\"relu\")(layer2)\n",
        "    output = keras.layers.Dense(1, activation=\"sigmoid\", name = \"outputs\")(actv3) #shoudl be one binary output, hopefully\n",
        "    model = keras.Model(inputs=inputs, outputs=output)\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "model = init_model()\n",
        "#fit models\n",
        "loss_history = model.fit(X, y, epochs=100)\n",
        "#plot losses across epochs\n",
        "plt.plot(loss_history.history['loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x15725be90>"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "predicted = tf.squeeze(model.predict(testX))\n",
        "predicted = np.array([1 if x >= 0.5 else 0 for x in predicted])\n",
        "actual = np.array(testY)\n",
        "conf_mat = confusion_matrix(actual, predicted)\n",
        "displ = ConfusionMatrixDisplay(confusion_matrix=conf_mat)\n",
        "displ.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [],
      "source": [
        "#make prediction dataframe\n",
        "prediction_df = pd.DataFrame()\n",
        "prediction_df['actual'] = actual\n",
        "prediction_df['bool_pred'] = predicted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Algorithm</th>\n",
              "      <th>Feature Set</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>MCC</th>\n",
              "      <th>Recall</th>\n",
              "      <th>TrueNegRate</th>\n",
              "      <th>Precision</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>keras</td>\n",
              "      <td>AllMeanSph</td>\n",
              "      <td>98.643411</td>\n",
              "      <td>0.970145</td>\n",
              "      <td>100.0</td>\n",
              "      <td>97.971014</td>\n",
              "      <td>96.067416</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Algorithm Feature Set   Accuracy       MCC  Recall  TrueNegRate  Precision\n",
              "0     keras  AllMeanSph  98.643411  0.970145   100.0    97.971014  96.067416"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#result metrics for keras (also in utilties)\n",
        "def check_result_metrics_for_keras(alg, feat_set, prediction_df):\n",
        "    mcc = matthews_corrcoef(prediction_df['actual'], prediction_df['bool_pred'])\n",
        "    TN, FP, FN, TP = confusion_matrix(prediction_df['actual'], prediction_df['bool_pred']).ravel()\n",
        "\n",
        "    TPR=(TP/(TP+FN))*100\n",
        "    TNR=(TN/(TN+FP))*100\n",
        "    acc=((TP+TN)/(TP+TN+FP+FN))*100\n",
        "    Prec=(TP/(TP+FP))*100\n",
        "    return(pd.DataFrame([[alg, feat_set, acc, mcc, TPR, TNR, Prec]],\n",
        "        columns=['Algorithm', 'Feature Set', 'Accuracy', 'MCC', 'Recall', 'TrueNegRate', 'Precision']))\n",
        "\n",
        "keras_alg = \"keras\"\n",
        "check_result_metrics_for_keras(keras_alg, MAHOMES_feature_set, prediction_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [],
      "source": [
        "#USING SKLEARN (original), intitialize model\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "MAHOMES_clf = MLPClassifier(learning_rate_init = 0.01, activation='relu', hidden_layer_sizes= (100,), alpha = 0.001 )\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "random_seed = 0\t(num. training sites= 684 (171+ : 513-) \tnum. features: 181)\n",
            "\tTP=171 \tTN=337 \tFP=8 \tFN=0\n",
            "random_seed = 1\t(num. training sites= 684 (171+ : 513-) \tnum. features: 181)\n",
            "\tTP=171 \tTN=337 \tFP=8 \tFN=0\n",
            "random_seed = 2\t(num. training sites= 684 (171+ : 513-) \tnum. features: 181)\n",
            "\tTP=171 \tTN=341 \tFP=4 \tFN=0\n",
            "random_seed = 3\t(num. training sites= 684 (171+ : 513-) \tnum. features: 181)\n",
            "\tTP=171 \tTN=339 \tFP=6 \tFN=0\n",
            "random_seed = 4\t(num. training sites= 684 (171+ : 513-) \tnum. features: 181)\n",
            "\tTP=171 \tTN=332 \tFP=13 \tFN=0\n",
            "random_seed = 5\t(num. training sites= 684 (171+ : 513-) \tnum. features: 181)\n",
            "\tTP=171 \tTN=339 \tFP=6 \tFN=0\n",
            "random_seed = 6\t(num. training sites= 684 (171+ : 513-) \tnum. features: 181)\n",
            "\tTP=171 \tTN=336 \tFP=9 \tFN=0\n",
            "random_seed = 7\t(num. training sites= 684 (171+ : 513-) \tnum. features: 181)\n",
            "\tTP=171 \tTN=340 \tFP=5 \tFN=0\n",
            "random_seed = 8\t(num. training sites= 684 (171+ : 513-) \tnum. features: 181)\n",
            "\tTP=171 \tTN=337 \tFP=8 \tFN=0\n",
            "random_seed = 9\t(num. training sites= 684 (171+ : 513-) \tnum. features: 181)\n",
            "\tTP=171 \tTN=338 \tFP=7 \tFN=0\n"
          ]
        }
      ],
      "source": [
        "#train\n",
        "MAHOMES_Tsite_predictions =  Utils.evaluate_model_with_Tsite(MAHOMES_clf, MAHOMES_feature_set, Tsites_scaled)\n",
        "MAHOMES_alg = \"NeurNet\" #MLP classifier\n",
        "MAHOMES_feature_set = \"AllMeanSph\"\n",
        "#scores = check_result_metrics(MAHOMES_alg, MAHOMES_feature_set, predicted_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x15810f3e0>"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#MAHOMES ORIGINAL CONFUSION MATRIX\n",
        "predicted = tf.squeeze(MAHOMES_clf.predict(testX))\n",
        "#predicted = np.array([1 if x >= 0.5 else 0 for x in predicted])\n",
        "actual = np.array(testY)\n",
        "conf_mat = confusion_matrix(actual, predicted)\n",
        "displ = ConfusionMatrixDisplay(confusion_matrix=conf_mat)\n",
        "displ.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#to set num samples variable for dataset\n",
        "num_samples = len(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test data correct outputs look like this tensor([1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
            "        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
            "        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n"
          ]
        }
      ],
      "source": [
        "test_data = torch.from_numpy(testX.to_numpy()).float()\n",
        "test_targets = torch.from_numpy(testY.to_numpy()).float()\n",
        "print(\"Test data correct outputs look like this\", test_targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Squared Error: 0.10207024977596316\n",
            "R2 Score: 0.5393369248437435\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "with torch.no_grad():\n",
        "    outputs = mlp(test_data)\n",
        "    predicted_labels = outputs.squeeze().tolist()\n",
        "\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "test_targets = np.array(test_targets)\n",
        "\n",
        "mse = mean_squared_error(test_targets, predicted_labels)\n",
        "r2 = r2_score(test_targets, predicted_labels)\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "print(\"R2 Score:\", r2)\n",
        "# Mean Squared Error: 0.10207024977596316\n",
        "# R2 Score: 0.5393369248437435"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Sklearn MLP confusion matrix:"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
